# Copyright (C) 2017 NVIDIA Corporation. All rights reserved.
# Licensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).

method: codagan
command: train
problem: ss
gpu: 0

# Logger options
image_save_iter: 1000         # How often do you want to save output images during training.
image_display_iter: 100       # How often do you want to display output images during training.
display_size: 8               # How many images do you want to display each time.
snapshot_save_iter: 5         # How often do you want to save trained models.
log_iter: 1                   # How often do you want to log the training stats.

# Training options.
trainer: MUNIT                # Image translation architecture [MUNIT/UNIT].
max_iter: 400                 # Maximum number of training iterations.
batch_size: 32                # Batch size.
weight_decay: 0.0001          # Weight decay.
beta1: 0.5                    # Adam parameter.
beta2: 0.999                  # Adam parameter.
init: kaiming                 # Initialization [gaussian/kaiming/xavier/orthogonal].
lr: 0.0001                    # Initial learning rate.
lr_policy: step               # Learning rate scheduler.
step_size: 400                # How often to decay learning rate.
gamma: 0.5                    # How much to decay learning rate.
gan_w: 1                      # Weight of adversarial loss.
recon_x_w: 10                 # Weight of image reconstruction loss.
recon_s_w: 1                  # Weight of style reconstruction loss.
recon_c_w: 1                  # Weight of content reconstruction loss.
recon_x_cyc_w: 1              # Weight of explicit style augmented cycle consistency loss.

# Model options.
gen:
  dim: 32                     # Number of filters in the bottommost layer.
  mlp_dim: 32                 # Number of filters in MLP.
  style_dim: 8                # Length of style code.
  activ: relu                 # Activation function [relu/lrelu/prelu/selu/tanh].
  n_downsample: 2             # Number of downsampling layers in content encoder.
  n_res: 2                    # Number of residual blocks in content encoder/decoder.
  pad_type: reflect           # Padding type [zero/reflect].
dis:
  dim: 32                     # Number of filters in the bottommost layer.
  norm: none                  # Normalization layer [none/bn/in/ln].
  activ: lrelu                # Activation function [relu/lrelu/prelu/selu/tanh].
  n_layer: 2                  # Number of layers in D.
  gan_type: lsgan             # GAN loss [lsgan/nsgan].
  num_scales: 1               # Number of scales.
  pad_type: reflect           # Padding type [zero/reflect].

# Data options.
input_dim: 1                                # Number of image channels [1/3].
num_workers: 1                              # Number of data loading threads.
new_size: 256                               # First resize the shortest image side to this size.
crop_image_height: 256                      # Random crop image of this height.
crop_image_width: 256                       # Random crop image of this width.
data_root: /home/muhammadyusuf.hassan/Dataset/cc359/           # Dataset folder location.
output_path: /home/muhammadyusuf.hassan/Brain-MR-Segmentation-Playground/
resume: -1
snapshot_dir: .
n_datasets: 3                               # Number of datasets for Domain Adaptation.
trim: 1                                     # Trim images or not.
transform_ge3: 2                            # Type of Data Augmentation. More info on file data.py.
transform_siemens3: 2                       # Type of Data Augmentation. More info on file data.py.
transform_philips3: 2                       # Type of Data Augmentation. More info on file data.py.
prob_ge3: 0.33                              # Probability of chosing the dataset at each iteration.
prob_siemens3: 0.33                         # Probability of chosing the dataset at each iteration.
prob_philips3: 0.34                         # Probability of chosing the dataset at each iteration.
sample_ge3: 1.0                             # Percentage of labeled samples to maintain in dataset to simulate UDA and SSDA.
sample_siemens3: 1.0                        # Percentage of labeled samples to maintain in dataset to simulate UDA and SSDA.
sample_philips3: 1.0                        # Percentage of labeled samples to maintain in dataset to simulate UDA and SSDA.
