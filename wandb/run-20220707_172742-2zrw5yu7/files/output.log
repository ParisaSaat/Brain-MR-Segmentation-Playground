Training Main Encoder
Epoch  0 / 300
Train Epoch: 0 [12/10752 (0%)]	 Regressor Loss: -0.262533
Regressor Loss: -0.2625
Domain Loss: 0.6986
Train Epoch: 0 [132/10752 (1%)]	 Regressor Loss: -0.103808
Regressor Loss: -0.1038
Domain Loss: 0.6584
Train Epoch: 0 [252/10752 (2%)]	 Regressor Loss: -0.322632
Regressor Loss: -0.3226
Domain Loss: 0.7207
Train Epoch: 0 [372/10752 (3%)]	 Regressor Loss: -0.077124
Regressor Loss: -0.0771
Domain Loss: 0.6235
Train Epoch: 0 [492/10752 (5%)]	 Regressor Loss: -0.363405
Regressor Loss: -0.3634
Domain Loss: 0.6846
Train Epoch: 0 [612/10752 (6%)]	 Regressor Loss: -0.153007
Regressor Loss: -0.1530
Domain Loss: 0.6308
Train Epoch: 0 [732/10752 (7%)]	 Regressor Loss: -0.375872
Regressor Loss: -0.3759
Domain Loss: 0.6681
Train Epoch: 0 [852/10752 (8%)]	 Regressor Loss: -0.154699
Regressor Loss: -0.1547
Domain Loss: 0.5575
Train Epoch: 0 [972/10752 (9%)]	 Regressor Loss: -0.174147
Regressor Loss: -0.1741
Domain Loss: 0.5600
Train Epoch: 0 [1092/10752 (10%)]	 Regressor Loss: -0.168779
Regressor Loss: -0.1688
Domain Loss: 0.4743
Train Epoch: 0 [1212/10752 (11%)]	 Regressor Loss: -0.227847
Regressor Loss: -0.2278
Domain Loss: 0.5282
Train Epoch: 0 [1332/10752 (12%)]	 Regressor Loss: -0.213798
Regressor Loss: -0.2138
Domain Loss: 0.4393
Train Epoch: 0 [1452/10752 (14%)]	 Regressor Loss: -0.137135
Regressor Loss: -0.1371
Domain Loss: 0.4126
Train Epoch: 0 [1572/10752 (15%)]	 Regressor Loss: -0.180922
Regressor Loss: -0.1809
Domain Loss: 0.5185
Train Epoch: 0 [1692/10752 (16%)]	 Regressor Loss: -0.049292
Regressor Loss: -0.0493
Domain Loss: 0.3461
Train Epoch: 0 [1812/10752 (17%)]	 Regressor Loss: -0.217206
Regressor Loss: -0.2172
Domain Loss: 0.4064
Train Epoch: 0 [1932/10752 (18%)]	 Regressor Loss: -0.091193
Regressor Loss: -0.0912
Domain Loss: 0.2640
Train Epoch: 0 [2052/10752 (19%)]	 Regressor Loss: -0.193476
Regressor Loss: -0.1935
Domain Loss: 0.6000
Train Epoch: 0 [2172/10752 (20%)]	 Regressor Loss: -0.144167
Regressor Loss: -0.1442
Domain Loss: 0.2812
Train Epoch: 0 [2292/10752 (21%)]	 Regressor Loss: -0.262941
Regressor Loss: -0.2629
Domain Loss: 0.2843
Train Epoch: 0 [2412/10752 (22%)]	 Regressor Loss: -0.141916
Regressor Loss: -0.1419
Domain Loss: 0.2011
Train Epoch: 0 [2532/10752 (24%)]	 Regressor Loss: -0.235582
Regressor Loss: -0.2356
Domain Loss: 0.3990
Train Epoch: 0 [2652/10752 (25%)]	 Regressor Loss: -0.000000
Regressor Loss: -0.0000
Domain Loss: 0.1330
Train Epoch: 0 [2772/10752 (26%)]	 Regressor Loss: -0.315793
Regressor Loss: -0.3158
Domain Loss: 0.4218
Train Epoch: 0 [2892/10752 (27%)]	 Regressor Loss: -0.126242
Regressor Loss: -0.1262
Domain Loss: 0.2037
Train Epoch: 0 [3012/10752 (28%)]	 Regressor Loss: -0.296680
Regressor Loss: -0.2967
Domain Loss: 0.2319
Train Epoch: 0 [3132/10752 (29%)]	 Regressor Loss: -0.210067
Regressor Loss: -0.2101
Domain Loss: 0.1665
Train Epoch: 0 [3252/10752 (30%)]	 Regressor Loss: -0.340050
Regressor Loss: -0.3400
Domain Loss: 0.1350
Train Epoch: 0 [3372/10752 (31%)]	 Regressor Loss: -0.164167
Regressor Loss: -0.1642
Domain Loss: 0.1122
Train Epoch: 0 [3492/10752 (32%)]	 Regressor Loss: -0.324481
Regressor Loss: -0.3245
Domain Loss: 0.1075
Train Epoch: 0 [3612/10752 (34%)]	 Regressor Loss: -0.127420
Regressor Loss: -0.1274
Domain Loss: 0.0702
Train Epoch: 0 [3732/10752 (35%)]	 Regressor Loss: -0.385290
Regressor Loss: -0.3853
Domain Loss: 0.0614
Train Epoch: 0 [3852/10752 (36%)]	 Regressor Loss: -0.110620
Regressor Loss: -0.1106
Domain Loss: 0.0998
Train Epoch: 0 [3972/10752 (37%)]	 Regressor Loss: -0.315323
Regressor Loss: -0.3153
Domain Loss: 0.0418
Train Epoch: 0 [4092/10752 (38%)]	 Regressor Loss: -0.139278
Regressor Loss: -0.1393
Domain Loss: 0.0334
Train Epoch: 0 [4212/10752 (39%)]	 Regressor Loss: -0.102784
Regressor Loss: -0.1028
Domain Loss: 0.2096
Train Epoch: 0 [4332/10752 (40%)]	 Regressor Loss: -0.094158
Regressor Loss: -0.0942
Domain Loss: 0.0429
Train Epoch: 0 [4452/10752 (41%)]	 Regressor Loss: -0.089558
Regressor Loss: -0.0896
Domain Loss: 0.0173
Train Epoch: 0 [4572/10752 (43%)]	 Regressor Loss: -0.126967
Regressor Loss: -0.1270
Domain Loss: 0.0146
Train Epoch: 0 [4692/10752 (44%)]	 Regressor Loss: -0.120917
Regressor Loss: -0.1209
Domain Loss: 0.0394
Train Epoch: 0 [4812/10752 (45%)]	 Regressor Loss: -0.151139
Regressor Loss: -0.1511
Domain Loss: 0.0443
Train Epoch: 0 [4932/10752 (46%)]	 Regressor Loss: -0.212821
Regressor Loss: -0.2128
Domain Loss: 0.0206
Train Epoch: 0 [5052/10752 (47%)]	 Regressor Loss: -0.181307
Regressor Loss: -0.1813
Domain Loss: 0.0227
Train Epoch: 0 [5172/10752 (48%)]	 Regressor Loss: -0.124602
Regressor Loss: -0.1246
Domain Loss: 0.0079
Train Epoch: 0 [5292/10752 (49%)]	 Regressor Loss: -0.287192
Regressor Loss: -0.2872
Domain Loss: 0.0155
Train Epoch: 0 [5412/10752 (50%)]	 Regressor Loss: -0.043820
Regressor Loss: -0.0438
Domain Loss: 0.0925
Train Epoch: 0 [5532/10752 (51%)]	 Regressor Loss: -0.288223
Regressor Loss: -0.2882
Domain Loss: 0.0122
Train Epoch: 0 [5652/10752 (53%)]	 Regressor Loss: -0.163548
Regressor Loss: -0.1635
Domain Loss: 0.0123
Train Epoch: 0 [5772/10752 (54%)]	 Regressor Loss: -0.326635
Regressor Loss: -0.3266
Domain Loss: 0.0172
Train Epoch: 0 [5892/10752 (55%)]	 Regressor Loss: -0.140701
Regressor Loss: -0.1407
Domain Loss: 0.0087
Train Epoch: 0 [6012/10752 (56%)]	 Regressor Loss: -0.348779
Regressor Loss: -0.3488
Domain Loss: 0.0096
Train Epoch: 0 [6132/10752 (57%)]	 Regressor Loss: -0.225578
Regressor Loss: -0.2256
Domain Loss: 0.0111
Train Epoch: 0 [6252/10752 (58%)]	 Regressor Loss: -0.335631
Regressor Loss: -0.3356
Domain Loss: 0.0177
Train Epoch: 0 [6372/10752 (59%)]	 Regressor Loss: -0.142884
Regressor Loss: -0.1429
Domain Loss: 0.0045
Train Epoch: 0 [6492/10752 (60%)]	 Regressor Loss: -0.314419
Regressor Loss: -0.3144
Domain Loss: 0.0260
Train Epoch: 0 [6612/10752 (61%)]	 Regressor Loss: -0.168604
Regressor Loss: -0.1686
Domain Loss: 0.0097
Train Epoch: 0 [6732/10752 (63%)]	 Regressor Loss: -0.332347
Regressor Loss: -0.3323
Domain Loss: 0.0135
Train Epoch: 0 [6852/10752 (64%)]	 Regressor Loss: -0.183298
Regressor Loss: -0.1833
Domain Loss: 0.0053
Train Epoch: 0 [6972/10752 (65%)]	 Regressor Loss: -0.320512
Regressor Loss: -0.3205
Domain Loss: 0.0075
Train Epoch: 0 [7092/10752 (66%)]	 Regressor Loss: -0.147999
Regressor Loss: -0.1480
Domain Loss: 0.0057
Train Epoch: 0 [7212/10752 (67%)]	 Regressor Loss: -0.283182
Regressor Loss: -0.2832
Domain Loss: 0.0029
Train Epoch: 0 [7332/10752 (68%)]	 Regressor Loss: -0.187034
Regressor Loss: -0.1870
Domain Loss: 0.0013
Train Epoch: 0 [7452/10752 (69%)]	 Regressor Loss: -0.366220
Regressor Loss: -0.3662
Domain Loss: 0.0015
Train Epoch: 0 [7572/10752 (70%)]	 Regressor Loss: -0.205648
Regressor Loss: -0.2056
Domain Loss: 0.0090
Train Epoch: 0 [7692/10752 (72%)]	 Regressor Loss: -0.200332
Regressor Loss: -0.2003
Domain Loss: 0.0051
Train Epoch: 0 [7812/10752 (73%)]	 Regressor Loss: -0.120602
Regressor Loss: -0.1206
Domain Loss: 0.0083
Train Epoch: 0 [7932/10752 (74%)]	 Regressor Loss: -0.142863
Regressor Loss: -0.1429
Domain Loss: 0.0037
Train Epoch: 0 [8052/10752 (75%)]	 Regressor Loss: -0.092825
Regressor Loss: -0.0928
Domain Loss: 0.0140
Train Epoch: 0 [8172/10752 (76%)]	 Regressor Loss: -0.122946
Regressor Loss: -0.1229
Domain Loss: 0.0024
Train Epoch: 0 [8292/10752 (77%)]	 Regressor Loss: -0.237535
Regressor Loss: -0.2375
Domain Loss: 0.0022
Train Epoch: 0 [8412/10752 (78%)]	 Regressor Loss: -0.140191
Regressor Loss: -0.1402
Domain Loss: 0.0016
Train Epoch: 0 [8532/10752 (79%)]	 Regressor Loss: -0.189775
Regressor Loss: -0.1898
Domain Loss: 0.0027
Train Epoch: 0 [8652/10752 (80%)]	 Regressor Loss: -0.202049
Regressor Loss: -0.2020
Domain Loss: 0.0023
Train Epoch: 0 [8772/10752 (82%)]	 Regressor Loss: -0.259592
Regressor Loss: -0.2596
Domain Loss: 0.0020
Train Epoch: 0 [8892/10752 (83%)]	 Regressor Loss: -0.109807
Regressor Loss: -0.1098
Domain Loss: 0.0006
Train Epoch: 0 [9012/10752 (84%)]	 Regressor Loss: -0.369142
Regressor Loss: -0.3691
Domain Loss: 0.0053
Train Epoch: 0 [9132/10752 (85%)]	 Regressor Loss: -0.188280
Regressor Loss: -0.1883
Domain Loss: 0.0022
Train Epoch: 0 [9252/10752 (86%)]	 Regressor Loss: -0.363263
Regressor Loss: -0.3633
Domain Loss: 0.0033
Train Epoch: 0 [9372/10752 (87%)]	 Regressor Loss: -0.076837
Regressor Loss: -0.0768
Domain Loss: 0.0011
Training set: Average loss: -0.2012
Training set: Average Domain loss: 0.1688
Training set: Average Acc: 0.9426
Validation set: Average loss: -0.1996
Validation set: Average Domain loss: 0.0041
 Validation set: Average Acc: 1.0000
Training Main Encoder
Epoch  1 / 300
Train Epoch: 1 [12/10752 (0%)]	 Regressor Loss: -0.197086
Regressor Loss: -0.1971
Domain Loss: 0.0077
Train Epoch: 1 [132/10752 (1%)]	 Regressor Loss: -0.225669
Regressor Loss: -0.2257
Domain Loss: 0.0005
Train Epoch: 1 [252/10752 (2%)]	 Regressor Loss: -0.347136
Regressor Loss: -0.3471
Domain Loss: 0.0023
Train Epoch: 1 [372/10752 (3%)]	 Regressor Loss: -0.132537
Regressor Loss: -0.1325
Domain Loss: 0.0125
Train Epoch: 1 [492/10752 (5%)]	 Regressor Loss: -0.369214
Regressor Loss: -0.3692
Domain Loss: 0.0060
Train Epoch: 1 [612/10752 (6%)]	 Regressor Loss: -0.115352
Regressor Loss: -0.1154
Domain Loss: 0.0007
Train Epoch: 1 [732/10752 (7%)]	 Regressor Loss: -0.394081
Regressor Loss: -0.3941
Domain Loss: 0.0022
Train Epoch: 1 [852/10752 (8%)]	 Regressor Loss: -0.184972
Regressor Loss: -0.1850
Domain Loss: 0.0020
Train Epoch: 1 [972/10752 (9%)]	 Regressor Loss: -0.130666
Regressor Loss: -0.1307
Domain Loss: 0.0012
Train Epoch: 1 [1092/10752 (10%)]	 Regressor Loss: -0.066855
Regressor Loss: -0.0669
Domain Loss: 0.0007
Train Epoch: 1 [1212/10752 (11%)]	 Regressor Loss: -0.127762
Regressor Loss: -0.1278
Domain Loss: 0.0009
Train Epoch: 1 [1332/10752 (12%)]	 Regressor Loss: -0.184260
Regressor Loss: -0.1843
Domain Loss: 0.0031
Train Epoch: 1 [1452/10752 (14%)]	 Regressor Loss: -0.182572
Regressor Loss: -0.1826
Domain Loss: 0.0010
Train Epoch: 1 [1572/10752 (15%)]	 Regressor Loss: -0.234383
Regressor Loss: -0.2344
Domain Loss: 0.0029
Train Epoch: 1 [1692/10752 (16%)]	 Regressor Loss: -0.103454
Regressor Loss: -0.1035
Domain Loss: 0.0004
Train Epoch: 1 [1812/10752 (17%)]	 Regressor Loss: -0.182134
Regressor Loss: -0.1821
Domain Loss: 0.0026
Train Epoch: 1 [1932/10752 (18%)]	 Regressor Loss: -0.110019
Regressor Loss: -0.1100
Domain Loss: 0.0029
Train Epoch: 1 [2052/10752 (19%)]	 Regressor Loss: -0.224192
Regressor Loss: -0.2242
Domain Loss: 0.0022
Train Epoch: 1 [2172/10752 (20%)]	 Regressor Loss: -0.160201
Regressor Loss: -0.1602
Domain Loss: 0.0017
Train Epoch: 1 [2292/10752 (21%)]	 Regressor Loss: -0.363700
Regressor Loss: -0.3637
Domain Loss: 0.0018
Train Epoch: 1 [2412/10752 (22%)]	 Regressor Loss: -0.097473
Regressor Loss: -0.0975
Domain Loss: 0.0006
Train Epoch: 1 [2532/10752 (24%)]	 Regressor Loss: -0.305060
Regressor Loss: -0.3051
Domain Loss: 0.0017
Train Epoch: 1 [2652/10752 (25%)]	 Regressor Loss: -0.087657
Regressor Loss: -0.0877
Domain Loss: 0.0003
Train Epoch: 1 [2772/10752 (26%)]	 Regressor Loss: -0.398675
Regressor Loss: -0.3987
Domain Loss: 0.0031
Train Epoch: 1 [2892/10752 (27%)]	 Regressor Loss: -0.159102
Regressor Loss: -0.1591
Domain Loss: 0.0009
Train Epoch: 1 [3012/10752 (28%)]	 Regressor Loss: -0.341881
Regressor Loss: -0.3419
Domain Loss: 0.0010
Train Epoch: 1 [3132/10752 (29%)]	 Regressor Loss: -0.227060
Regressor Loss: -0.2271
Domain Loss: 0.0008
Train Epoch: 1 [3252/10752 (30%)]	 Regressor Loss: -0.308468
Regressor Loss: -0.3085
Domain Loss: 0.0014
Train Epoch: 1 [3372/10752 (31%)]	 Regressor Loss: -0.090141
Regressor Loss: -0.0901
Domain Loss: 0.0046
Train Epoch: 1 [3492/10752 (32%)]	 Regressor Loss: -0.388287
Regressor Loss: -0.3883
Domain Loss: 0.0119
Train Epoch: 1 [3612/10752 (34%)]	 Regressor Loss: -0.113238
Regressor Loss: -0.1132
Domain Loss: 0.0010
Train Epoch: 1 [3732/10752 (35%)]	 Regressor Loss: -0.383588
Regressor Loss: -0.3836
Domain Loss: 0.0010
Train Epoch: 1 [3852/10752 (36%)]	 Regressor Loss: -0.193118
Regressor Loss: -0.1931
Domain Loss: 0.0005
Train Epoch: 1 [3972/10752 (37%)]	 Regressor Loss: -0.283317
Regressor Loss: -0.2833
Domain Loss: 0.0019
Train Epoch: 1 [4092/10752 (38%)]	 Regressor Loss: -0.192601
Regressor Loss: -0.1926
Domain Loss: 0.0002
Train Epoch: 1 [4212/10752 (39%)]	 Regressor Loss: -0.264933
Regressor Loss: -0.2649
Domain Loss: 0.0022
Train Epoch: 1 [4332/10752 (40%)]	 Regressor Loss: -0.083758
Regressor Loss: -0.0838
Domain Loss: 0.0010
Train Epoch: 1 [4452/10752 (41%)]	 Regressor Loss: -0.113299
Regressor Loss: -0.1133
Domain Loss: 0.0007
Train Epoch: 1 [4572/10752 (43%)]	 Regressor Loss: -0.120662
Regressor Loss: -0.1207
Domain Loss: 0.0005
Train Epoch: 1 [4692/10752 (44%)]	 Regressor Loss: -0.127734
Regressor Loss: -0.1277
Domain Loss: 0.0003
Train Epoch: 1 [4812/10752 (45%)]	 Regressor Loss: -0.144588
Regressor Loss: -0.1446
Domain Loss: 0.0017
Train Epoch: 1 [4932/10752 (46%)]	 Regressor Loss: -0.142270
Regressor Loss: -0.1423
Domain Loss: 0.0004
Train Epoch: 1 [5052/10752 (47%)]	 Regressor Loss: -0.203599
Regressor Loss: -0.2036
Domain Loss: 0.0003
Train Epoch: 1 [5172/10752 (48%)]	 Regressor Loss: -0.158384
Regressor Loss: -0.1584
Domain Loss: 0.0012
Train Epoch: 1 [5292/10752 (49%)]	 Regressor Loss: -0.299056
Regressor Loss: -0.2991
Domain Loss: 0.0010
Train Epoch: 1 [5412/10752 (50%)]	 Regressor Loss: -0.179665
Regressor Loss: -0.1797
Domain Loss: 0.0001
Train Epoch: 1 [5532/10752 (51%)]	 Regressor Loss: -0.297989
Regressor Loss: -0.2980
Domain Loss: 0.0004
Train Epoch: 1 [5652/10752 (53%)]	 Regressor Loss: -0.160125
Regressor Loss: -0.1601
Domain Loss: 0.0012
Train Epoch: 1 [5772/10752 (54%)]	 Regressor Loss: -0.374686
Regressor Loss: -0.3747
Domain Loss: 0.0230
Train Epoch: 1 [5892/10752 (55%)]	 Regressor Loss: -0.214355
Regressor Loss: -0.2144
Domain Loss: 0.0024
Train Epoch: 1 [6012/10752 (56%)]	 Regressor Loss: -0.369650
Regressor Loss: -0.3697
Domain Loss: 0.0011
Train Epoch: 1 [6132/10752 (57%)]	 Regressor Loss: -0.187512
Regressor Loss: -0.1875
Domain Loss: 0.0006
Train Epoch: 1 [6252/10752 (58%)]	 Regressor Loss: -0.350376
Regressor Loss: -0.3504
Domain Loss: 0.0011
Train Epoch: 1 [6372/10752 (59%)]	 Regressor Loss: -0.133098
Regressor Loss: -0.1331
Domain Loss: 0.0018
Train Epoch: 1 [6492/10752 (60%)]	 Regressor Loss: -0.357412
Regressor Loss: -0.3574
Domain Loss: 0.0199
Train Epoch: 1 [6612/10752 (61%)]	 Regressor Loss: -0.086377
Regressor Loss: -0.0864
Domain Loss: 0.0017
Train Epoch: 1 [6732/10752 (63%)]	 Regressor Loss: -0.159276
Regressor Loss: -0.1593
Domain Loss: 0.0005
Train Epoch: 1 [6852/10752 (64%)]	 Regressor Loss: -0.139599
Regressor Loss: -0.1396
Domain Loss: 0.0011
Train Epoch: 1 [6972/10752 (65%)]	 Regressor Loss: -0.344631
Regressor Loss: -0.3446
Domain Loss: 0.0005
Train Epoch: 1 [7092/10752 (66%)]	 Regressor Loss: -0.085522
Regressor Loss: -0.0855
Domain Loss: 0.0006
Train Epoch: 1 [7212/10752 (67%)]	 Regressor Loss: -0.255663
Regressor Loss: -0.2557
Domain Loss: 0.0008
Train Epoch: 1 [7332/10752 (68%)]	 Regressor Loss: -0.132568
Regressor Loss: -0.1326
Domain Loss: 0.0008
Train Epoch: 1 [7452/10752 (69%)]	 Regressor Loss: -0.256492
Regressor Loss: -0.2565
Domain Loss: 0.0004
Train Epoch: 1 [7572/10752 (70%)]	 Regressor Loss: -0.097964
Regressor Loss: -0.0980
Domain Loss: 0.0009
Train Epoch: 1 [7692/10752 (72%)]	 Regressor Loss: -0.138154
Regressor Loss: -0.1382
Domain Loss: 0.0023
Train Epoch: 1 [7812/10752 (73%)]	 Regressor Loss: -0.155915
Regressor Loss: -0.1559
Domain Loss: 0.0016
Train Epoch: 1 [7932/10752 (74%)]	 Regressor Loss: -0.155018
Regressor Loss: -0.1550
Domain Loss: 0.0004
Train Epoch: 1 [8052/10752 (75%)]	 Regressor Loss: -0.165318
Regressor Loss: -0.1653
Domain Loss: 0.0005
Train Epoch: 1 [8172/10752 (76%)]	 Regressor Loss: -0.219951
Regressor Loss: -0.2200
Domain Loss: 0.0004
Train Epoch: 1 [8292/10752 (77%)]	 Regressor Loss: -0.248116
Regressor Loss: -0.2481
Domain Loss: 0.0003
Train Epoch: 1 [8412/10752 (78%)]	 Regressor Loss: -0.198781
Regressor Loss: -0.1988
Domain Loss: 0.0008
Train Epoch: 1 [8532/10752 (79%)]	 Regressor Loss: -0.277773
Regressor Loss: -0.2778
Domain Loss: 0.0003
Train Epoch: 1 [8652/10752 (80%)]	 Regressor Loss: -0.142215
Regressor Loss: -0.1422
Domain Loss: 0.0011
Train Epoch: 1 [8772/10752 (82%)]	 Regressor Loss: -0.296095
Regressor Loss: -0.2961
Domain Loss: 0.0003
Train Epoch: 1 [8892/10752 (83%)]	 Regressor Loss: -0.150624
Regressor Loss: -0.1506
Domain Loss: 0.0004
Train Epoch: 1 [9012/10752 (84%)]	 Regressor Loss: -0.411828
Regressor Loss: -0.4118
Domain Loss: 0.0003
Train Epoch: 1 [9132/10752 (85%)]	 Regressor Loss: -0.211237
Regressor Loss: -0.2112
Domain Loss: 0.0004
Train Epoch: 1 [9252/10752 (86%)]	 Regressor Loss: -0.345842
Regressor Loss: -0.3458
Domain Loss: 0.0010
Train Epoch: 1 [9372/10752 (87%)]	 Regressor Loss: -0.143235
Regressor Loss: -0.1432
Domain Loss: 0.0008
Training set: Average loss: -0.2085
Training set: Average Domain loss: 0.0025
Training set: Average Acc: 0.9997
Validation set: Average loss: -0.2059
Validation set: Average Domain loss: 0.0010
 Validation set: Average Acc: 1.0000
Training Main Encoder
Epoch  2 / 300
Train Epoch: 2 [12/10752 (0%)]	 Regressor Loss: -0.365884
Regressor Loss: -0.3659
Domain Loss: 0.0004
Train Epoch: 2 [132/10752 (1%)]	 Regressor Loss: -0.242613
Regressor Loss: -0.2426
Domain Loss: 0.0006
Train Epoch: 2 [252/10752 (2%)]	 Regressor Loss: -0.352701
Regressor Loss: -0.3527
Domain Loss: 0.0011
Train Epoch: 2 [372/10752 (3%)]	 Regressor Loss: -0.141688
Regressor Loss: -0.1417
Domain Loss: 0.0002
Train Epoch: 2 [492/10752 (5%)]	 Regressor Loss: -0.321252
Regressor Loss: -0.3213
Domain Loss: 0.0006
Train Epoch: 2 [612/10752 (6%)]	 Regressor Loss: -0.219756
Regressor Loss: -0.2198
Domain Loss: 0.0006
Train Epoch: 2 [732/10752 (7%)]	 Regressor Loss: -0.373607
Regressor Loss: -0.3736
Domain Loss: 0.0008
Train Epoch: 2 [852/10752 (8%)]	 Regressor Loss: -0.201974
Regressor Loss: -0.2020
Domain Loss: 0.0001
Train Epoch: 2 [972/10752 (9%)]	 Regressor Loss: -0.172037
Regressor Loss: -0.1720
Domain Loss: 0.0018
Train Epoch: 2 [1092/10752 (10%)]	 Regressor Loss: -0.159947
Regressor Loss: -0.1599
Domain Loss: 0.0002
Train Epoch: 2 [1212/10752 (11%)]	 Regressor Loss: -0.141378
Regressor Loss: -0.1414
Domain Loss: 0.0006
Train Epoch: 2 [1332/10752 (12%)]	 Regressor Loss: -0.169386
Regressor Loss: -0.1694
Domain Loss: 0.0004
Train Epoch: 2 [1452/10752 (14%)]	 Regressor Loss: -0.160271
Regressor Loss: -0.1603
Domain Loss: 0.0002
Train Epoch: 2 [1572/10752 (15%)]	 Regressor Loss: -0.150116
Regressor Loss: -0.1501
Domain Loss: 0.0018
Train Epoch: 2 [1692/10752 (16%)]	 Regressor Loss: -0.155702
Regressor Loss: -0.1557
Domain Loss: 0.0009
Train Epoch: 2 [1812/10752 (17%)]	 Regressor Loss: -0.260725
Regressor Loss: -0.2607
Domain Loss: 0.0008
Train Epoch: 2 [1932/10752 (18%)]	 Regressor Loss: -0.074960
Regressor Loss: -0.0750
Domain Loss: 0.0001
Train Epoch: 2 [2052/10752 (19%)]	 Regressor Loss: -0.285838
Regressor Loss: -0.2858
Domain Loss: 0.0002
Train Epoch: 2 [2172/10752 (20%)]	 Regressor Loss: -0.091915
Regressor Loss: -0.0919
Domain Loss: 0.0001
Train Epoch: 2 [2292/10752 (21%)]	 Regressor Loss: -0.325314
Regressor Loss: -0.3253
Domain Loss: 0.0001
Train Epoch: 2 [2412/10752 (22%)]	 Regressor Loss: -0.155935
Regressor Loss: -0.1559
Domain Loss: 0.0001
Train Epoch: 2 [2532/10752 (24%)]	 Regressor Loss: -0.286884
Regressor Loss: -0.2869
Domain Loss: 0.0002
Train Epoch: 2 [2652/10752 (25%)]	 Regressor Loss: -0.140946
Regressor Loss: -0.1409
Domain Loss: 0.0004
Train Epoch: 2 [2772/10752 (26%)]	 Regressor Loss: -0.330130
Regressor Loss: -0.3301
Domain Loss: 0.0010
Train Epoch: 2 [2892/10752 (27%)]	 Regressor Loss: -0.118042
Regressor Loss: -0.1180
Domain Loss: 0.0002
Train Epoch: 2 [3012/10752 (28%)]	 Regressor Loss: -0.340773
Regressor Loss: -0.3408
Domain Loss: 0.0001
Train Epoch: 2 [3132/10752 (29%)]	 Regressor Loss: -0.252527
Regressor Loss: -0.2525
Domain Loss: 0.0003
Train Epoch: 2 [3252/10752 (30%)]	 Regressor Loss: -0.401050
Regressor Loss: -0.4010
Domain Loss: 0.0006
Train Epoch: 2 [3372/10752 (31%)]	 Regressor Loss: -0.162069
Regressor Loss: -0.1621
Domain Loss: 0.0003
Train Epoch: 2 [3492/10752 (32%)]	 Regressor Loss: -0.374576
Regressor Loss: -0.3746
Domain Loss: 0.0001
Train Epoch: 2 [3612/10752 (34%)]	 Regressor Loss: -0.111001
Regressor Loss: -0.1110
Domain Loss: 0.0002
Train Epoch: 2 [3732/10752 (35%)]	 Regressor Loss: -0.408132
Regressor Loss: -0.4081
Domain Loss: 0.0003
Train Epoch: 2 [3852/10752 (36%)]	 Regressor Loss: -0.065261
Regressor Loss: -0.0653
Domain Loss: 0.0001
Train Epoch: 2 [3972/10752 (37%)]	 Regressor Loss: -0.376794
Regressor Loss: -0.3768
Domain Loss: 0.0005
Train Epoch: 2 [4092/10752 (38%)]	 Regressor Loss: -0.197041
Regressor Loss: -0.1970
Domain Loss: 0.0002
Train Epoch: 2 [4212/10752 (39%)]	 Regressor Loss: -0.202530
Regressor Loss: -0.2025
Domain Loss: 0.0004
Train Epoch: 2 [4332/10752 (40%)]	 Regressor Loss: -0.160265
Regressor Loss: -0.1603
Domain Loss: 0.0001
Train Epoch: 2 [4452/10752 (41%)]	 Regressor Loss: -0.094992
Regressor Loss: -0.0950
Domain Loss: 0.0002
Train Epoch: 2 [4572/10752 (43%)]	 Regressor Loss: -0.093180
Regressor Loss: -0.0932
Domain Loss: 0.0000
Train Epoch: 2 [4692/10752 (44%)]	 Regressor Loss: -0.154637
Regressor Loss: -0.1546
Domain Loss: 0.0002
Train Epoch: 2 [4812/10752 (45%)]	 Regressor Loss: -0.095274
Regressor Loss: -0.0953
Domain Loss: 0.0008
Train Epoch: 2 [4932/10752 (46%)]	 Regressor Loss: -0.238656
Regressor Loss: -0.2387
Domain Loss: 0.0003
Train Epoch: 2 [5052/10752 (47%)]	 Regressor Loss: -0.223066
Regressor Loss: -0.2231
Domain Loss: 0.0003
Train Epoch: 2 [5172/10752 (48%)]	 Regressor Loss: -0.113982
Regressor Loss: -0.1140
Domain Loss: 0.0000
Train Epoch: 2 [5292/10752 (49%)]	 Regressor Loss: -0.357565
Regressor Loss: -0.3576
Domain Loss: 0.0002
Train Epoch: 2 [5412/10752 (50%)]	 Regressor Loss: -0.013671
Regressor Loss: -0.0137
Domain Loss: 0.0002
Train Epoch: 2 [5532/10752 (51%)]	 Regressor Loss: -0.364479
Regressor Loss: -0.3645
Domain Loss: 0.0003
Train Epoch: 2 [5652/10752 (53%)]	 Regressor Loss: -0.214981
Regressor Loss: -0.2150
Domain Loss: 0.0003
Train Epoch: 2 [5772/10752 (54%)]	 Regressor Loss: -0.367744
Regressor Loss: -0.3677
Domain Loss: 0.0003
Train Epoch: 2 [5892/10752 (55%)]	 Regressor Loss: -0.178431
Regressor Loss: -0.1784
Domain Loss: 0.0001
Train Epoch: 2 [6012/10752 (56%)]	 Regressor Loss: -0.342472
Regressor Loss: -0.3425
Domain Loss: 0.0007
Train Epoch: 2 [6132/10752 (57%)]	 Regressor Loss: -0.201311
Regressor Loss: -0.2013
Domain Loss: 0.0000
Train Epoch: 2 [6252/10752 (58%)]	 Regressor Loss: -0.334408
Regressor Loss: -0.3344
Domain Loss: 0.0005
Train Epoch: 2 [6372/10752 (59%)]	 Regressor Loss: -0.166944
Regressor Loss: -0.1669
Domain Loss: 0.0010
Train Epoch: 2 [6492/10752 (60%)]	 Regressor Loss: -0.381174
Regressor Loss: -0.3812
Domain Loss: 0.0003
Train Epoch: 2 [6612/10752 (61%)]	 Regressor Loss: -0.140969
Regressor Loss: -0.1410
Domain Loss: 0.0000
Train Epoch: 2 [6732/10752 (63%)]	 Regressor Loss: -0.256775
Regressor Loss: -0.2568
Domain Loss: 0.0000
Train Epoch: 2 [6852/10752 (64%)]	 Regressor Loss: -0.118873
Regressor Loss: -0.1189
Domain Loss: 0.0002
Train Epoch: 2 [6972/10752 (65%)]	 Regressor Loss: -0.434590
Regressor Loss: -0.4346
Domain Loss: 0.0002
Train Epoch: 2 [7092/10752 (66%)]	 Regressor Loss: -0.149108
Regressor Loss: -0.1491
Domain Loss: 0.0000
Train Epoch: 2 [7212/10752 (67%)]	 Regressor Loss: -0.373793
Regressor Loss: -0.3738
Domain Loss: 0.0002
Train Epoch: 2 [7332/10752 (68%)]	 Regressor Loss: -0.105667
Regressor Loss: -0.1057
Domain Loss: 0.0002
Train Epoch: 2 [7452/10752 (69%)]	 Regressor Loss: -0.260472
Regressor Loss: -0.2605
Domain Loss: 0.0000
Train Epoch: 2 [7572/10752 (70%)]	 Regressor Loss: -0.122851
Regressor Loss: -0.1229
Domain Loss: 0.0000
Train Epoch: 2 [7692/10752 (72%)]	 Regressor Loss: -0.161039
Regressor Loss: -0.1610
Domain Loss: 0.0002
Train Epoch: 2 [7812/10752 (73%)]	 Regressor Loss: -0.211245
Regressor Loss: -0.2112
Domain Loss: 0.0002
Train Epoch: 2 [7932/10752 (74%)]	 Regressor Loss: -0.154296
Regressor Loss: -0.1543
Domain Loss: 0.0004
Train Epoch: 2 [8052/10752 (75%)]	 Regressor Loss: -0.222135
Regressor Loss: -0.2221
Domain Loss: 0.0002
Train Epoch: 2 [8172/10752 (76%)]	 Regressor Loss: -0.148810
Regressor Loss: -0.1488
Domain Loss: 0.0017
Train Epoch: 2 [8292/10752 (77%)]	 Regressor Loss: -0.208403
Regressor Loss: -0.2084
Domain Loss: 0.0002
Train Epoch: 2 [8412/10752 (78%)]	 Regressor Loss: -0.092012
Regressor Loss: -0.0920
Domain Loss: 0.0001
Train Epoch: 2 [8532/10752 (79%)]	 Regressor Loss: -0.231040
Regressor Loss: -0.2310
Domain Loss: 0.0001
Train Epoch: 2 [8652/10752 (80%)]	 Regressor Loss: -0.210155
Regressor Loss: -0.2102
Domain Loss: 0.0003
Train Epoch: 2 [8772/10752 (82%)]	 Regressor Loss: -0.260996
Regressor Loss: -0.2610
Domain Loss: 0.0011
Train Epoch: 2 [8892/10752 (83%)]	 Regressor Loss: -0.158568
Regressor Loss: -0.1586
Domain Loss: 0.0001
Train Epoch: 2 [9012/10752 (84%)]	 Regressor Loss: -0.391861
Regressor Loss: -0.3919
Domain Loss: 0.0005
Train Epoch: 2 [9132/10752 (85%)]	 Regressor Loss: -0.136056
Regressor Loss: -0.1361
Domain Loss: 0.0002
Train Epoch: 2 [9252/10752 (86%)]	 Regressor Loss: -0.278196
Regressor Loss: -0.2782
Domain Loss: 0.0001
Train Epoch: 2 [9372/10752 (87%)]	 Regressor Loss: -0.090052
Regressor Loss: -0.0901
Domain Loss: 0.0004
Training set: Average loss: -0.2140
Training set: Average Domain loss: 0.0006
Training set: Average Acc: 1.0000
Validation set: Average loss: -0.2201
Validation set: Average Domain loss: 0.0120
 Validation set: Average Acc: 0.9925
Training Main Encoder
Epoch  3 / 300
Train Epoch: 3 [12/10752 (0%)]	 Regressor Loss: -0.265566
Regressor Loss: -0.2656
Domain Loss: 0.0002
Train Epoch: 3 [132/10752 (1%)]	 Regressor Loss: -0.181230
Regressor Loss: -0.1812
Domain Loss: 0.0004
Train Epoch: 3 [252/10752 (2%)]	 Regressor Loss: -0.445440
Regressor Loss: -0.4454
Domain Loss: 0.0004
Train Epoch: 3 [372/10752 (3%)]	 Regressor Loss: -0.095094
Regressor Loss: -0.0951
Domain Loss: 0.0002
Train Epoch: 3 [492/10752 (5%)]	 Regressor Loss: -0.429913
Regressor Loss: -0.4299
Domain Loss: 0.0006
Train Epoch: 3 [612/10752 (6%)]	 Regressor Loss: -0.229204
Regressor Loss: -0.2292
Domain Loss: 0.0004
Train Epoch: 3 [732/10752 (7%)]	 Regressor Loss: -0.383241
Regressor Loss: -0.3832
Domain Loss: 0.0004
Train Epoch: 3 [852/10752 (8%)]	 Regressor Loss: -0.219237
Regressor Loss: -0.2192
Domain Loss: 0.0000
Train Epoch: 3 [972/10752 (9%)]	 Regressor Loss: -0.247817
Regressor Loss: -0.2478
Domain Loss: 0.0001
Train Epoch: 3 [1092/10752 (10%)]	 Regressor Loss: -0.154413
Regressor Loss: -0.1544
Domain Loss: 0.0003
Train Epoch: 3 [1212/10752 (11%)]	 Regressor Loss: -0.029463
Regressor Loss: -0.0295
Domain Loss: 0.0008
Train Epoch: 3 [1332/10752 (12%)]	 Regressor Loss: -0.098614
Regressor Loss: -0.0986
Domain Loss: 0.0006
Train Epoch: 3 [1452/10752 (14%)]	 Regressor Loss: -0.134333
Regressor Loss: -0.1343
Domain Loss: 0.0005
Train Epoch: 3 [1572/10752 (15%)]	 Regressor Loss: -0.159307
Regressor Loss: -0.1593
Domain Loss: 0.0002
Train Epoch: 3 [1692/10752 (16%)]	 Regressor Loss: -0.189015
Regressor Loss: -0.1890
Domain Loss: 0.0001
Train Epoch: 3 [1812/10752 (17%)]	 Regressor Loss: -0.255960
Regressor Loss: -0.2560
Domain Loss: 0.0001
Train Epoch: 3 [1932/10752 (18%)]	 Regressor Loss: -0.132029
Regressor Loss: -0.1320
Domain Loss: 0.0000
Train Epoch: 3 [2052/10752 (19%)]	 Regressor Loss: -0.333279
Regressor Loss: -0.3333
Domain Loss: 0.0002
Train Epoch: 3 [2172/10752 (20%)]	 Regressor Loss: -0.121695
Regressor Loss: -0.1217
Domain Loss: 0.0001
Train Epoch: 3 [2292/10752 (21%)]	 Regressor Loss: -0.300273
Regressor Loss: -0.3003
Domain Loss: 0.0000
Train Epoch: 3 [2412/10752 (22%)]	 Regressor Loss: -0.111257
Regressor Loss: -0.1113
Domain Loss: 0.0002
Train Epoch: 3 [2532/10752 (24%)]	 Regressor Loss: -0.324788
Regressor Loss: -0.3248
Domain Loss: 0.0003
Train Epoch: 3 [2652/10752 (25%)]	 Regressor Loss: -0.237036
Regressor Loss: -0.2370
Domain Loss: 0.0000
Train Epoch: 3 [2772/10752 (26%)]	 Regressor Loss: -0.400284
Regressor Loss: -0.4003
Domain Loss: 0.0002
Train Epoch: 3 [2892/10752 (27%)]	 Regressor Loss: -0.153644
Regressor Loss: -0.1536
Domain Loss: 0.0001
Train Epoch: 3 [3012/10752 (28%)]	 Regressor Loss: -0.320393
Regressor Loss: -0.3204
Domain Loss: 0.0000
Train Epoch: 3 [3132/10752 (29%)]	 Regressor Loss: -0.109120
Regressor Loss: -0.1091
Domain Loss: 0.0000
Train Epoch: 3 [3252/10752 (30%)]	 Regressor Loss: -0.423624
Regressor Loss: -0.4236
Domain Loss: 0.0003
Train Epoch: 3 [3372/10752 (31%)]	 Regressor Loss: -0.122662
Regressor Loss: -0.1227
Domain Loss: 0.0050
Train Epoch: 3 [3492/10752 (32%)]	 Regressor Loss: -0.399612
Regressor Loss: -0.3996
Domain Loss: 0.0000
Train Epoch: 3 [3612/10752 (34%)]	 Regressor Loss: -0.175786
Regressor Loss: -0.1758
Domain Loss: 0.0003
Train Epoch: 3 [3732/10752 (35%)]	 Regressor Loss: -0.364870
Regressor Loss: -0.3649
Domain Loss: 0.0001
Train Epoch: 3 [3852/10752 (36%)]	 Regressor Loss: -0.212453
Regressor Loss: -0.2125
Domain Loss: 0.0000
Train Epoch: 3 [3972/10752 (37%)]	 Regressor Loss: -0.371196
Regressor Loss: -0.3712
Domain Loss: 0.0002
Train Epoch: 3 [4092/10752 (38%)]	 Regressor Loss: -0.175242
Regressor Loss: -0.1752
Domain Loss: 0.0001
Train Epoch: 3 [4212/10752 (39%)]	 Regressor Loss: -0.183495
Regressor Loss: -0.1835
Domain Loss: 0.0003
Train Epoch: 3 [4332/10752 (40%)]	 Regressor Loss: -0.134454
Regressor Loss: -0.1345
Domain Loss: 0.0001
Train Epoch: 3 [4452/10752 (41%)]	 Regressor Loss: -0.162499
Regressor Loss: -0.1625
Domain Loss: 0.0001
Train Epoch: 3 [4572/10752 (43%)]	 Regressor Loss: -0.204942
Regressor Loss: -0.2049
Domain Loss: 0.0000
Train Epoch: 3 [4692/10752 (44%)]	 Regressor Loss: -0.091725
Regressor Loss: -0.0917
Domain Loss: 0.0002
Train Epoch: 3 [4812/10752 (45%)]	 Regressor Loss: -0.138715
Regressor Loss: -0.1387
Domain Loss: 0.0001
Train Epoch: 3 [4932/10752 (46%)]	 Regressor Loss: -0.192993
Regressor Loss: -0.1930
Domain Loss: 0.0001
Train Epoch: 3 [5052/10752 (47%)]	 Regressor Loss: -0.208044
Regressor Loss: -0.2080
Domain Loss: 0.0001
Train Epoch: 3 [5172/10752 (48%)]	 Regressor Loss: -0.121824
Regressor Loss: -0.1218
Domain Loss: 0.0000
Train Epoch: 3 [5292/10752 (49%)]	 Regressor Loss: -0.320696
Regressor Loss: -0.3207
Domain Loss: 0.0000
Train Epoch: 3 [5412/10752 (50%)]	 Regressor Loss: -0.118228
Regressor Loss: -0.1182
Domain Loss: 0.0006
Train Epoch: 3 [5532/10752 (51%)]	 Regressor Loss: -0.374072
Regressor Loss: -0.3741
Domain Loss: 0.0000
Train Epoch: 3 [5652/10752 (53%)]	 Regressor Loss: -0.156466
Regressor Loss: -0.1565
Domain Loss: 0.0000
Train Epoch: 3 [5772/10752 (54%)]	 Regressor Loss: -0.317068
Regressor Loss: -0.3171
Domain Loss: 0.0001
Train Epoch: 3 [5892/10752 (55%)]	 Regressor Loss: -0.165155
Regressor Loss: -0.1652
Domain Loss: 0.0007
Train Epoch: 3 [6012/10752 (56%)]	 Regressor Loss: -0.416808
Regressor Loss: -0.4168
Domain Loss: 0.0001
Train Epoch: 3 [6132/10752 (57%)]	 Regressor Loss: -0.139165
Regressor Loss: -0.1392
Domain Loss: 0.0000
Train Epoch: 3 [6252/10752 (58%)]	 Regressor Loss: -0.393144
Regressor Loss: -0.3931
Domain Loss: 0.0003
Train Epoch: 3 [6372/10752 (59%)]	 Regressor Loss: -0.125303
Regressor Loss: -0.1253
Domain Loss: 0.0005
Train Epoch: 3 [6492/10752 (60%)]	 Regressor Loss: -0.248999
Regressor Loss: -0.2490
Domain Loss: 0.0016
Train Epoch: 3 [6612/10752 (61%)]	 Regressor Loss: -0.170857
Regressor Loss: -0.1709
Domain Loss: 0.0001
Train Epoch: 3 [6732/10752 (63%)]	 Regressor Loss: -0.342359
Regressor Loss: -0.3424
Domain Loss: 0.0000
Train Epoch: 3 [6852/10752 (64%)]	 Regressor Loss: -0.123589
Regressor Loss: -0.1236
Domain Loss: 0.0000
Train Epoch: 3 [6972/10752 (65%)]	 Regressor Loss: -0.429522
Regressor Loss: -0.4295
Domain Loss: 0.0001
Train Epoch: 3 [7092/10752 (66%)]	 Regressor Loss: -0.065548
Regressor Loss: -0.0655
Domain Loss: 0.0000
Train Epoch: 3 [7212/10752 (67%)]	 Regressor Loss: -0.314623
Regressor Loss: -0.3146
Domain Loss: 0.0001
Train Epoch: 3 [7332/10752 (68%)]	 Regressor Loss: -0.237177
Regressor Loss: -0.2372
Domain Loss: 0.0001
Train Epoch: 3 [7452/10752 (69%)]	 Regressor Loss: -0.285736
Regressor Loss: -0.2857
Domain Loss: 0.0001
Train Epoch: 3 [7572/10752 (70%)]	 Regressor Loss: -0.145025
Regressor Loss: -0.1450
Domain Loss: 0.0001
Train Epoch: 3 [7692/10752 (72%)]	 Regressor Loss: -0.185199
Regressor Loss: -0.1852
Domain Loss: 0.0001
Train Epoch: 3 [7812/10752 (73%)]	 Regressor Loss: -0.175517
Regressor Loss: -0.1755
Domain Loss: 0.0001
Train Epoch: 3 [7932/10752 (74%)]	 Regressor Loss: -0.236147
Regressor Loss: -0.2361
Domain Loss: 0.0000
Train Epoch: 3 [8052/10752 (75%)]	 Regressor Loss: -0.145808
Regressor Loss: -0.1458
Domain Loss: 0.0001
Train Epoch: 3 [8172/10752 (76%)]	 Regressor Loss: -0.191588
Regressor Loss: -0.1916
Domain Loss: 0.0002
Train Epoch: 3 [8292/10752 (77%)]	 Regressor Loss: -0.289814
Regressor Loss: -0.2898
Domain Loss: 0.0001
Train Epoch: 3 [8412/10752 (78%)]	 Regressor Loss: -0.128801
Regressor Loss: -0.1288
Domain Loss: 0.0000
Train Epoch: 3 [8532/10752 (79%)]	 Regressor Loss: -0.329091
Regressor Loss: -0.3291
Domain Loss: 0.0001
Train Epoch: 3 [8652/10752 (80%)]	 Regressor Loss: -0.301090
Regressor Loss: -0.3011
Domain Loss: 0.0001
Train Epoch: 3 [8772/10752 (82%)]	 Regressor Loss: -0.377643
Regressor Loss: -0.3776
Domain Loss: 0.0005
Train Epoch: 3 [8892/10752 (83%)]	 Regressor Loss: -0.132259
Regressor Loss: -0.1323
Domain Loss: 0.0000
Train Epoch: 3 [9012/10752 (84%)]	 Regressor Loss: -0.438529
Regressor Loss: -0.4385
Domain Loss: 0.0003
Train Epoch: 3 [9132/10752 (85%)]	 Regressor Loss: -0.126552
Regressor Loss: -0.1266
Domain Loss: 0.0003
Train Epoch: 3 [9252/10752 (86%)]	 Regressor Loss: -0.392237
Regressor Loss: -0.3922
Domain Loss: 0.0004
Train Epoch: 3 [9372/10752 (87%)]	 Regressor Loss: -0.135175
Regressor Loss: -0.1352
Domain Loss: 0.0006
Training set: Average loss: -0.2246
Training set: Average Domain loss: 0.0002
Training set: Average Acc: 1.0000
Validation set: Average loss: -0.2276
Validation set: Average Domain loss: 0.0007
 Validation set: Average Acc: 1.0000
Training Main Encoder
Epoch  4 / 300
Train Epoch: 4 [12/10752 (0%)]	 Regressor Loss: -0.151698
Regressor Loss: -0.1517
Domain Loss: 0.0000
Train Epoch: 4 [132/10752 (1%)]	 Regressor Loss: -0.053789
Regressor Loss: -0.0538
Domain Loss: 0.0001
Train Epoch: 4 [252/10752 (2%)]	 Regressor Loss: -0.307319
Regressor Loss: -0.3073
Domain Loss: 0.0000
Train Epoch: 4 [372/10752 (3%)]	 Regressor Loss: -0.178335
Regressor Loss: -0.1783
Domain Loss: 0.0000
Train Epoch: 4 [492/10752 (5%)]	 Regressor Loss: -0.322344
Regressor Loss: -0.3223
Domain Loss: 0.0006
Train Epoch: 4 [612/10752 (6%)]	 Regressor Loss: -0.151981
Regressor Loss: -0.1520
Domain Loss: 0.0000
Train Epoch: 4 [732/10752 (7%)]	 Regressor Loss: -0.426958
Regressor Loss: -0.4270
Domain Loss: 0.0002
Train Epoch: 4 [852/10752 (8%)]	 Regressor Loss: -0.109114
Regressor Loss: -0.1091
Domain Loss: 0.0000
Train Epoch: 4 [972/10752 (9%)]	 Regressor Loss: -0.173165
Regressor Loss: -0.1732
Domain Loss: 0.0007
Train Epoch: 4 [1092/10752 (10%)]	 Regressor Loss: -0.181737
Regressor Loss: -0.1817
Domain Loss: 0.0001
Train Epoch: 4 [1212/10752 (11%)]	 Regressor Loss: -0.249423
Regressor Loss: -0.2494
Domain Loss: 0.0003
Train Epoch: 4 [1332/10752 (12%)]	 Regressor Loss: -0.249734
Regressor Loss: -0.2497
Domain Loss: 0.0001
Train Epoch: 4 [1452/10752 (14%)]	 Regressor Loss: -0.104787
Regressor Loss: -0.1048
Domain Loss: 0.0001
Train Epoch: 4 [1572/10752 (15%)]	 Regressor Loss: -0.210610
Regressor Loss: -0.2106
Domain Loss: 0.0003
Train Epoch: 4 [1692/10752 (16%)]	 Regressor Loss: -0.122249
Regressor Loss: -0.1222
Domain Loss: 0.0002
Train Epoch: 4 [1812/10752 (17%)]	 Regressor Loss: -0.207084
Regressor Loss: -0.2071
Domain Loss: 0.0002
Train Epoch: 4 [1932/10752 (18%)]	 Regressor Loss: -0.073112
Regressor Loss: -0.0731
Domain Loss: 0.0000
Train Epoch: 4 [2052/10752 (19%)]	 Regressor Loss: -0.338144
Regressor Loss: -0.3381
Domain Loss: 0.0000
Train Epoch: 4 [2172/10752 (20%)]	 Regressor Loss: -0.055555
Regressor Loss: -0.0556
Domain Loss: 0.0001
Train Epoch: 4 [2292/10752 (21%)]	 Regressor Loss: -0.418104
Regressor Loss: -0.4181
Domain Loss: 0.0001
Train Epoch: 4 [2412/10752 (22%)]	 Regressor Loss: -0.140886
Regressor Loss: -0.1409
Domain Loss: 0.0001
Train Epoch: 4 [2532/10752 (24%)]	 Regressor Loss: -0.338166
Regressor Loss: -0.3382
Domain Loss: 0.0004
Train Epoch: 4 [2652/10752 (25%)]	 Regressor Loss: -0.147550
Regressor Loss: -0.1476
Domain Loss: 0.0001
Train Epoch: 4 [2772/10752 (26%)]	 Regressor Loss: -0.386105
Regressor Loss: -0.3861
Domain Loss: 0.0003
Train Epoch: 4 [2892/10752 (27%)]	 Regressor Loss: -0.156458
Regressor Loss: -0.1565
Domain Loss: 0.0000
Train Epoch: 4 [3012/10752 (28%)]	 Regressor Loss: -0.410379
Regressor Loss: -0.4104
Domain Loss: 0.0005
Train Epoch: 4 [3132/10752 (29%)]	 Regressor Loss: -0.150687
Regressor Loss: -0.1507
Domain Loss: 0.0000
Train Epoch: 4 [3252/10752 (30%)]	 Regressor Loss: -0.312303
Regressor Loss: -0.3123
Domain Loss: 0.0007
Train Epoch: 4 [3372/10752 (31%)]	 Regressor Loss: -0.153177
Regressor Loss: -0.1532
Domain Loss: 0.0000
Train Epoch: 4 [3492/10752 (32%)]	 Regressor Loss: -0.401839
Regressor Loss: -0.4018
Domain Loss: 0.0001
Train Epoch: 4 [3612/10752 (34%)]	 Regressor Loss: -0.288383
Regressor Loss: -0.2884
Domain Loss: 0.0000
Train Epoch: 4 [3732/10752 (35%)]	 Regressor Loss: -0.406358
Regressor Loss: -0.4064
Domain Loss: 0.0000
Train Epoch: 4 [3852/10752 (36%)]	 Regressor Loss: -0.095672
Regressor Loss: -0.0957
Domain Loss: 0.0000
Train Epoch: 4 [3972/10752 (37%)]	 Regressor Loss: -0.365452
Regressor Loss: -0.3655
Domain Loss: 0.0001
Train Epoch: 4 [4092/10752 (38%)]	 Regressor Loss: -0.078495
Regressor Loss: -0.0785
Domain Loss: 0.0009
Train Epoch: 4 [4212/10752 (39%)]	 Regressor Loss: -0.258081
Regressor Loss: -0.2581
Domain Loss: 0.0003
Train Epoch: 4 [4332/10752 (40%)]	 Regressor Loss: -0.085543
Regressor Loss: -0.0855
Domain Loss: 0.0002
Train Epoch: 4 [4452/10752 (41%)]	 Regressor Loss: -0.202057
Regressor Loss: -0.2021
Domain Loss: 0.0004
Train Epoch: 4 [4572/10752 (43%)]	 Regressor Loss: -0.112710
Regressor Loss: -0.1127
Domain Loss: 0.0006
Train Epoch: 4 [4692/10752 (44%)]	 Regressor Loss: -0.104514
Regressor Loss: -0.1045
Domain Loss: 0.0001
Train Epoch: 4 [4812/10752 (45%)]	 Regressor Loss: -0.198438
Regressor Loss: -0.1984
Domain Loss: 0.0003
Train Epoch: 4 [4932/10752 (46%)]	 Regressor Loss: -0.138433
Regressor Loss: -0.1384
Domain Loss: 0.0001
Train Epoch: 4 [5052/10752 (47%)]	 Regressor Loss: -0.170679
Regressor Loss: -0.1707
Domain Loss: 0.0004
Train Epoch: 4 [5172/10752 (48%)]	 Regressor Loss: -0.119604
Regressor Loss: -0.1196
Domain Loss: 0.0000
Train Epoch: 4 [5292/10752 (49%)]	 Regressor Loss: -0.283954
Regressor Loss: -0.2840
Domain Loss: 0.0001
Train Epoch: 4 [5412/10752 (50%)]	 Regressor Loss: -0.171393
Regressor Loss: -0.1714
Domain Loss: 0.0001
Train Epoch: 4 [5532/10752 (51%)]	 Regressor Loss: -0.402634
Regressor Loss: -0.4026
Domain Loss: 0.0000
Train Epoch: 4 [5652/10752 (53%)]	 Regressor Loss: -0.218188
Regressor Loss: -0.2182
Domain Loss: 0.0000
Train Epoch: 4 [5772/10752 (54%)]	 Regressor Loss: -0.469657
Regressor Loss: -0.4697
Domain Loss: 0.0012
Train Epoch: 4 [5892/10752 (55%)]	 Regressor Loss: -0.131830
Regressor Loss: -0.1318
Domain Loss: 0.0001
Train Epoch: 4 [6012/10752 (56%)]	 Regressor Loss: -0.364269
Regressor Loss: -0.3643
Domain Loss: 0.0001
Train Epoch: 4 [6132/10752 (57%)]	 Regressor Loss: -0.246255
Regressor Loss: -0.2463
Domain Loss: 0.0000
Train Epoch: 4 [6252/10752 (58%)]	 Regressor Loss: -0.417077
Regressor Loss: -0.4171
Domain Loss: 0.0005
Train Epoch: 4 [6372/10752 (59%)]	 Regressor Loss: -0.078286
Regressor Loss: -0.0783
Domain Loss: 0.0001
Train Epoch: 4 [6492/10752 (60%)]	 Regressor Loss: -0.410613
Regressor Loss: -0.4106
Domain Loss: 0.0000
Train Epoch: 4 [6612/10752 (61%)]	 Regressor Loss: -0.178894
Regressor Loss: -0.1789
Domain Loss: 0.0000
Train Epoch: 4 [6732/10752 (63%)]	 Regressor Loss: -0.307302
Regressor Loss: -0.3073
Domain Loss: 0.0002
Train Epoch: 4 [6852/10752 (64%)]	 Regressor Loss: -0.098702
Regressor Loss: -0.0987
Domain Loss: 0.0000
Train Epoch: 4 [6972/10752 (65%)]	 Regressor Loss: -0.482480
Regressor Loss: -0.4825
Domain Loss: 0.0000
Train Epoch: 4 [7092/10752 (66%)]	 Regressor Loss: -0.091612
Regressor Loss: -0.0916
Domain Loss: 0.0000
Train Epoch: 4 [7212/10752 (67%)]	 Regressor Loss: -0.324921
Regressor Loss: -0.3249
Domain Loss: 0.0002
Train Epoch: 4 [7332/10752 (68%)]	 Regressor Loss: -0.229234
Regressor Loss: -0.2292
Domain Loss: 0.0000
Train Epoch: 4 [7452/10752 (69%)]	 Regressor Loss: -0.342528
Regressor Loss: -0.3425
Domain Loss: 0.0000
Train Epoch: 4 [7572/10752 (70%)]	 Regressor Loss: -0.202937
Regressor Loss: -0.2029
Domain Loss: 0.0001
Train Epoch: 4 [7692/10752 (72%)]	 Regressor Loss: -0.172026
Regressor Loss: -0.1720
Domain Loss: 0.0003
Train Epoch: 4 [7812/10752 (73%)]	 Regressor Loss: -0.201341
Regressor Loss: -0.2013
Domain Loss: 0.0000
Train Epoch: 4 [7932/10752 (74%)]	 Regressor Loss: -0.154852
Regressor Loss: -0.1549
Domain Loss: 0.0004
Train Epoch: 4 [8052/10752 (75%)]	 Regressor Loss: -0.269782
Regressor Loss: -0.2698
Domain Loss: 0.0001
Train Epoch: 4 [8172/10752 (76%)]	 Regressor Loss: -0.253669
Regressor Loss: -0.2537
Domain Loss: 0.0001
Train Epoch: 4 [8292/10752 (77%)]	 Regressor Loss: -0.309429
Regressor Loss: -0.3094
Domain Loss: 0.0004
Train Epoch: 4 [8412/10752 (78%)]	 Regressor Loss: -0.050253
Regressor Loss: -0.0503
Domain Loss: 0.0007
Train Epoch: 4 [8532/10752 (79%)]	 Regressor Loss: -0.328797
Regressor Loss: -0.3288
Domain Loss: 0.0001
Train Epoch: 4 [8652/10752 (80%)]	 Regressor Loss: -0.258223
Regressor Loss: -0.2582
Domain Loss: 0.0008
Train Epoch: 4 [8772/10752 (82%)]	 Regressor Loss: -0.303027
Regressor Loss: -0.3030
Domain Loss: 0.0003
Train Epoch: 4 [8892/10752 (83%)]	 Regressor Loss: -0.224719
Regressor Loss: -0.2247
Domain Loss: 0.0001
Train Epoch: 4 [9012/10752 (84%)]	 Regressor Loss: -0.446212
Regressor Loss: -0.4462
Domain Loss: 0.0001
Train Epoch: 4 [9132/10752 (85%)]	 Regressor Loss: -0.127517
Regressor Loss: -0.1275
Domain Loss: 0.0003
Train Epoch: 4 [9252/10752 (86%)]	 Regressor Loss: -0.377719
Regressor Loss: -0.3777
Domain Loss: 0.0001
Train Epoch: 4 [9372/10752 (87%)]	 Regressor Loss: -0.091738
Regressor Loss: -0.0917
Domain Loss: 0.0000
Training set: Average loss: -0.2391
Training set: Average Domain loss: 0.0003
Training set: Average Acc: 1.0000
Validation set: Average loss: -0.2504
Validation set: Average Domain loss: 0.0003
 Validation set: Average Acc: 1.0000
Training Main Encoder
Epoch  5 / 300
Train Epoch: 5 [12/10752 (0%)]	 Regressor Loss: -0.260148
Regressor Loss: -0.2601
Domain Loss: 0.0000
Train Epoch: 5 [132/10752 (1%)]	 Regressor Loss: -0.143385
Regressor Loss: -0.1434
Domain Loss: 0.0000
Train Epoch: 5 [252/10752 (2%)]	 Regressor Loss: -0.467719
Regressor Loss: -0.4677
Domain Loss: 0.0009
Train Epoch: 5 [372/10752 (3%)]	 Regressor Loss: -0.169035
Regressor Loss: -0.1690
Domain Loss: 0.0002
Train Epoch: 5 [492/10752 (5%)]	 Regressor Loss: -0.437960
Regressor Loss: -0.4380
Domain Loss: 0.0000
Train Epoch: 5 [612/10752 (6%)]	 Regressor Loss: -0.139897
Regressor Loss: -0.1399
Domain Loss: 0.0000
Train Epoch: 5 [732/10752 (7%)]	 Regressor Loss: -0.435022
Regressor Loss: -0.4350
Domain Loss: 0.0003
Train Epoch: 5 [852/10752 (8%)]	 Regressor Loss: -0.178865
Regressor Loss: -0.1789
Domain Loss: 0.0000
Train Epoch: 5 [972/10752 (9%)]	 Regressor Loss: -0.109745
Regressor Loss: -0.1097
Domain Loss: 0.0006
Train Epoch: 5 [1092/10752 (10%)]	 Regressor Loss: -0.160392
Regressor Loss: -0.1604
Domain Loss: 0.0006
Train Epoch: 5 [1212/10752 (11%)]	 Regressor Loss: -0.247768
Regressor Loss: -0.2478
Domain Loss: 0.0004
Train Epoch: 5 [1332/10752 (12%)]	 Regressor Loss: -0.092323
Regressor Loss: -0.0923
Domain Loss: 0.0001
Train Epoch: 5 [1452/10752 (14%)]	 Regressor Loss: -0.153414
Regressor Loss: -0.1534
Domain Loss: 0.0006
Train Epoch: 5 [1572/10752 (15%)]	 Regressor Loss: -0.236761
Regressor Loss: -0.2368
Domain Loss: 0.0003
Train Epoch: 5 [1692/10752 (16%)]	 Regressor Loss: -0.188174
Regressor Loss: -0.1882
Domain Loss: 0.0000
Train Epoch: 5 [1812/10752 (17%)]	 Regressor Loss: -0.333915
Regressor Loss: -0.3339
Domain Loss: 0.0000
Train Epoch: 5 [1932/10752 (18%)]	 Regressor Loss: -0.159716
Regressor Loss: -0.1597
Domain Loss: 0.0000
Train Epoch: 5 [2052/10752 (19%)]	 Regressor Loss: -0.418106
Regressor Loss: -0.4181
Domain Loss: 0.0001
Train Epoch: 5 [2172/10752 (20%)]	 Regressor Loss: -0.225507
Regressor Loss: -0.2255
Domain Loss: 0.0002
Train Epoch: 5 [2292/10752 (21%)]	 Regressor Loss: -0.437515
Regressor Loss: -0.4375
Domain Loss: 0.0000
Train Epoch: 5 [2412/10752 (22%)]	 Regressor Loss: -0.168026
Regressor Loss: -0.1680
Domain Loss: 0.0003
Train Epoch: 5 [2532/10752 (24%)]	 Regressor Loss: -0.143954
Regressor Loss: -0.1440
Domain Loss: 0.0000
Train Epoch: 5 [2652/10752 (25%)]	 Regressor Loss: -0.091896
Regressor Loss: -0.0919
Domain Loss: 0.0001
Train Epoch: 5 [2772/10752 (26%)]	 Regressor Loss: -0.441964
Regressor Loss: -0.4420
Domain Loss: 0.0003
Train Epoch: 5 [2892/10752 (27%)]	 Regressor Loss: -0.175948
Regressor Loss: -0.1759
Domain Loss: 0.0001
Train Epoch: 5 [3012/10752 (28%)]	 Regressor Loss: -0.424459
Regressor Loss: -0.4245
Domain Loss: 0.0000
Train Epoch: 5 [3132/10752 (29%)]	 Regressor Loss: -0.222731
Regressor Loss: -0.2227
Domain Loss: 0.0001
Train Epoch: 5 [3252/10752 (30%)]	 Regressor Loss: -0.310128
Regressor Loss: -0.3101
Domain Loss: 0.0001
Train Epoch: 5 [3372/10752 (31%)]	 Regressor Loss: -0.303605
Regressor Loss: -0.3036
Domain Loss: 0.0003
Train Epoch: 5 [3492/10752 (32%)]	 Regressor Loss: -0.467081
Regressor Loss: -0.4671
Domain Loss: 0.0000
Train Epoch: 5 [3612/10752 (34%)]	 Regressor Loss: -0.123354
Regressor Loss: -0.1234
Domain Loss: 0.0001
Train Epoch: 5 [3732/10752 (35%)]	 Regressor Loss: -0.521876
Regressor Loss: -0.5219
Domain Loss: 0.0000
Train Epoch: 5 [3852/10752 (36%)]	 Regressor Loss: -0.236957
Regressor Loss: -0.2370
Domain Loss: 0.0000
Train Epoch: 5 [3972/10752 (37%)]	 Regressor Loss: -0.395999
Regressor Loss: -0.3960
Domain Loss: 0.0000
Train Epoch: 5 [4092/10752 (38%)]	 Regressor Loss: -0.100270
Regressor Loss: -0.1003
Domain Loss: 0.0007
Train Epoch: 5 [4212/10752 (39%)]	 Regressor Loss: -0.325778
Regressor Loss: -0.3258
Domain Loss: 0.0008
Train Epoch: 5 [4332/10752 (40%)]	 Regressor Loss: -0.158454
Regressor Loss: -0.1585
Domain Loss: 0.0000
Train Epoch: 5 [4452/10752 (41%)]	 Regressor Loss: -0.245038
Regressor Loss: -0.2450
Domain Loss: 0.0001
Train Epoch: 5 [4572/10752 (43%)]	 Regressor Loss: -0.149551
Regressor Loss: -0.1496
Domain Loss: 0.0000
Train Epoch: 5 [4692/10752 (44%)]	 Regressor Loss: -0.143025
Regressor Loss: -0.1430
Domain Loss: 0.0002
Train Epoch: 5 [4812/10752 (45%)]	 Regressor Loss: -0.195111
Regressor Loss: -0.1951
Domain Loss: 0.0004
Train Epoch: 5 [4932/10752 (46%)]	 Regressor Loss: -0.291277
Regressor Loss: -0.2913
Domain Loss: 0.0001
Train Epoch: 5 [5052/10752 (47%)]	 Regressor Loss: -0.276212
Regressor Loss: -0.2762
Domain Loss: 0.0001
Train Epoch: 5 [5172/10752 (48%)]	 Regressor Loss: -0.269491
Regressor Loss: -0.2695
Domain Loss: 0.0000
Train Epoch: 5 [5292/10752 (49%)]	 Regressor Loss: -0.336803
Regressor Loss: -0.3368
Domain Loss: 0.0001
Train Epoch: 5 [5412/10752 (50%)]	 Regressor Loss: -0.233626
Regressor Loss: -0.2336
Domain Loss: 0.0000
Train Epoch: 5 [5532/10752 (51%)]	 Regressor Loss: -0.450809
Regressor Loss: -0.4508
Domain Loss: 0.0000
Train Epoch: 5 [5652/10752 (53%)]	 Regressor Loss: -0.215245
Regressor Loss: -0.2152
Domain Loss: 0.0000
Train Epoch: 5 [5772/10752 (54%)]	 Regressor Loss: -0.419345
Regressor Loss: -0.4193
Domain Loss: 0.0000
Train Epoch: 5 [5892/10752 (55%)]	 Regressor Loss: -0.107126
Regressor Loss: -0.1071
Domain Loss: 0.0001
Train Epoch: 5 [6012/10752 (56%)]	 Regressor Loss: -0.493471
Regressor Loss: -0.4935
Domain Loss: 0.0000
Train Epoch: 5 [6132/10752 (57%)]	 Regressor Loss: -0.284057
Regressor Loss: -0.2841
Domain Loss: 0.0004
Train Epoch: 5 [6252/10752 (58%)]	 Regressor Loss: -0.412842
Regressor Loss: -0.4128
Domain Loss: 0.0001
Train Epoch: 5 [6372/10752 (59%)]	 Regressor Loss: -0.224231
Regressor Loss: -0.2242
Domain Loss: 0.0001
Train Epoch: 5 [6492/10752 (60%)]	 Regressor Loss: -0.413224
Regressor Loss: -0.4132
Domain Loss: 0.0007
Train Epoch: 5 [6612/10752 (61%)]	 Regressor Loss: -0.120548
Regressor Loss: -0.1205
Domain Loss: 0.0001
Train Epoch: 5 [6732/10752 (63%)]	 Regressor Loss: -0.429966
Regressor Loss: -0.4300
Domain Loss: 0.0264
Train Epoch: 5 [6852/10752 (64%)]	 Regressor Loss: -0.141622
Regressor Loss: -0.1416
Domain Loss: 0.0001
Train Epoch: 5 [6972/10752 (65%)]	 Regressor Loss: -0.486244
Regressor Loss: -0.4862
Domain Loss: 0.0001
Train Epoch: 5 [7092/10752 (66%)]	 Regressor Loss: -0.193527
Regressor Loss: -0.1935
Domain Loss: 0.0000
Train Epoch: 5 [7212/10752 (67%)]	 Regressor Loss: -0.379785
Regressor Loss: -0.3798
Domain Loss: 0.0000
Train Epoch: 5 [7332/10752 (68%)]	 Regressor Loss: -0.000000
Regressor Loss: -0.0000
Domain Loss: 0.2143
Train Epoch: 5 [7452/10752 (69%)]	 Regressor Loss: -0.321612
Regressor Loss: -0.3216
Domain Loss: 0.0007
Train Epoch: 5 [7572/10752 (70%)]	 Regressor Loss: -0.091592
Regressor Loss: -0.0916
Domain Loss: 0.0002
Train Epoch: 5 [7692/10752 (72%)]	 Regressor Loss: -0.273622
Regressor Loss: -0.2736
Domain Loss: 0.0011
Train Epoch: 5 [7812/10752 (73%)]	 Regressor Loss: -0.182911
Regressor Loss: -0.1829
Domain Loss: 0.0001
Train Epoch: 5 [7932/10752 (74%)]	 Regressor Loss: -0.287668
Regressor Loss: -0.2877
Domain Loss: 0.0001
Train Epoch: 5 [8052/10752 (75%)]	 Regressor Loss: -0.218476
Regressor Loss: -0.2185
Domain Loss: 0.0003
Train Epoch: 5 [8172/10752 (76%)]	 Regressor Loss: -0.274419
Regressor Loss: -0.2744
Domain Loss: 0.0000
Train Epoch: 5 [8292/10752 (77%)]	 Regressor Loss: -0.311666
Regressor Loss: -0.3117
Domain Loss: 0.0004
Train Epoch: 5 [8412/10752 (78%)]	 Regressor Loss: -0.217418
Regressor Loss: -0.2174
Domain Loss: 0.0000
Train Epoch: 5 [8532/10752 (79%)]	 Regressor Loss: -0.429895
Regressor Loss: -0.4299
Domain Loss: 0.0001
Train Epoch: 5 [8652/10752 (80%)]	 Regressor Loss: -0.285538
Regressor Loss: -0.2855
Domain Loss: 0.0003
Train Epoch: 5 [8772/10752 (82%)]	 Regressor Loss: -0.431498
Regressor Loss: -0.4315
Domain Loss: 0.0001
Train Epoch: 5 [8892/10752 (83%)]	 Regressor Loss: -0.115247
Regressor Loss: -0.1152
Domain Loss: 0.0001
Train Epoch: 5 [9012/10752 (84%)]	 Regressor Loss: -0.496264
Regressor Loss: -0.4963
Domain Loss: 0.0001
Train Epoch: 5 [9132/10752 (85%)]	 Regressor Loss: -0.224576
Regressor Loss: -0.2246
Domain Loss: 0.0000
Train Epoch: 5 [9252/10752 (86%)]	 Regressor Loss: -0.471562
Regressor Loss: -0.4716
Domain Loss: 0.0002
Train Epoch: 5 [9372/10752 (87%)]	 Regressor Loss: -0.153177
Regressor Loss: -0.1532
Domain Loss: 0.0000
Training set: Average loss: -0.2694
Training set: Average Domain loss: 0.0006
Training set: Average Acc: 0.9999
Validation set: Average loss: -0.2679
Validation set: Average Domain loss: 0.0024
 Validation set: Average Acc: 0.9992
Training Main Encoder
Epoch  6 / 300
Train Epoch: 6 [12/10752 (0%)]	 Regressor Loss: -0.150480
Regressor Loss: -0.1505
Domain Loss: 0.0003
Train Epoch: 6 [132/10752 (1%)]	 Regressor Loss: -0.165183
Regressor Loss: -0.1652
Domain Loss: 0.0001
Train Epoch: 6 [252/10752 (2%)]	 Regressor Loss: -0.558117
Regressor Loss: -0.5581
Domain Loss: 0.0000
Train Epoch: 6 [372/10752 (3%)]	 Regressor Loss: -0.163706
Regressor Loss: -0.1637
Domain Loss: 0.0001
Train Epoch: 6 [492/10752 (5%)]	 Regressor Loss: -0.529237
Regressor Loss: -0.5292
Domain Loss: 0.0002
Train Epoch: 6 [612/10752 (6%)]	 Regressor Loss: -0.059383
Regressor Loss: -0.0594
Domain Loss: 0.0002
Train Epoch: 6 [732/10752 (7%)]	 Regressor Loss: -0.410369
Regressor Loss: -0.4104
Domain Loss: 0.0002
Train Epoch: 6 [852/10752 (8%)]	 Regressor Loss: -0.346579
Regressor Loss: -0.3466
Domain Loss: 0.0002
Train Epoch: 6 [972/10752 (9%)]	 Regressor Loss: -0.291683
Regressor Loss: -0.2917
Domain Loss: 0.0001
Train Epoch: 6 [1092/10752 (10%)]	 Regressor Loss: -0.128994
Regressor Loss: -0.1290
Domain Loss: 0.0001
Train Epoch: 6 [1212/10752 (11%)]	 Regressor Loss: -0.193191
Regressor Loss: -0.1932
Domain Loss: 0.0001
Train Epoch: 6 [1332/10752 (12%)]	 Regressor Loss: -0.345897
Regressor Loss: -0.3459
Domain Loss: 0.0001
Train Epoch: 6 [1452/10752 (14%)]	 Regressor Loss: -0.038826
Regressor Loss: -0.0388
Domain Loss: 0.0010
Train Epoch: 6 [1572/10752 (15%)]	 Regressor Loss: -0.226589
Regressor Loss: -0.2266
Domain Loss: 0.0001
Train Epoch: 6 [1692/10752 (16%)]	 Regressor Loss: -0.234618
Regressor Loss: -0.2346
Domain Loss: 0.0001
Train Epoch: 6 [1812/10752 (17%)]	 Regressor Loss: -0.294045
Regressor Loss: -0.2940
Domain Loss: 0.0001
Train Epoch: 6 [1932/10752 (18%)]	 Regressor Loss: -0.281545
Regressor Loss: -0.2815
Domain Loss: 0.0002
Train Epoch: 6 [2052/10752 (19%)]	 Regressor Loss: -0.505403
Regressor Loss: -0.5054
Domain Loss: 0.0001
Train Epoch: 6 [2172/10752 (20%)]	 Regressor Loss: -0.129908
Regressor Loss: -0.1299
Domain Loss: 0.0001
Train Epoch: 6 [2292/10752 (21%)]	 Regressor Loss: -0.491435
Regressor Loss: -0.4914
Domain Loss: 0.0000
Train Epoch: 6 [2412/10752 (22%)]	 Regressor Loss: -0.234353
Regressor Loss: -0.2344
Domain Loss: 0.0000
Train Epoch: 6 [2532/10752 (24%)]	 Regressor Loss: -0.417190
Regressor Loss: -0.4172
Domain Loss: 0.0000
Train Epoch: 6 [2652/10752 (25%)]	 Regressor Loss: -0.154531
Regressor Loss: -0.1545
Domain Loss: 0.0002
Train Epoch: 6 [2772/10752 (26%)]	 Regressor Loss: -0.545032
Regressor Loss: -0.5450
Domain Loss: 0.0002
Train Epoch: 6 [2892/10752 (27%)]	 Regressor Loss: -0.094391
Regressor Loss: -0.0944
Domain Loss: 0.0002
Train Epoch: 6 [3012/10752 (28%)]	 Regressor Loss: -0.454811
Regressor Loss: -0.4548
Domain Loss: 0.0000
Train Epoch: 6 [3132/10752 (29%)]	 Regressor Loss: -0.241558
Regressor Loss: -0.2416
Domain Loss: 0.0000
Train Epoch: 6 [3252/10752 (30%)]	 Regressor Loss: -0.461622
Regressor Loss: -0.4616
Domain Loss: 0.0001
Train Epoch: 6 [3372/10752 (31%)]	 Regressor Loss: -0.266692
Regressor Loss: -0.2667
Domain Loss: 0.0002
Train Epoch: 6 [3492/10752 (32%)]	 Regressor Loss: -0.538124
Regressor Loss: -0.5381
Domain Loss: 0.0001
Train Epoch: 6 [3612/10752 (34%)]	 Regressor Loss: -0.026467
Regressor Loss: -0.0265
Domain Loss: 0.0005
Train Epoch: 6 [3732/10752 (35%)]	 Regressor Loss: -0.453300
Regressor Loss: -0.4533
Domain Loss: 0.0001
Train Epoch: 6 [3852/10752 (36%)]	 Regressor Loss: -0.184202
Regressor Loss: -0.1842
Domain Loss: 0.0001
Train Epoch: 6 [3972/10752 (37%)]	 Regressor Loss: -0.398367
Regressor Loss: -0.3984
Domain Loss: 0.0000
Train Epoch: 6 [4092/10752 (38%)]	 Regressor Loss: -0.038861
Regressor Loss: -0.0389
Domain Loss: 0.0001
Train Epoch: 6 [4212/10752 (39%)]	 Regressor Loss: -0.391928
Regressor Loss: -0.3919
Domain Loss: 0.0002
Train Epoch: 6 [4332/10752 (40%)]	 Regressor Loss: -0.167526
Regressor Loss: -0.1675
Domain Loss: 0.0001
Train Epoch: 6 [4452/10752 (41%)]	 Regressor Loss: -0.207238
Regressor Loss: -0.2072
Domain Loss: 0.0002
Train Epoch: 6 [4572/10752 (43%)]	 Regressor Loss: -0.211132
Regressor Loss: -0.2111
Domain Loss: 0.0001
Train Epoch: 6 [4692/10752 (44%)]	 Regressor Loss: -0.089388
Regressor Loss: -0.0894
Domain Loss: 0.0052
Train Epoch: 6 [4812/10752 (45%)]	 Regressor Loss: -0.221225
Regressor Loss: -0.2212
Domain Loss: 0.0003
Train Epoch: 6 [4932/10752 (46%)]	 Regressor Loss: -0.197047
Regressor Loss: -0.1970
Domain Loss: 0.0001
Train Epoch: 6 [5052/10752 (47%)]	 Regressor Loss: -0.262543
Regressor Loss: -0.2625
Domain Loss: 0.0002
Train Epoch: 6 [5172/10752 (48%)]	 Regressor Loss: -0.163550
Regressor Loss: -0.1635
Domain Loss: 0.0022
Train Epoch: 6 [5292/10752 (49%)]	 Regressor Loss: -0.466582
Regressor Loss: -0.4666
Domain Loss: 0.0002
Train Epoch: 6 [5412/10752 (50%)]	 Regressor Loss: -0.316224
Regressor Loss: -0.3162
Domain Loss: 0.0000
Train Epoch: 6 [5532/10752 (51%)]	 Regressor Loss: -0.431766
Regressor Loss: -0.4318
Domain Loss: 0.0000
Train Epoch: 6 [5652/10752 (53%)]	 Regressor Loss: -0.258589
Regressor Loss: -0.2586
Domain Loss: 0.0002
Train Epoch: 6 [5772/10752 (54%)]	 Regressor Loss: -0.489461
Regressor Loss: -0.4895
Domain Loss: 0.0003
Train Epoch: 6 [5892/10752 (55%)]	 Regressor Loss: -0.209127
Regressor Loss: -0.2091
Domain Loss: 0.0002
Train Epoch: 6 [6012/10752 (56%)]	 Regressor Loss: -0.544420
Regressor Loss: -0.5444
Domain Loss: 0.0000
Train Epoch: 6 [6132/10752 (57%)]	 Regressor Loss: -0.291858
Regressor Loss: -0.2919
Domain Loss: 0.0000
Train Epoch: 6 [6252/10752 (58%)]	 Regressor Loss: -0.300431
Regressor Loss: -0.3004
Domain Loss: 0.0003
Train Epoch: 6 [6372/10752 (59%)]	 Regressor Loss: -0.174354
Regressor Loss: -0.1744
Domain Loss: 0.0016
Train Epoch: 6 [6492/10752 (60%)]	 Regressor Loss: -0.298306
Regressor Loss: -0.2983
Domain Loss: 0.0007
Train Epoch: 6 [6612/10752 (61%)]	 Regressor Loss: -0.177405
Regressor Loss: -0.1774
Domain Loss: 0.0004
Train Epoch: 6 [6732/10752 (63%)]	 Regressor Loss: -0.515012
Regressor Loss: -0.5150
Domain Loss: 0.0000
Train Epoch: 6 [6852/10752 (64%)]	 Regressor Loss: -0.172663
Regressor Loss: -0.1727
Domain Loss: 0.0000
Train Epoch: 6 [6972/10752 (65%)]	 Regressor Loss: -0.385650
Regressor Loss: -0.3856
Domain Loss: 0.0000
Train Epoch: 6 [7092/10752 (66%)]	 Regressor Loss: -0.176642
Regressor Loss: -0.1766
Domain Loss: 0.0001
Train Epoch: 6 [7212/10752 (67%)]	 Regressor Loss: -0.401891
Regressor Loss: -0.4019
Domain Loss: 0.0003
Train Epoch: 6 [7332/10752 (68%)]	 Regressor Loss: -0.184885
Regressor Loss: -0.1849
Domain Loss: 0.0000
Train Epoch: 6 [7452/10752 (69%)]	 Regressor Loss: -0.360004
Regressor Loss: -0.3600
Domain Loss: 0.0001
Train Epoch: 6 [7572/10752 (70%)]	 Regressor Loss: -0.115156
Regressor Loss: -0.1152
Domain Loss: 0.0001
Train Epoch: 6 [7692/10752 (72%)]	 Regressor Loss: -0.299702
Regressor Loss: -0.2997
Domain Loss: 0.0001
Train Epoch: 6 [7812/10752 (73%)]	 Regressor Loss: -0.103491
Regressor Loss: -0.1035
Domain Loss: 0.0004
Train Epoch: 6 [7932/10752 (74%)]	 Regressor Loss: -0.200561
Regressor Loss: -0.2006
Domain Loss: 0.0001
Train Epoch: 6 [8052/10752 (75%)]	 Regressor Loss: -0.290189
Regressor Loss: -0.2902
Domain Loss: 0.0001
Train Epoch: 6 [8172/10752 (76%)]	 Regressor Loss: -0.305112
Regressor Loss: -0.3051
Domain Loss: 0.0001
Train Epoch: 6 [8292/10752 (77%)]	 Regressor Loss: -0.193370
Regressor Loss: -0.1934
Domain Loss: 0.0000
Train Epoch: 6 [8412/10752 (78%)]	 Regressor Loss: -0.248649
Regressor Loss: -0.2486
Domain Loss: 0.0000
Train Epoch: 6 [8532/10752 (79%)]	 Regressor Loss: -0.356638
Regressor Loss: -0.3566
Domain Loss: 0.0001
Train Epoch: 6 [8652/10752 (80%)]	 Regressor Loss: -0.368357
Regressor Loss: -0.3684
Domain Loss: 0.0000
Train Epoch: 6 [8772/10752 (82%)]	 Regressor Loss: -0.423451
Regressor Loss: -0.4235
Domain Loss: 0.0002
Train Epoch: 6 [8892/10752 (83%)]	 Regressor Loss: -0.240785
Regressor Loss: -0.2408
Domain Loss: 0.0003
Train Epoch: 6 [9012/10752 (84%)]	 Regressor Loss: -0.537141
Regressor Loss: -0.5371
Domain Loss: 0.0035
Train Epoch: 6 [9132/10752 (85%)]	 Regressor Loss: -0.187745
Regressor Loss: -0.1877
Domain Loss: 0.0000
Train Epoch: 6 [9252/10752 (86%)]	 Regressor Loss: -0.395320
Regressor Loss: -0.3953
Domain Loss: 0.0000
Train Epoch: 6 [9372/10752 (87%)]	 Regressor Loss: -0.242882
Regressor Loss: -0.2429
Domain Loss: 0.0000
Training set: Average loss: -0.2868
Training set: Average Domain loss: 0.0004
Training set: Average Acc: 1.0000
Validation set: Average loss: -0.2946
Validation set: Average Domain loss: 0.0125
 Validation set: Average Acc: 0.9933
Training Main Encoder
Epoch  7 / 300
Train Epoch: 7 [12/10752 (0%)]	 Regressor Loss: -0.255943
Regressor Loss: -0.2559
Domain Loss: 0.0001
Train Epoch: 7 [132/10752 (1%)]	 Regressor Loss: -0.119120
Regressor Loss: -0.1191
Domain Loss: 0.0002
Train Epoch: 7 [252/10752 (2%)]	 Regressor Loss: -0.557794
Regressor Loss: -0.5578
Domain Loss: 0.0004
Train Epoch: 7 [372/10752 (3%)]	 Regressor Loss: -0.194855
Regressor Loss: -0.1949
Domain Loss: 0.0002
Train Epoch: 7 [492/10752 (5%)]	 Regressor Loss: -0.577109
Regressor Loss: -0.5771
Domain Loss: 0.0003
Train Epoch: 7 [612/10752 (6%)]	 Regressor Loss: -0.337510
Regressor Loss: -0.3375
Domain Loss: 0.0001
Train Epoch: 7 [732/10752 (7%)]	 Regressor Loss: -0.546756
Regressor Loss: -0.5468
Domain Loss: 0.0003
Train Epoch: 7 [852/10752 (8%)]	 Regressor Loss: -0.315534
Regressor Loss: -0.3155
Domain Loss: 0.0002
Train Epoch: 7 [972/10752 (9%)]	 Regressor Loss: -0.287377
Regressor Loss: -0.2874
Domain Loss: 0.0002
Train Epoch: 7 [1092/10752 (10%)]	 Regressor Loss: -0.114466
Regressor Loss: -0.1145
Domain Loss: 0.0000
Train Epoch: 7 [1212/10752 (11%)]	 Regressor Loss: -0.234396
Regressor Loss: -0.2344
Domain Loss: 0.0002
Train Epoch: 7 [1332/10752 (12%)]	 Regressor Loss: -0.184027
Regressor Loss: -0.1840
Domain Loss: 0.0001
Train Epoch: 7 [1452/10752 (14%)]	 Regressor Loss: -0.174002
Regressor Loss: -0.1740
Domain Loss: 0.0002
Train Epoch: 7 [1572/10752 (15%)]	 Regressor Loss: -0.301628
Regressor Loss: -0.3016
Domain Loss: 0.0120
Train Epoch: 7 [1692/10752 (16%)]	 Regressor Loss: -0.317856
Regressor Loss: -0.3179
Domain Loss: 0.0000
Train Epoch: 7 [1812/10752 (17%)]	 Regressor Loss: -0.327825
Regressor Loss: -0.3278
Domain Loss: 0.0001
Train Epoch: 7 [1932/10752 (18%)]	 Regressor Loss: -0.202224
Regressor Loss: -0.2022
Domain Loss: 0.0000
Train Epoch: 7 [2052/10752 (19%)]	 Regressor Loss: -0.445818
Regressor Loss: -0.4458
Domain Loss: 0.0009
Train Epoch: 7 [2172/10752 (20%)]	 Regressor Loss: -0.212167
Regressor Loss: -0.2122
Domain Loss: 0.0003
Train Epoch: 7 [2292/10752 (21%)]	 Regressor Loss: -0.442802
Regressor Loss: -0.4428
Domain Loss: 0.0000
Train Epoch: 7 [2412/10752 (22%)]	 Regressor Loss: -0.243211
Regressor Loss: -0.2432
Domain Loss: 0.0000
Train Epoch: 7 [2532/10752 (24%)]	 Regressor Loss: -0.479998
Regressor Loss: -0.4800
Domain Loss: 0.0000
Train Epoch: 7 [2652/10752 (25%)]	 Regressor Loss: -0.194565
Regressor Loss: -0.1946
Domain Loss: 0.0000
Train Epoch: 7 [2772/10752 (26%)]	 Regressor Loss: -0.518765
Regressor Loss: -0.5188
Domain Loss: 0.0000
Train Epoch: 7 [2892/10752 (27%)]	 Regressor Loss: -0.215559
Regressor Loss: -0.2156
Domain Loss: 0.0000
Train Epoch: 7 [3012/10752 (28%)]	 Regressor Loss: -0.603753
Regressor Loss: -0.6038
Domain Loss: 0.0000
Train Epoch: 7 [3132/10752 (29%)]	 Regressor Loss: -0.203671
Regressor Loss: -0.2037
Domain Loss: 0.0000
Train Epoch: 7 [3252/10752 (30%)]	 Regressor Loss: -0.480621
Regressor Loss: -0.4806
Domain Loss: 0.0000
Train Epoch: 7 [3372/10752 (31%)]	 Regressor Loss: -0.264855
Regressor Loss: -0.2649
Domain Loss: 0.0000
Train Epoch: 7 [3492/10752 (32%)]	 Regressor Loss: -0.481194
Regressor Loss: -0.4812
Domain Loss: 0.0000
Train Epoch: 7 [3612/10752 (34%)]	 Regressor Loss: -0.112241
Regressor Loss: -0.1122
Domain Loss: 0.0001
Train Epoch: 7 [3732/10752 (35%)]	 Regressor Loss: -0.460955
Regressor Loss: -0.4610
Domain Loss: 0.0000
Train Epoch: 7 [3852/10752 (36%)]	 Regressor Loss: -0.202542
Regressor Loss: -0.2025
Domain Loss: 0.0000
Train Epoch: 7 [3972/10752 (37%)]	 Regressor Loss: -0.494801
Regressor Loss: -0.4948
Domain Loss: 0.0000
Train Epoch: 7 [4092/10752 (38%)]	 Regressor Loss: -0.150312
Regressor Loss: -0.1503
Domain Loss: 0.0003
Train Epoch: 7 [4212/10752 (39%)]	 Regressor Loss: -0.287284
Regressor Loss: -0.2873
Domain Loss: 0.0000
Train Epoch: 7 [4332/10752 (40%)]	 Regressor Loss: -0.184360
Regressor Loss: -0.1844
Domain Loss: 0.0000
Train Epoch: 7 [4452/10752 (41%)]	 Regressor Loss: -0.222032
Regressor Loss: -0.2220
Domain Loss: 0.0000
Train Epoch: 7 [4572/10752 (43%)]	 Regressor Loss: -0.010710
Regressor Loss: -0.0107
Domain Loss: 0.0001
Train Epoch: 7 [4692/10752 (44%)]	 Regressor Loss: -0.118589
Regressor Loss: -0.1186
Domain Loss: 0.0000
Train Epoch: 7 [4812/10752 (45%)]	 Regressor Loss: -0.291285
Regressor Loss: -0.2913
Domain Loss: 0.0001
Train Epoch: 7 [4932/10752 (46%)]	 Regressor Loss: -0.102673
Regressor Loss: -0.1027
Domain Loss: 0.0000
Train Epoch: 7 [5052/10752 (47%)]	 Regressor Loss: -0.237595
Regressor Loss: -0.2376
Domain Loss: 0.0000
Train Epoch: 7 [5172/10752 (48%)]	 Regressor Loss: -0.265932
Regressor Loss: -0.2659
Domain Loss: 0.0000
Train Epoch: 7 [5292/10752 (49%)]	 Regressor Loss: -0.465079
Regressor Loss: -0.4651
Domain Loss: 0.0000
Train Epoch: 7 [5412/10752 (50%)]	 Regressor Loss: -0.197990
Regressor Loss: -0.1980
Domain Loss: 0.0000
Train Epoch: 7 [5532/10752 (51%)]	 Regressor Loss: -0.463807
Regressor Loss: -0.4638
Domain Loss: 0.0000
Train Epoch: 7 [5652/10752 (53%)]	 Regressor Loss: -0.206686
Regressor Loss: -0.2067
Domain Loss: 0.0000
Train Epoch: 7 [5772/10752 (54%)]	 Regressor Loss: -0.589899
Regressor Loss: -0.5899
Domain Loss: 0.0005
Train Epoch: 7 [5892/10752 (55%)]	 Regressor Loss: -0.211491
Regressor Loss: -0.2115
Domain Loss: 0.0000
Train Epoch: 7 [6012/10752 (56%)]	 Regressor Loss: -0.589714
Regressor Loss: -0.5897
Domain Loss: 0.0002
Train Epoch: 7 [6132/10752 (57%)]	 Regressor Loss: -0.183833
Regressor Loss: -0.1838
Domain Loss: 0.0000
Train Epoch: 7 [6252/10752 (58%)]	 Regressor Loss: -0.591175
Regressor Loss: -0.5912
Domain Loss: 0.0008
Train Epoch: 7 [6372/10752 (59%)]	 Regressor Loss: -0.202608
Regressor Loss: -0.2026
Domain Loss: 0.0000
Train Epoch: 7 [6492/10752 (60%)]	 Regressor Loss: -0.456432
Regressor Loss: -0.4564
Domain Loss: 0.0003
Train Epoch: 7 [6612/10752 (61%)]	 Regressor Loss: -0.178594
Regressor Loss: -0.1786
Domain Loss: 0.0000
Train Epoch: 7 [6732/10752 (63%)]	 Regressor Loss: -0.214481
Regressor Loss: -0.2145
Domain Loss: 0.0000
Train Epoch: 7 [6852/10752 (64%)]	 Regressor Loss: -0.218115
Regressor Loss: -0.2181
Domain Loss: 0.0001
Train Epoch: 7 [6972/10752 (65%)]	 Regressor Loss: -0.514136
Regressor Loss: -0.5141
Domain Loss: 0.0000
Train Epoch: 7 [7092/10752 (66%)]	 Regressor Loss: -0.207634
Regressor Loss: -0.2076
Domain Loss: 0.0001
Train Epoch: 7 [7212/10752 (67%)]	 Regressor Loss: -0.424309
Regressor Loss: -0.4243
Domain Loss: 0.0000
Train Epoch: 7 [7332/10752 (68%)]	 Regressor Loss: -0.128266
Regressor Loss: -0.1283
Domain Loss: 0.0000
Train Epoch: 7 [7452/10752 (69%)]	 Regressor Loss: -0.551395
Regressor Loss: -0.5514
Domain Loss: 0.0000
Train Epoch: 7 [7572/10752 (70%)]	 Regressor Loss: -0.199055
Regressor Loss: -0.1991
Domain Loss: 0.0001
Train Epoch: 7 [7692/10752 (72%)]	 Regressor Loss: -0.274397
Regressor Loss: -0.2744
Domain Loss: 0.0000
Train Epoch: 7 [7812/10752 (73%)]	 Regressor Loss: -0.271650
Regressor Loss: -0.2716
Domain Loss: 0.0006
Train Epoch: 7 [7932/10752 (74%)]	 Regressor Loss: -0.225447
Regressor Loss: -0.2254
Domain Loss: 0.0000
Train Epoch: 7 [8052/10752 (75%)]	 Regressor Loss: -0.360178
Regressor Loss: -0.3602
Domain Loss: 0.0000
Train Epoch: 7 [8172/10752 (76%)]	 Regressor Loss: -0.265087
Regressor Loss: -0.2651
Domain Loss: 0.0000
Train Epoch: 7 [8292/10752 (77%)]	 Regressor Loss: -0.331674
Regressor Loss: -0.3317
Domain Loss: 0.0000
Train Epoch: 7 [8412/10752 (78%)]	 Regressor Loss: -0.148223
Regressor Loss: -0.1482
Domain Loss: 0.0000
Train Epoch: 7 [8532/10752 (79%)]	 Regressor Loss: -0.382478
Regressor Loss: -0.3825
Domain Loss: 0.0000
Train Epoch: 7 [8652/10752 (80%)]	 Regressor Loss: -0.395597
Regressor Loss: -0.3956
Domain Loss: 0.0003
Train Epoch: 7 [8772/10752 (82%)]	 Regressor Loss: -0.453313
Regressor Loss: -0.4533
Domain Loss: 0.0006
Train Epoch: 7 [8892/10752 (83%)]	 Regressor Loss: -0.157878
Regressor Loss: -0.1579
Domain Loss: 0.0000
Train Epoch: 7 [9012/10752 (84%)]	 Regressor Loss: -0.491363
Regressor Loss: -0.4914
Domain Loss: 0.0002
Train Epoch: 7 [9132/10752 (85%)]	 Regressor Loss: -0.210074
Regressor Loss: -0.2101
Domain Loss: 0.0001
Train Epoch: 7 [9252/10752 (86%)]	 Regressor Loss: -0.517978
Regressor Loss: -0.5180
Domain Loss: 0.0001
Train Epoch: 7 [9372/10752 (87%)]	 Regressor Loss: -0.000000
Regressor Loss: -0.0000
Domain Loss: 0.0000
Training set: Average loss: -0.3132
Training set: Average Domain loss: 0.0008
Training set: Average Acc: 0.9998
Validation set: Average loss: -0.3131
Validation set: Average Domain loss: 0.1633
 Validation set: Average Acc: 0.9725
Training Main Encoder
Epoch  8 / 300
Train Epoch: 8 [12/10752 (0%)]	 Regressor Loss: -0.325518
Regressor Loss: -0.3255
Domain Loss: 0.0000
Train Epoch: 8 [132/10752 (1%)]	 Regressor Loss: -0.216057
Regressor Loss: -0.2161
Domain Loss: 0.0000
Train Epoch: 8 [252/10752 (2%)]	 Regressor Loss: -0.555188
Regressor Loss: -0.5552
Domain Loss: 0.0000
Train Epoch: 8 [372/10752 (3%)]	 Regressor Loss: -0.189496
Regressor Loss: -0.1895
Domain Loss: 0.0000
Train Epoch: 8 [492/10752 (5%)]	 Regressor Loss: -0.505962
Regressor Loss: -0.5060
Domain Loss: 0.0000
Train Epoch: 8 [612/10752 (6%)]	 Regressor Loss: -0.113803
Regressor Loss: -0.1138
Domain Loss: 0.0001
Train Epoch: 8 [732/10752 (7%)]	 Regressor Loss: -0.682482
Regressor Loss: -0.6825
Domain Loss: 0.0001
Train Epoch: 8 [852/10752 (8%)]	 Regressor Loss: -0.248454
Regressor Loss: -0.2485
Domain Loss: 0.0000
Train Epoch: 8 [972/10752 (9%)]	 Regressor Loss: -0.422281
Regressor Loss: -0.4223
Domain Loss: 0.0001
Train Epoch: 8 [1092/10752 (10%)]	 Regressor Loss: -0.312680
Regressor Loss: -0.3127
Domain Loss: 0.0000
Train Epoch: 8 [1212/10752 (11%)]	 Regressor Loss: -0.170435
Regressor Loss: -0.1704
Domain Loss: 0.0000
Train Epoch: 8 [1332/10752 (12%)]	 Regressor Loss: -0.148779
Regressor Loss: -0.1488
Domain Loss: 0.0000
Train Epoch: 8 [1452/10752 (14%)]	 Regressor Loss: -0.195093
Regressor Loss: -0.1951
Domain Loss: 0.0000
Train Epoch: 8 [1572/10752 (15%)]	 Regressor Loss: -0.219926
Regressor Loss: -0.2199
Domain Loss: 0.0000
Train Epoch: 8 [1692/10752 (16%)]	 Regressor Loss: -0.135358
Regressor Loss: -0.1354
Domain Loss: 0.0000
Train Epoch: 8 [1812/10752 (17%)]	 Regressor Loss: -0.145345
Regressor Loss: -0.1453
Domain Loss: 0.0000
Train Epoch: 8 [1932/10752 (18%)]	 Regressor Loss: -0.036266
Regressor Loss: -0.0363
Domain Loss: 0.0000
Train Epoch: 8 [2052/10752 (19%)]	 Regressor Loss: -0.449008
Regressor Loss: -0.4490
Domain Loss: 0.0000
Train Epoch: 8 [2172/10752 (20%)]	 Regressor Loss: -0.285794
Regressor Loss: -0.2858
Domain Loss: 0.0000
Train Epoch: 8 [2292/10752 (21%)]	 Regressor Loss: -0.435919
Regressor Loss: -0.4359
Domain Loss: 0.0000
Train Epoch: 8 [2412/10752 (22%)]	 Regressor Loss: -0.233582
Regressor Loss: -0.2336
Domain Loss: 0.0000
Train Epoch: 8 [2532/10752 (24%)]	 Regressor Loss: -0.204145
Regressor Loss: -0.2041
Domain Loss: 0.0040
Train Epoch: 8 [2652/10752 (25%)]	 Regressor Loss: -0.207100
Regressor Loss: -0.2071
Domain Loss: 0.0001
Train Epoch: 8 [2772/10752 (26%)]	 Regressor Loss: -0.571883
Regressor Loss: -0.5719
Domain Loss: 0.0001
Train Epoch: 8 [2892/10752 (27%)]	 Regressor Loss: -0.242651
Regressor Loss: -0.2427
Domain Loss: 0.0000
Train Epoch: 8 [3012/10752 (28%)]	 Regressor Loss: -0.393012
Regressor Loss: -0.3930
Domain Loss: 0.0000
Train Epoch: 8 [3132/10752 (29%)]	 Regressor Loss: -0.204772
Regressor Loss: -0.2048
Domain Loss: 0.0000
Train Epoch: 8 [3252/10752 (30%)]	 Regressor Loss: -0.510544
Regressor Loss: -0.5105
Domain Loss: 0.0000
Train Epoch: 8 [3372/10752 (31%)]	 Regressor Loss: -0.276604
Regressor Loss: -0.2766
Domain Loss: 0.0000
Train Epoch: 8 [3492/10752 (32%)]	 Regressor Loss: -0.477689
Regressor Loss: -0.4777
Domain Loss: 0.0000
Train Epoch: 8 [3612/10752 (34%)]	 Regressor Loss: -0.207189
Regressor Loss: -0.2072
Domain Loss: 0.0000
Train Epoch: 8 [3732/10752 (35%)]	 Regressor Loss: -0.549946
Regressor Loss: -0.5499
Domain Loss: 0.0000
Train Epoch: 8 [3852/10752 (36%)]	 Regressor Loss: -0.253334
Regressor Loss: -0.2533
Domain Loss: 0.0000
Train Epoch: 8 [3972/10752 (37%)]	 Regressor Loss: -0.526655
Regressor Loss: -0.5267
Domain Loss: 0.0000
Train Epoch: 8 [4092/10752 (38%)]	 Regressor Loss: -0.210225
Regressor Loss: -0.2102
Domain Loss: 0.0000
Train Epoch: 8 [4212/10752 (39%)]	 Regressor Loss: -0.304618
Regressor Loss: -0.3046
Domain Loss: 0.0000
Train Epoch: 8 [4332/10752 (40%)]	 Regressor Loss: -0.221656
Regressor Loss: -0.2217
Domain Loss: 0.0000
Train Epoch: 8 [4452/10752 (41%)]	 Regressor Loss: -0.148962
Regressor Loss: -0.1490
Domain Loss: 0.0000
Train Epoch: 8 [4572/10752 (43%)]	 Regressor Loss: -0.247923
Regressor Loss: -0.2479
Domain Loss: 0.0000
Train Epoch: 8 [4692/10752 (44%)]	 Regressor Loss: -0.329432
Regressor Loss: -0.3294
Domain Loss: 0.0001
Train Epoch: 8 [4812/10752 (45%)]	 Regressor Loss: -0.211466
Regressor Loss: -0.2115
Domain Loss: 0.0000
Train Epoch: 8 [4932/10752 (46%)]	 Regressor Loss: -0.206003
Regressor Loss: -0.2060
Domain Loss: 0.0000
Train Epoch: 8 [5052/10752 (47%)]	 Regressor Loss: -0.328810
Regressor Loss: -0.3288
Domain Loss: 0.0000
Train Epoch: 8 [5172/10752 (48%)]	 Regressor Loss: -0.258998
Regressor Loss: -0.2590
Domain Loss: 0.0000
Train Epoch: 8 [5292/10752 (49%)]	 Regressor Loss: -0.424926
Regressor Loss: -0.4249
Domain Loss: 0.0000
Train Epoch: 8 [5412/10752 (50%)]	 Regressor Loss: -0.213318
Regressor Loss: -0.2133
Domain Loss: 0.0000
Train Epoch: 8 [5532/10752 (51%)]	 Regressor Loss: -0.549552
Regressor Loss: -0.5496
Domain Loss: 0.0000
Train Epoch: 8 [5652/10752 (53%)]	 Regressor Loss: -0.339128
Regressor Loss: -0.3391
Domain Loss: 0.0000
Train Epoch: 8 [5772/10752 (54%)]	 Regressor Loss: -0.610064
Regressor Loss: -0.6101
Domain Loss: 0.0001
Train Epoch: 8 [5892/10752 (55%)]	 Regressor Loss: -0.231069
Regressor Loss: -0.2311
Domain Loss: 0.0001
Train Epoch: 8 [6012/10752 (56%)]	 Regressor Loss: -0.471634
Regressor Loss: -0.4716
Domain Loss: 0.0000
Train Epoch: 8 [6132/10752 (57%)]	 Regressor Loss: -0.317904
Regressor Loss: -0.3179
Domain Loss: 0.0000
Train Epoch: 8 [6252/10752 (58%)]	 Regressor Loss: -0.533139
Regressor Loss: -0.5331
Domain Loss: 0.0000
Train Epoch: 8 [6372/10752 (59%)]	 Regressor Loss: -0.267269
Regressor Loss: -0.2673
Domain Loss: 0.0000
Train Epoch: 8 [6492/10752 (60%)]	 Regressor Loss: -0.569108
Regressor Loss: -0.5691
Domain Loss: 0.0001
Train Epoch: 8 [6612/10752 (61%)]	 Regressor Loss: -0.182138
Regressor Loss: -0.1821
Domain Loss: 0.0000
Train Epoch: 8 [6732/10752 (63%)]	 Regressor Loss: -0.511163
Regressor Loss: -0.5112
Domain Loss: 0.0000
Train Epoch: 8 [6852/10752 (64%)]	 Regressor Loss: -0.216357
Regressor Loss: -0.2164
Domain Loss: 0.0001
Train Epoch: 8 [6972/10752 (65%)]	 Regressor Loss: -0.604395
Regressor Loss: -0.6044
Domain Loss: 0.0002
Train Epoch: 8 [7092/10752 (66%)]	 Regressor Loss: -0.240206
Regressor Loss: -0.2402
Domain Loss: 0.0002
Train Epoch: 8 [7212/10752 (67%)]	 Regressor Loss: -0.517441
Regressor Loss: -0.5174
Domain Loss: 0.0002
Train Epoch: 8 [7332/10752 (68%)]	 Regressor Loss: -0.289360
Regressor Loss: -0.2894
Domain Loss: 0.0000
Train Epoch: 8 [7452/10752 (69%)]	 Regressor Loss: -0.469340
Regressor Loss: -0.4693
Domain Loss: 0.0000
Train Epoch: 8 [7572/10752 (70%)]	 Regressor Loss: -0.148271
Regressor Loss: -0.1483
Domain Loss: 0.0000
Train Epoch: 8 [7692/10752 (72%)]	 Regressor Loss: -0.272171
Regressor Loss: -0.2722
Domain Loss: 0.0000
Train Epoch: 8 [7812/10752 (73%)]	 Regressor Loss: -0.275221
Regressor Loss: -0.2752
Domain Loss: 0.0000
Train Epoch: 8 [7932/10752 (74%)]	 Regressor Loss: -0.332139
Regressor Loss: -0.3321
Domain Loss: 0.0001
Train Epoch: 8 [8052/10752 (75%)]	 Regressor Loss: -0.181217
Regressor Loss: -0.1812
Domain Loss: 0.0000
Train Epoch: 8 [8172/10752 (76%)]	 Regressor Loss: -0.256881
Regressor Loss: -0.2569
Domain Loss: 0.0000
Train Epoch: 8 [8292/10752 (77%)]	 Regressor Loss: -0.325752
Regressor Loss: -0.3258
Domain Loss: 0.0000
Train Epoch: 8 [8412/10752 (78%)]	 Regressor Loss: -0.246028
Regressor Loss: -0.2460
Domain Loss: 0.0000
Train Epoch: 8 [8532/10752 (79%)]	 Regressor Loss: -0.475787
Regressor Loss: -0.4758
Domain Loss: 0.0000
Train Epoch: 8 [8652/10752 (80%)]	 Regressor Loss: -0.175045
Regressor Loss: -0.1750
Domain Loss: 0.0000
Train Epoch: 8 [8772/10752 (82%)]	 Regressor Loss: -0.542037
Regressor Loss: -0.5420
Domain Loss: 0.0000
Train Epoch: 8 [8892/10752 (83%)]	 Regressor Loss: -0.248355
Regressor Loss: -0.2484
Domain Loss: 0.0000
Train Epoch: 8 [9012/10752 (84%)]	 Regressor Loss: -0.522896
Regressor Loss: -0.5229
Domain Loss: 0.0000
Train Epoch: 8 [9132/10752 (85%)]	 Regressor Loss: -0.248843
Regressor Loss: -0.2488
Domain Loss: 0.0000
Train Epoch: 8 [9252/10752 (86%)]	 Regressor Loss: -0.474368
Regressor Loss: -0.4744
Domain Loss: 0.0000
Train Epoch: 8 [9372/10752 (87%)]	 Regressor Loss: -0.171261
Regressor Loss: -0.1713
Domain Loss: 0.0000
Training set: Average loss: -0.3278
Training set: Average Domain loss: 0.0022
Training set: Average Acc: 0.9995
Validation set: Average loss: -0.3145
Validation set: Average Domain loss: 0.1136
 Validation set: Average Acc: 0.9833
Training Main Encoder
Epoch  9 / 300
Train Epoch: 9 [12/10752 (0%)]	 Regressor Loss: -0.321857
Regressor Loss: -0.3219
Domain Loss: 0.0000
Train Epoch: 9 [132/10752 (1%)]	 Regressor Loss: -0.225248
Regressor Loss: -0.2252
Domain Loss: 0.0001
Train Epoch: 9 [252/10752 (2%)]	 Regressor Loss: -0.574832
Regressor Loss: -0.5748
Domain Loss: 0.0000
Train Epoch: 9 [372/10752 (3%)]	 Regressor Loss: -0.278117
Regressor Loss: -0.2781
Domain Loss: 0.0001
Train Epoch: 9 [492/10752 (5%)]	 Regressor Loss: -0.368914
Regressor Loss: -0.3689
Domain Loss: 0.0000
Train Epoch: 9 [612/10752 (6%)]	 Regressor Loss: -0.203535
Regressor Loss: -0.2035
Domain Loss: 0.0007
Train Epoch: 9 [732/10752 (7%)]	 Regressor Loss: -0.475328
Regressor Loss: -0.4753
Domain Loss: 0.0000
Train Epoch: 9 [852/10752 (8%)]	 Regressor Loss: -0.406570
Regressor Loss: -0.4066
Domain Loss: 0.0001
Train Epoch: 9 [972/10752 (9%)]	 Regressor Loss: -0.203087
Regressor Loss: -0.2031
Domain Loss: 0.0000
Train Epoch: 9 [1092/10752 (10%)]	 Regressor Loss: -0.195680
Regressor Loss: -0.1957
Domain Loss: 0.0000
Train Epoch: 9 [1212/10752 (11%)]	 Regressor Loss: -0.123759
Regressor Loss: -0.1238
Domain Loss: 0.0000
Train Epoch: 9 [1332/10752 (12%)]	 Regressor Loss: -0.122922
Regressor Loss: -0.1229
Domain Loss: 0.0000
Train Epoch: 9 [1452/10752 (14%)]	 Regressor Loss: -0.176931
Regressor Loss: -0.1769
Domain Loss: 0.0000
Train Epoch: 9 [1572/10752 (15%)]	 Regressor Loss: -0.230824
Regressor Loss: -0.2308
Domain Loss: 0.0000
Train Epoch: 9 [1692/10752 (16%)]	 Regressor Loss: -0.173995
Regressor Loss: -0.1740
Domain Loss: 0.0004
Train Epoch: 9 [1812/10752 (17%)]	 Regressor Loss: -0.359788
Regressor Loss: -0.3598
Domain Loss: 0.0000
Train Epoch: 9 [1932/10752 (18%)]	 Regressor Loss: -0.199159
Regressor Loss: -0.1992
Domain Loss: 0.0001
Train Epoch: 9 [2052/10752 (19%)]	 Regressor Loss: -0.586844
Regressor Loss: -0.5868
Domain Loss: 0.0000
Train Epoch: 9 [2172/10752 (20%)]	 Regressor Loss: -0.251381
Regressor Loss: -0.2514
Domain Loss: 0.0001
Train Epoch: 9 [2292/10752 (21%)]	 Regressor Loss: -0.517653
Regressor Loss: -0.5177
Domain Loss: 0.0000
Train Epoch: 9 [2412/10752 (22%)]	 Regressor Loss: -0.260705
Regressor Loss: -0.2607
Domain Loss: 0.0000
Train Epoch: 9 [2532/10752 (24%)]	 Regressor Loss: -0.568201
Regressor Loss: -0.5682
Domain Loss: 0.0000
Train Epoch: 9 [2652/10752 (25%)]	 Regressor Loss: -0.149974
Regressor Loss: -0.1500
Domain Loss: 0.0001
Train Epoch: 9 [2772/10752 (26%)]	 Regressor Loss: -0.589670
Regressor Loss: -0.5897
Domain Loss: 0.0000
Train Epoch: 9 [2892/10752 (27%)]	 Regressor Loss: -0.210299
Regressor Loss: -0.2103
Domain Loss: 0.0000
Train Epoch: 9 [3012/10752 (28%)]	 Regressor Loss: -0.561883
Regressor Loss: -0.5619
Domain Loss: 0.0000
Train Epoch: 9 [3132/10752 (29%)]	 Regressor Loss: -0.341712
Regressor Loss: -0.3417
Domain Loss: 0.0000
Train Epoch: 9 [3252/10752 (30%)]	 Regressor Loss: -0.524811
Regressor Loss: -0.5248
Domain Loss: 0.0001
Train Epoch: 9 [3372/10752 (31%)]	 Regressor Loss: -0.216065
Regressor Loss: -0.2161
Domain Loss: 0.0000
Train Epoch: 9 [3492/10752 (32%)]	 Regressor Loss: -0.448746
Regressor Loss: -0.4487
Domain Loss: 0.0000
Train Epoch: 9 [3612/10752 (34%)]	 Regressor Loss: -0.164509
Regressor Loss: -0.1645
Domain Loss: 0.0000
Train Epoch: 9 [3732/10752 (35%)]	 Regressor Loss: -0.517614
Regressor Loss: -0.5176
Domain Loss: 0.0000
Train Epoch: 9 [3852/10752 (36%)]	 Regressor Loss: -0.341621
Regressor Loss: -0.3416
Domain Loss: 0.0000
Train Epoch: 9 [3972/10752 (37%)]	 Regressor Loss: -0.485289
Regressor Loss: -0.4853
Domain Loss: 0.0000
Train Epoch: 9 [4092/10752 (38%)]	 Regressor Loss: -0.118507
Regressor Loss: -0.1185
Domain Loss: 0.0000
Train Epoch: 9 [4212/10752 (39%)]	 Regressor Loss: -0.346463
Regressor Loss: -0.3465
Domain Loss: 0.0000
Train Epoch: 9 [4332/10752 (40%)]	 Regressor Loss: -0.105635
Regressor Loss: -0.1056
Domain Loss: 0.0000
Train Epoch: 9 [4452/10752 (41%)]	 Regressor Loss: -0.248089
Regressor Loss: -0.2481
Domain Loss: 0.0000
Train Epoch: 9 [4572/10752 (43%)]	 Regressor Loss: -0.134818
Regressor Loss: -0.1348
Domain Loss: 0.0000
Train Epoch: 9 [4692/10752 (44%)]	 Regressor Loss: -0.159171
Regressor Loss: -0.1592
Domain Loss: 0.0000
Train Epoch: 9 [4812/10752 (45%)]	 Regressor Loss: -0.312518
Regressor Loss: -0.3125
Domain Loss: 0.0000
Train Epoch: 9 [4932/10752 (46%)]	 Regressor Loss: -0.173912
Regressor Loss: -0.1739
Domain Loss: 0.0002
Train Epoch: 9 [5052/10752 (47%)]	 Regressor Loss: -0.174970
Regressor Loss: -0.1750
Domain Loss: 0.0000
Train Epoch: 9 [5172/10752 (48%)]	 Regressor Loss: -0.234788
Regressor Loss: -0.2348
Domain Loss: 0.0032
Train Epoch: 9 [5292/10752 (49%)]	 Regressor Loss: -0.467952
Regressor Loss: -0.4680
Domain Loss: 0.0000
Train Epoch: 9 [5412/10752 (50%)]	 Regressor Loss: -0.249513
Regressor Loss: -0.2495
Domain Loss: 0.0000
Train Epoch: 9 [5532/10752 (51%)]	 Regressor Loss: -0.361415
Regressor Loss: -0.3614
Domain Loss: 0.0000
Train Epoch: 9 [5652/10752 (53%)]	 Regressor Loss: -0.281476
Regressor Loss: -0.2815
Domain Loss: 0.0000
Train Epoch: 9 [5772/10752 (54%)]	 Regressor Loss: -0.556690
Regressor Loss: -0.5567
Domain Loss: 0.0001
Train Epoch: 9 [5892/10752 (55%)]	 Regressor Loss: -0.296860
Regressor Loss: -0.2969
Domain Loss: 0.0000
Train Epoch: 9 [6012/10752 (56%)]	 Regressor Loss: -0.466227
Regressor Loss: -0.4662
Domain Loss: 0.0000
Train Epoch: 9 [6132/10752 (57%)]	 Regressor Loss: -0.495059
Regressor Loss: -0.4951
Domain Loss: 0.0001
Train Epoch: 9 [6252/10752 (58%)]	 Regressor Loss: -0.579072
Regressor Loss: -0.5791
Domain Loss: 0.0013
Train Epoch: 9 [6372/10752 (59%)]	 Regressor Loss: -0.169880
Regressor Loss: -0.1699
Domain Loss: 0.0000
Train Epoch: 9 [6492/10752 (60%)]	 Regressor Loss: -0.637338
Regressor Loss: -0.6373
Domain Loss: 0.0000
Train Epoch: 9 [6612/10752 (61%)]	 Regressor Loss: -0.203895
Regressor Loss: -0.2039
Domain Loss: 0.0000
Train Epoch: 9 [6732/10752 (63%)]	 Regressor Loss: -0.496616
Regressor Loss: -0.4966
Domain Loss: 0.0000
Train Epoch: 9 [6852/10752 (64%)]	 Regressor Loss: -0.196481
Regressor Loss: -0.1965
Domain Loss: 0.0000
Train Epoch: 9 [6972/10752 (65%)]	 Regressor Loss: -0.642022
Regressor Loss: -0.6420
Domain Loss: 0.0001
Train Epoch: 9 [7092/10752 (66%)]	 Regressor Loss: -0.305853
Regressor Loss: -0.3059
Domain Loss: 0.0000
Train Epoch: 9 [7212/10752 (67%)]	 Regressor Loss: -0.508650
Regressor Loss: -0.5087
Domain Loss: 0.0000
Train Epoch: 9 [7332/10752 (68%)]	 Regressor Loss: -0.142443
Regressor Loss: -0.1424
Domain Loss: 0.0000
Train Epoch: 9 [7452/10752 (69%)]	 Regressor Loss: -0.381899
Regressor Loss: -0.3819
Domain Loss: 0.0000
Train Epoch: 9 [7572/10752 (70%)]	 Regressor Loss: -0.227240
Regressor Loss: -0.2272
Domain Loss: 0.0000
Train Epoch: 9 [7692/10752 (72%)]	 Regressor Loss: -0.281454
Regressor Loss: -0.2815
Domain Loss: 0.0000
Train Epoch: 9 [7812/10752 (73%)]	 Regressor Loss: -0.250254
Regressor Loss: -0.2503
Domain Loss: 0.0000
Train Epoch: 9 [7932/10752 (74%)]	 Regressor Loss: -0.354823
Regressor Loss: -0.3548
Domain Loss: 0.0000
Train Epoch: 9 [8052/10752 (75%)]	 Regressor Loss: -0.390304
Regressor Loss: -0.3903
Domain Loss: 0.0000
Train Epoch: 9 [8172/10752 (76%)]	 Regressor Loss: -0.254144
Regressor Loss: -0.2541
Domain Loss: 0.0001
Train Epoch: 9 [8292/10752 (77%)]	 Regressor Loss: -0.393004
Regressor Loss: -0.3930
Domain Loss: 0.0000
Train Epoch: 9 [8412/10752 (78%)]	 Regressor Loss: -0.226622
Regressor Loss: -0.2266
Domain Loss: 0.0000
Train Epoch: 9 [8532/10752 (79%)]	 Regressor Loss: -0.289432
Regressor Loss: -0.2894
Domain Loss: 0.0000
Train Epoch: 9 [8652/10752 (80%)]	 Regressor Loss: -0.331135
Regressor Loss: -0.3311
Domain Loss: 0.0000
Train Epoch: 9 [8772/10752 (82%)]	 Regressor Loss: -0.483032
Regressor Loss: -0.4830
Domain Loss: 0.0000
Train Epoch: 9 [8892/10752 (83%)]	 Regressor Loss: -0.197380
Regressor Loss: -0.1974
Domain Loss: 0.0000
Train Epoch: 9 [9012/10752 (84%)]	 Regressor Loss: -0.599436
Regressor Loss: -0.5994
Domain Loss: 0.0000
Train Epoch: 9 [9132/10752 (85%)]	 Regressor Loss: -0.263546
Regressor Loss: -0.2635
Domain Loss: 0.0000
Train Epoch: 9 [9252/10752 (86%)]	 Regressor Loss: -0.591370
Regressor Loss: -0.5914
Domain Loss: 0.0000
Train Epoch: 9 [9372/10752 (87%)]	 Regressor Loss: -0.137144
Regressor Loss: -0.1371
Domain Loss: 0.0000
Training set: Average loss: -0.3358
Training set: Average Domain loss: 0.0001
Training set: Average Acc: 1.0000
Validation set: Average loss: -0.3323
Validation set: Average Domain loss: 0.1084
 Validation set: Average Acc: 0.9808
Training Main Encoder
Epoch  10 / 300
Train Epoch: 10 [12/10752 (0%)]	 Regressor Loss: -0.391412
Regressor Loss: -0.3914
Domain Loss: 0.0000
Train Epoch: 10 [132/10752 (1%)]	 Regressor Loss: -0.196870
Regressor Loss: -0.1969
Domain Loss: 0.0000
Train Epoch: 10 [252/10752 (2%)]	 Regressor Loss: -0.650540
Regressor Loss: -0.6505
Domain Loss: 0.0000
Train Epoch: 10 [372/10752 (3%)]	 Regressor Loss: -0.202673
Regressor Loss: -0.2027
Domain Loss: 0.0000
Train Epoch: 10 [492/10752 (5%)]	 Regressor Loss: -0.572497
Regressor Loss: -0.5725
Domain Loss: 0.0000
Train Epoch: 10 [612/10752 (6%)]	 Regressor Loss: -0.252725
Regressor Loss: -0.2527
Domain Loss: 0.0000
Train Epoch: 10 [732/10752 (7%)]	 Regressor Loss: -0.533286
Regressor Loss: -0.5333
Domain Loss: 0.0000
Train Epoch: 10 [852/10752 (8%)]	 Regressor Loss: -0.318580
Regressor Loss: -0.3186
Domain Loss: 0.0001
Train Epoch: 10 [972/10752 (9%)]	 Regressor Loss: -0.295134
Regressor Loss: -0.2951
Domain Loss: 0.0000
Train Epoch: 10 [1092/10752 (10%)]	 Regressor Loss: -0.229131
Regressor Loss: -0.2291
Domain Loss: 0.0000
Train Epoch: 10 [1212/10752 (11%)]	 Regressor Loss: -0.203328
Regressor Loss: -0.2033
Domain Loss: 0.0000
Train Epoch: 10 [1332/10752 (12%)]	 Regressor Loss: -0.369727
Regressor Loss: -0.3697
Domain Loss: 0.0000
Train Epoch: 10 [1452/10752 (14%)]	 Regressor Loss: -0.195908
Regressor Loss: -0.1959
Domain Loss: 0.0000
Train Epoch: 10 [1572/10752 (15%)]	 Regressor Loss: -0.154641
Regressor Loss: -0.1546
Domain Loss: 0.0000
Train Epoch: 10 [1692/10752 (16%)]	 Regressor Loss: -0.248574
Regressor Loss: -0.2486
Domain Loss: 0.0000
Train Epoch: 10 [1812/10752 (17%)]	 Regressor Loss: -0.412797
Regressor Loss: -0.4128
Domain Loss: 0.0000
Train Epoch: 10 [1932/10752 (18%)]	 Regressor Loss: -0.216860
Regressor Loss: -0.2169
Domain Loss: 0.0000
Train Epoch: 10 [2052/10752 (19%)]	 Regressor Loss: -0.474588
Regressor Loss: -0.4746
Domain Loss: 0.0000
Train Epoch: 10 [2172/10752 (20%)]	 Regressor Loss: -0.126717
Regressor Loss: -0.1267
Domain Loss: 0.0000
Train Epoch: 10 [2292/10752 (21%)]	 Regressor Loss: -0.511053
Regressor Loss: -0.5111
Domain Loss: 0.0000
Train Epoch: 10 [2412/10752 (22%)]	 Regressor Loss: -0.264033
Regressor Loss: -0.2640
Domain Loss: 0.0000
Train Epoch: 10 [2532/10752 (24%)]	 Regressor Loss: -0.196083
Regressor Loss: -0.1961
Domain Loss: 0.0000
Train Epoch: 10 [2652/10752 (25%)]	 Regressor Loss: -0.039500
Regressor Loss: -0.0395
Domain Loss: 0.0000
Train Epoch: 10 [2772/10752 (26%)]	 Regressor Loss: -0.534306
Regressor Loss: -0.5343
Domain Loss: 0.0000
Train Epoch: 10 [2892/10752 (27%)]	 Regressor Loss: -0.211202
Regressor Loss: -0.2112
Domain Loss: 0.0000
Train Epoch: 10 [3012/10752 (28%)]	 Regressor Loss: -0.615092
Regressor Loss: -0.6151
Domain Loss: 0.0000
Train Epoch: 10 [3132/10752 (29%)]	 Regressor Loss: -0.179986
Regressor Loss: -0.1800
Domain Loss: 0.0000
Train Epoch: 10 [3252/10752 (30%)]	 Regressor Loss: -0.583994
Regressor Loss: -0.5840
Domain Loss: 0.0000
Train Epoch: 10 [3372/10752 (31%)]	 Regressor Loss: -0.342852
Regressor Loss: -0.3429
Domain Loss: 0.0000
Train Epoch: 10 [3492/10752 (32%)]	 Regressor Loss: -0.598075
Regressor Loss: -0.5981
Domain Loss: 0.0000
Train Epoch: 10 [3612/10752 (34%)]	 Regressor Loss: -0.224209
Regressor Loss: -0.2242
Domain Loss: 0.0000
Train Epoch: 10 [3732/10752 (35%)]	 Regressor Loss: -0.556721
Regressor Loss: -0.5567
Domain Loss: 0.0000
Train Epoch: 10 [3852/10752 (36%)]	 Regressor Loss: -0.180945
Regressor Loss: -0.1809
Domain Loss: 0.0000
Train Epoch: 10 [3972/10752 (37%)]	 Regressor Loss: -0.325269
Regressor Loss: -0.3253
Domain Loss: 0.0000
Train Epoch: 10 [4092/10752 (38%)]	 Regressor Loss: -0.288098
Regressor Loss: -0.2881
Domain Loss: 0.0000
Train Epoch: 10 [4212/10752 (39%)]	 Regressor Loss: -0.344005
Regressor Loss: -0.3440
Domain Loss: 0.0000
Train Epoch: 10 [4332/10752 (40%)]	 Regressor Loss: -0.266425
Regressor Loss: -0.2664
Domain Loss: 0.0000
Train Epoch: 10 [4452/10752 (41%)]	 Regressor Loss: -0.114953
Regressor Loss: -0.1150
Domain Loss: 0.0000
Train Epoch: 10 [4572/10752 (43%)]	 Regressor Loss: -0.233538
Regressor Loss: -0.2335
Domain Loss: 0.0000
Train Epoch: 10 [4692/10752 (44%)]	 Regressor Loss: -0.216204
Regressor Loss: -0.2162
Domain Loss: 0.0000
Train Epoch: 10 [4812/10752 (45%)]	 Regressor Loss: -0.199604
Regressor Loss: -0.1996
Domain Loss: 0.0000
Train Epoch: 10 [4932/10752 (46%)]	 Regressor Loss: -0.282702
Regressor Loss: -0.2827
Domain Loss: 0.0000
Train Epoch: 10 [5052/10752 (47%)]	 Regressor Loss: -0.391048
Regressor Loss: -0.3910
Domain Loss: 0.0001
Train Epoch: 10 [5172/10752 (48%)]	 Regressor Loss: -0.110086
Regressor Loss: -0.1101
Domain Loss: 0.0000
Train Epoch: 10 [5292/10752 (49%)]	 Regressor Loss: -0.548068
Regressor Loss: -0.5481
Domain Loss: 0.0001
Train Epoch: 10 [5412/10752 (50%)]	 Regressor Loss: -0.258987
Regressor Loss: -0.2590
Domain Loss: 0.0001
Train Epoch: 10 [5532/10752 (51%)]	 Regressor Loss: -0.364904
Regressor Loss: -0.3649
Domain Loss: 0.0000
Train Epoch: 10 [5652/10752 (53%)]	 Regressor Loss: -0.134267
Regressor Loss: -0.1343
Domain Loss: 0.0000
Train Epoch: 10 [5772/10752 (54%)]	 Regressor Loss: -0.553264
Regressor Loss: -0.5533
Domain Loss: 0.0002
Train Epoch: 10 [5892/10752 (55%)]	 Regressor Loss: -0.115263
Regressor Loss: -0.1153
Domain Loss: 0.0004
Train Epoch: 10 [6012/10752 (56%)]	 Regressor Loss: -0.603999
Regressor Loss: -0.6040
Domain Loss: 0.0002
Train Epoch: 10 [6132/10752 (57%)]	 Regressor Loss: -0.281459
Regressor Loss: -0.2815
Domain Loss: 0.0000
Train Epoch: 10 [6252/10752 (58%)]	 Regressor Loss: -0.472459
Regressor Loss: -0.4725
Domain Loss: 0.0012
Train Epoch: 10 [6372/10752 (59%)]	 Regressor Loss: -0.150090
Regressor Loss: -0.1501
Domain Loss: 0.0000
Train Epoch: 10 [6492/10752 (60%)]	 Regressor Loss: -0.605538
Regressor Loss: -0.6055
Domain Loss: 0.0001
Train Epoch: 10 [6612/10752 (61%)]	 Regressor Loss: -0.221109
Regressor Loss: -0.2211
Domain Loss: 0.0000
Train Epoch: 10 [6732/10752 (63%)]	 Regressor Loss: -0.509660
Regressor Loss: -0.5097
Domain Loss: 0.0000
Train Epoch: 10 [6852/10752 (64%)]	 Regressor Loss: -0.304337
Regressor Loss: -0.3043
Domain Loss: 0.0000
Train Epoch: 10 [6972/10752 (65%)]	 Regressor Loss: -0.548842
Regressor Loss: -0.5488
Domain Loss: 0.0000
Train Epoch: 10 [7092/10752 (66%)]	 Regressor Loss: -0.240729
Regressor Loss: -0.2407
Domain Loss: 0.0000
Train Epoch: 10 [7212/10752 (67%)]	 Regressor Loss: -0.449984
Regressor Loss: -0.4500
Domain Loss: 0.0000
Train Epoch: 10 [7332/10752 (68%)]	 Regressor Loss: -0.186658
Regressor Loss: -0.1867
Domain Loss: 0.0000
Train Epoch: 10 [7452/10752 (69%)]	 Regressor Loss: -0.483450
Regressor Loss: -0.4835
Domain Loss: 0.0011
Train Epoch: 10 [7572/10752 (70%)]	 Regressor Loss: -0.193578
Regressor Loss: -0.1936
Domain Loss: 0.0000
Train Epoch: 10 [7692/10752 (72%)]	 Regressor Loss: -0.202823
Regressor Loss: -0.2028
Domain Loss: 0.0000
Train Epoch: 10 [7812/10752 (73%)]	 Regressor Loss: -0.272695
Regressor Loss: -0.2727
Domain Loss: 0.0001
Train Epoch: 10 [7932/10752 (74%)]	 Regressor Loss: -0.296944
Regressor Loss: -0.2969
Domain Loss: 0.0000
Train Epoch: 10 [8052/10752 (75%)]	 Regressor Loss: -0.137173
Regressor Loss: -0.1372
Domain Loss: 0.0000
Train Epoch: 10 [8172/10752 (76%)]	 Regressor Loss: -0.182660
Regressor Loss: -0.1827
Domain Loss: 0.0000
Train Epoch: 10 [8292/10752 (77%)]	 Regressor Loss: -0.357741
Regressor Loss: -0.3577
Domain Loss: 0.0000
Train Epoch: 10 [8412/10752 (78%)]	 Regressor Loss: -0.386814
Regressor Loss: -0.3868
Domain Loss: 0.0000
Train Epoch: 10 [8532/10752 (79%)]	 Regressor Loss: -0.482245
Regressor Loss: -0.4822
Domain Loss: 0.0000
Train Epoch: 10 [8652/10752 (80%)]	 Regressor Loss: -0.337096
Regressor Loss: -0.3371
Domain Loss: 0.0001
Train Epoch: 10 [8772/10752 (82%)]	 Regressor Loss: -0.491941
Regressor Loss: -0.4919
Domain Loss: 0.0000
Train Epoch: 10 [8892/10752 (83%)]	 Regressor Loss: -0.279506
Regressor Loss: -0.2795
Domain Loss: 0.0004
Train Epoch: 10 [9012/10752 (84%)]	 Regressor Loss: -0.535816
Regressor Loss: -0.5358
Domain Loss: 0.0000
Train Epoch: 10 [9132/10752 (85%)]	 Regressor Loss: -0.195711
Regressor Loss: -0.1957
Domain Loss: 0.0037
Train Epoch: 10 [9252/10752 (86%)]	 Regressor Loss: -0.665765
Regressor Loss: -0.6658
Domain Loss: 0.0000
Train Epoch: 10 [9372/10752 (87%)]	 Regressor Loss: -0.193085
Regressor Loss: -0.1931
Domain Loss: 0.0001
Training set: Average loss: -0.3519
Training set: Average Domain loss: 0.0003
Training set: Average Acc: 0.9999
Validation set: Average loss: -0.3384
Validation set: Average Domain loss: 0.2013
 Validation set: Average Acc: 0.9717
Training Main Encoder
Epoch  11 / 300
Train Epoch: 11 [12/10752 (0%)]	 Regressor Loss: -0.515081
Regressor Loss: -0.5151
Domain Loss: 0.0002
Train Epoch: 11 [132/10752 (1%)]	 Regressor Loss: -0.283802
Regressor Loss: -0.2838
Domain Loss: 0.0010
Train Epoch: 11 [252/10752 (2%)]	 Regressor Loss: -0.414158
Regressor Loss: -0.4142
Domain Loss: 0.0000
Train Epoch: 11 [372/10752 (3%)]	 Regressor Loss: -0.189041
Regressor Loss: -0.1890
Domain Loss: 0.0000
Train Epoch: 11 [492/10752 (5%)]	 Regressor Loss: -0.531094
Regressor Loss: -0.5311
Domain Loss: 0.0000
Train Epoch: 11 [612/10752 (6%)]	 Regressor Loss: -0.222383
Regressor Loss: -0.2224
Domain Loss: 0.0016
Train Epoch: 11 [732/10752 (7%)]	 Regressor Loss: -0.636454
Regressor Loss: -0.6365
Domain Loss: 0.0000
Train Epoch: 11 [852/10752 (8%)]	 Regressor Loss: -0.378923
Regressor Loss: -0.3789
Domain Loss: 0.0000
Train Epoch: 11 [972/10752 (9%)]	 Regressor Loss: -0.452628
Regressor Loss: -0.4526
Domain Loss: 0.0000
Train Epoch: 11 [1092/10752 (10%)]	 Regressor Loss: -0.057871
Regressor Loss: -0.0579
Domain Loss: 0.0000
Train Epoch: 11 [1212/10752 (11%)]	 Regressor Loss: -0.036637
Regressor Loss: -0.0366
Domain Loss: 0.0000
Train Epoch: 11 [1332/10752 (12%)]	 Regressor Loss: -0.258083
Regressor Loss: -0.2581
Domain Loss: 0.0000
Train Epoch: 11 [1452/10752 (14%)]	 Regressor Loss: -0.263949
Regressor Loss: -0.2639
Domain Loss: 0.0000
Train Epoch: 11 [1572/10752 (15%)]	 Regressor Loss: -0.339703
Regressor Loss: -0.3397
Domain Loss: 0.0000
Train Epoch: 11 [1692/10752 (16%)]	 Regressor Loss: -0.249587
Regressor Loss: -0.2496
Domain Loss: 0.0000
Train Epoch: 11 [1812/10752 (17%)]	 Regressor Loss: -0.415504
Regressor Loss: -0.4155
Domain Loss: 0.0000
Train Epoch: 11 [1932/10752 (18%)]	 Regressor Loss: -0.193449
Regressor Loss: -0.1934
Domain Loss: 0.0000
Train Epoch: 11 [2052/10752 (19%)]	 Regressor Loss: -0.563164
Regressor Loss: -0.5632
Domain Loss: 0.0000
Train Epoch: 11 [2172/10752 (20%)]	 Regressor Loss: -0.258408
Regressor Loss: -0.2584
Domain Loss: 0.0001
Train Epoch: 11 [2292/10752 (21%)]	 Regressor Loss: -0.348769
Regressor Loss: -0.3488
Domain Loss: 0.0000
Train Epoch: 11 [2412/10752 (22%)]	 Regressor Loss: -0.229820
Regressor Loss: -0.2298
Domain Loss: 0.0000
Train Epoch: 11 [2532/10752 (24%)]	 Regressor Loss: -0.526701
Regressor Loss: -0.5267
Domain Loss: 0.0000
Train Epoch: 11 [2652/10752 (25%)]	 Regressor Loss: -0.277721
Regressor Loss: -0.2777
Domain Loss: 0.0000
Train Epoch: 11 [2772/10752 (26%)]	 Regressor Loss: -0.677166
Regressor Loss: -0.6772
Domain Loss: 0.0001
Train Epoch: 11 [2892/10752 (27%)]	 Regressor Loss: -0.279175
Regressor Loss: -0.2792
Domain Loss: 0.0001
Train Epoch: 11 [3012/10752 (28%)]	 Regressor Loss: -0.566419
Regressor Loss: -0.5664
Domain Loss: 0.0000
Train Epoch: 11 [3132/10752 (29%)]	 Regressor Loss: -0.247869
Regressor Loss: -0.2479
Domain Loss: 0.0000
Train Epoch: 11 [3252/10752 (30%)]	 Regressor Loss: -0.589934
Regressor Loss: -0.5899
Domain Loss: 0.0000
Train Epoch: 11 [3372/10752 (31%)]	 Regressor Loss: -0.272114
Regressor Loss: -0.2721
Domain Loss: 0.0000
Train Epoch: 11 [3492/10752 (32%)]	 Regressor Loss: -0.702906
Regressor Loss: -0.7029
Domain Loss: 0.0001
Train Epoch: 11 [3612/10752 (34%)]	 Regressor Loss: -0.307664
Regressor Loss: -0.3077
Domain Loss: 0.0000
Train Epoch: 11 [3732/10752 (35%)]	 Regressor Loss: -0.651641
Regressor Loss: -0.6516
Domain Loss: 0.0002
Train Epoch: 11 [3852/10752 (36%)]	 Regressor Loss: -0.301813
Regressor Loss: -0.3018
Domain Loss: 0.0000
Train Epoch: 11 [3972/10752 (37%)]	 Regressor Loss: -0.670857
Regressor Loss: -0.6709
Domain Loss: 0.0000
Train Epoch: 11 [4092/10752 (38%)]	 Regressor Loss: -0.205408
Regressor Loss: -0.2054
Domain Loss: 0.0000
Train Epoch: 11 [4212/10752 (39%)]	 Regressor Loss: -0.370318
Regressor Loss: -0.3703
Domain Loss: 0.0000
Train Epoch: 11 [4332/10752 (40%)]	 Regressor Loss: -0.247298
Regressor Loss: -0.2473
Domain Loss: 0.0000
Train Epoch: 11 [4452/10752 (41%)]	 Regressor Loss: -0.263501
Regressor Loss: -0.2635
Domain Loss: 0.0000
Train Epoch: 11 [4572/10752 (43%)]	 Regressor Loss: -0.237564
Regressor Loss: -0.2376
Domain Loss: 0.0001
Train Epoch: 11 [4692/10752 (44%)]	 Regressor Loss: -0.148602
Regressor Loss: -0.1486
Domain Loss: 0.0011
Train Epoch: 11 [4812/10752 (45%)]	 Regressor Loss: -0.248579
Regressor Loss: -0.2486
Domain Loss: 0.0000
Train Epoch: 11 [4932/10752 (46%)]	 Regressor Loss: -0.305449
Regressor Loss: -0.3054
Domain Loss: 0.0000
Train Epoch: 11 [5052/10752 (47%)]	 Regressor Loss: -0.351065
Regressor Loss: -0.3511
Domain Loss: 0.0002
Train Epoch: 11 [5172/10752 (48%)]	 Regressor Loss: -0.255685
Regressor Loss: -0.2557
Domain Loss: 0.0000
Train Epoch: 11 [5292/10752 (49%)]	 Regressor Loss: -0.489789
Regressor Loss: -0.4898
Domain Loss: 0.0000
Train Epoch: 11 [5412/10752 (50%)]	 Regressor Loss: -0.355235
Regressor Loss: -0.3552
Domain Loss: 0.0000
Train Epoch: 11 [5532/10752 (51%)]	 Regressor Loss: -0.619068
Regressor Loss: -0.6191
Domain Loss: 0.0000
Train Epoch: 11 [5652/10752 (53%)]	 Regressor Loss: -0.424617
Regressor Loss: -0.4246
Domain Loss: 0.0000
Train Epoch: 11 [5772/10752 (54%)]	 Regressor Loss: -0.601025
Regressor Loss: -0.6010
Domain Loss: 0.0001
Train Epoch: 11 [5892/10752 (55%)]	 Regressor Loss: -0.246347
Regressor Loss: -0.2463
Domain Loss: 0.0000
Train Epoch: 11 [6012/10752 (56%)]	 Regressor Loss: -0.582253
Regressor Loss: -0.5823
Domain Loss: 0.0000
Train Epoch: 11 [6132/10752 (57%)]	 Regressor Loss: -0.692861
Regressor Loss: -0.6929
Domain Loss: 0.0001
Train Epoch: 11 [6252/10752 (58%)]	 Regressor Loss: -0.539528
Regressor Loss: -0.5395
Domain Loss: 0.0003
Train Epoch: 11 [6372/10752 (59%)]	 Regressor Loss: -0.082836
Regressor Loss: -0.0828
Domain Loss: 0.0000
Train Epoch: 11 [6492/10752 (60%)]	 Regressor Loss: -0.580591
Regressor Loss: -0.5806
Domain Loss: 0.0001
Train Epoch: 11 [6612/10752 (61%)]	 Regressor Loss: -0.253135
Regressor Loss: -0.2531
Domain Loss: 0.0000
Train Epoch: 11 [6732/10752 (63%)]	 Regressor Loss: -0.222168
Regressor Loss: -0.2222
Domain Loss: 0.0000
Train Epoch: 11 [6852/10752 (64%)]	 Regressor Loss: -0.247798
Regressor Loss: -0.2478
Domain Loss: 0.0000
Train Epoch: 11 [6972/10752 (65%)]	 Regressor Loss: -0.600276
Regressor Loss: -0.6003
Domain Loss: 0.0000
Train Epoch: 11 [7092/10752 (66%)]	 Regressor Loss: -0.212259
Regressor Loss: -0.2123
Domain Loss: 0.0000
Train Epoch: 11 [7212/10752 (67%)]	 Regressor Loss: -0.577527
Regressor Loss: -0.5775
Domain Loss: 0.0000
Train Epoch: 11 [7332/10752 (68%)]	 Regressor Loss: -0.201145
Regressor Loss: -0.2011
Domain Loss: 0.0000
Train Epoch: 11 [7452/10752 (69%)]	 Regressor Loss: -0.466255
Regressor Loss: -0.4663
Domain Loss: 0.0000
Train Epoch: 11 [7572/10752 (70%)]	 Regressor Loss: -0.359096
Regressor Loss: -0.3591
Domain Loss: 0.0004
Train Epoch: 11 [7692/10752 (72%)]	 Regressor Loss: -0.448735
Regressor Loss: -0.4487
Domain Loss: 0.0000
Train Epoch: 11 [7812/10752 (73%)]	 Regressor Loss: -0.304232
Regressor Loss: -0.3042
Domain Loss: 0.0568
Train Epoch: 11 [7932/10752 (74%)]	 Regressor Loss: -0.254411
Regressor Loss: -0.2544
Domain Loss: 0.0000
Train Epoch: 11 [8052/10752 (75%)]	 Regressor Loss: -0.345736
Regressor Loss: -0.3457
Domain Loss: 0.0000
Train Epoch: 11 [8172/10752 (76%)]	 Regressor Loss: -0.238839
Regressor Loss: -0.2388
Domain Loss: 0.0000
Train Epoch: 11 [8292/10752 (77%)]	 Regressor Loss: -0.452430
Regressor Loss: -0.4524
Domain Loss: 0.0000
Train Epoch: 11 [8412/10752 (78%)]	 Regressor Loss: -0.295203
Regressor Loss: -0.2952
Domain Loss: 0.0000
Train Epoch: 11 [8532/10752 (79%)]	 Regressor Loss: -0.463354
Regressor Loss: -0.4634
Domain Loss: 0.0000
Train Epoch: 11 [8652/10752 (80%)]	 Regressor Loss: -0.276830
Regressor Loss: -0.2768
Domain Loss: 0.0000
Train Epoch: 11 [8772/10752 (82%)]	 Regressor Loss: -0.484197
Regressor Loss: -0.4842
Domain Loss: 0.0000
Train Epoch: 11 [8892/10752 (83%)]	 Regressor Loss: -0.003475
Regressor Loss: -0.0035
Domain Loss: 0.0000
Train Epoch: 11 [9012/10752 (84%)]	 Regressor Loss: -0.493366
Regressor Loss: -0.4934
Domain Loss: 0.0000
Train Epoch: 11 [9132/10752 (85%)]	 Regressor Loss: -0.243541
Regressor Loss: -0.2435
Domain Loss: 0.0000
Train Epoch: 11 [9252/10752 (86%)]	 Regressor Loss: -0.553795
Regressor Loss: -0.5538
Domain Loss: 0.0000
Train Epoch: 11 [9372/10752 (87%)]	 Regressor Loss: -0.257689
Regressor Loss: -0.2577
Domain Loss: 0.0000
Training set: Average loss: -0.3609
Training set: Average Domain loss: 0.0003
Training set: Average Acc: 1.0000
Validation set: Average loss: -0.3507
Validation set: Average Domain loss: 0.1635
 Validation set: Average Acc: 0.9717
Training Main Encoder
Epoch  12 / 300
Train Epoch: 12 [12/10752 (0%)]	 Regressor Loss: -0.415119
Regressor Loss: -0.4151
Domain Loss: 0.0000
Train Epoch: 12 [132/10752 (1%)]	 Regressor Loss: -0.319042
Regressor Loss: -0.3190
Domain Loss: 0.0000
Train Epoch: 12 [252/10752 (2%)]	 Regressor Loss: -0.680926
Regressor Loss: -0.6809
Domain Loss: 0.0000
Train Epoch: 12 [372/10752 (3%)]	 Regressor Loss: -0.309371
Regressor Loss: -0.3094
Domain Loss: 0.0000
Train Epoch: 12 [492/10752 (5%)]	 Regressor Loss: -0.654287
Regressor Loss: -0.6543
Domain Loss: 0.0001
Train Epoch: 12 [612/10752 (6%)]	 Regressor Loss: -0.283786
Regressor Loss: -0.2838
Domain Loss: 0.0000
Train Epoch: 12 [732/10752 (7%)]	 Regressor Loss: -0.660019
Regressor Loss: -0.6600
Domain Loss: 0.0001
Train Epoch: 12 [852/10752 (8%)]	 Regressor Loss: -0.243864
Regressor Loss: -0.2439
Domain Loss: 0.0000
Train Epoch: 12 [972/10752 (9%)]	 Regressor Loss: -0.450499
Regressor Loss: -0.4505
Domain Loss: 0.0000
Train Epoch: 12 [1092/10752 (10%)]	 Regressor Loss: -0.226765
Regressor Loss: -0.2268
Domain Loss: 0.0000
Train Epoch: 12 [1212/10752 (11%)]	 Regressor Loss: -0.251029
Regressor Loss: -0.2510
Domain Loss: 0.0000
Train Epoch: 12 [1332/10752 (12%)]	 Regressor Loss: -0.233906
Regressor Loss: -0.2339
Domain Loss: 0.0000
Train Epoch: 12 [1452/10752 (14%)]	 Regressor Loss: -0.175586
Regressor Loss: -0.1756
Domain Loss: 0.0000
Train Epoch: 12 [1572/10752 (15%)]	 Regressor Loss: -0.338493
Regressor Loss: -0.3385
Domain Loss: 0.0798
Train Epoch: 12 [1692/10752 (16%)]	 Regressor Loss: -0.292384
Regressor Loss: -0.2924
Domain Loss: 0.0000
Train Epoch: 12 [1812/10752 (17%)]	 Regressor Loss: -0.446137
Regressor Loss: -0.4461
Domain Loss: 0.0000
Train Epoch: 12 [1932/10752 (18%)]	 Regressor Loss: -0.235806
Regressor Loss: -0.2358
Domain Loss: 0.0000
Train Epoch: 12 [2052/10752 (19%)]	 Regressor Loss: -0.531367
Regressor Loss: -0.5314
Domain Loss: 0.0000
Train Epoch: 12 [2172/10752 (20%)]	 Regressor Loss: -0.181263
Regressor Loss: -0.1813
Domain Loss: 0.0000
Train Epoch: 12 [2292/10752 (21%)]	 Regressor Loss: -0.559139
Regressor Loss: -0.5591
Domain Loss: 0.0000
Train Epoch: 12 [2412/10752 (22%)]	 Regressor Loss: -0.271775
Regressor Loss: -0.2718
Domain Loss: 0.0001
Train Epoch: 12 [2532/10752 (24%)]	 Regressor Loss: -0.483345
Regressor Loss: -0.4833
Domain Loss: 0.0000
Train Epoch: 12 [2652/10752 (25%)]	 Regressor Loss: -0.086471
Regressor Loss: -0.0865
Domain Loss: 0.0000
Train Epoch: 12 [2772/10752 (26%)]	 Regressor Loss: -0.514397
Regressor Loss: -0.5144
Domain Loss: 0.0000
Train Epoch: 12 [2892/10752 (27%)]	 Regressor Loss: -0.212386
Regressor Loss: -0.2124
Domain Loss: 0.0000
Train Epoch: 12 [3012/10752 (28%)]	 Regressor Loss: -0.639614
Regressor Loss: -0.6396
Domain Loss: 0.0005
Train Epoch: 12 [3132/10752 (29%)]	 Regressor Loss: -0.361937
Regressor Loss: -0.3619
Domain Loss: 0.0000
Train Epoch: 12 [3252/10752 (30%)]	 Regressor Loss: -0.625821
Regressor Loss: -0.6258
Domain Loss: 0.0000
Train Epoch: 12 [3372/10752 (31%)]	 Regressor Loss: -0.263258
Regressor Loss: -0.2633
Domain Loss: 0.0000
Train Epoch: 12 [3492/10752 (32%)]	 Regressor Loss: -0.553030
Regressor Loss: -0.5530
Domain Loss: 0.0000
Train Epoch: 12 [3612/10752 (34%)]	 Regressor Loss: -0.232334
Regressor Loss: -0.2323
Domain Loss: 0.0000
Train Epoch: 12 [3732/10752 (35%)]	 Regressor Loss: -0.583915
Regressor Loss: -0.5839
Domain Loss: 0.0001
Train Epoch: 12 [3852/10752 (36%)]	 Regressor Loss: -0.198183
Regressor Loss: -0.1982
Domain Loss: 0.0000
Train Epoch: 12 [3972/10752 (37%)]	 Regressor Loss: -0.534493
Regressor Loss: -0.5345
Domain Loss: 0.0000
Train Epoch: 12 [4092/10752 (38%)]	 Regressor Loss: -0.252739
Regressor Loss: -0.2527
Domain Loss: 0.0000
Train Epoch: 12 [4212/10752 (39%)]	 Regressor Loss: -0.486618
Regressor Loss: -0.4866
Domain Loss: 0.0000
Train Epoch: 12 [4332/10752 (40%)]	 Regressor Loss: -0.212658
Regressor Loss: -0.2127
Domain Loss: 0.0005
Train Epoch: 12 [4452/10752 (41%)]	 Regressor Loss: -0.260629
Regressor Loss: -0.2606
Domain Loss: 0.0000
Train Epoch: 12 [4572/10752 (43%)]	 Regressor Loss: -0.224677
Regressor Loss: -0.2247
Domain Loss: 0.0000
Train Epoch: 12 [4692/10752 (44%)]	 Regressor Loss: -0.275155
Regressor Loss: -0.2752
Domain Loss: 0.0000
Train Epoch: 12 [4812/10752 (45%)]	 Regressor Loss: -0.215885
Regressor Loss: -0.2159
Domain Loss: 0.0000
Train Epoch: 12 [4932/10752 (46%)]	 Regressor Loss: -0.000000
Regressor Loss: -0.0000
Domain Loss: 0.0000
Train Epoch: 12 [5052/10752 (47%)]	 Regressor Loss: -0.340078
Regressor Loss: -0.3401
Domain Loss: 0.0000
Train Epoch: 12 [5172/10752 (48%)]	 Regressor Loss: -0.150138
Regressor Loss: -0.1501
Domain Loss: 0.0000
Train Epoch: 12 [5292/10752 (49%)]	 Regressor Loss: -0.546769
Regressor Loss: -0.5468
Domain Loss: 0.0000
Train Epoch: 12 [5412/10752 (50%)]	 Regressor Loss: -0.297529
Regressor Loss: -0.2975
Domain Loss: 0.0000
Train Epoch: 12 [5532/10752 (51%)]	 Regressor Loss: -0.589372
Regressor Loss: -0.5894
Domain Loss: 0.0000
Train Epoch: 12 [5652/10752 (53%)]	 Regressor Loss: -0.234001
Regressor Loss: -0.2340
Domain Loss: 0.0000
Train Epoch: 12 [5772/10752 (54%)]	 Regressor Loss: -0.545744
Regressor Loss: -0.5457
Domain Loss: 0.0000
Train Epoch: 12 [5892/10752 (55%)]	 Regressor Loss: -0.226818
Regressor Loss: -0.2268
Domain Loss: 0.0000
Train Epoch: 12 [6012/10752 (56%)]	 Regressor Loss: -0.707078
Regressor Loss: -0.7071
Domain Loss: 0.0000
Train Epoch: 12 [6132/10752 (57%)]	 Regressor Loss: -0.502394
Regressor Loss: -0.5024
Domain Loss: 0.0000
Train Epoch: 12 [6252/10752 (58%)]	 Regressor Loss: -0.595814
Regressor Loss: -0.5958
Domain Loss: 0.0000
Train Epoch: 12 [6372/10752 (59%)]	 Regressor Loss: -0.257765
Regressor Loss: -0.2578
Domain Loss: 0.0000
Train Epoch: 12 [6492/10752 (60%)]	 Regressor Loss: -0.637475
Regressor Loss: -0.6375
Domain Loss: 0.0001
Train Epoch: 12 [6612/10752 (61%)]	 Regressor Loss: -0.257306
Regressor Loss: -0.2573
Domain Loss: 0.0000
Train Epoch: 12 [6732/10752 (63%)]	 Regressor Loss: -0.552011
Regressor Loss: -0.5520
Domain Loss: 0.0000
Train Epoch: 12 [6852/10752 (64%)]	 Regressor Loss: -0.253011
Regressor Loss: -0.2530
Domain Loss: 0.0000
Train Epoch: 12 [6972/10752 (65%)]	 Regressor Loss: -0.630297
Regressor Loss: -0.6303
Domain Loss: 0.0000
Train Epoch: 12 [7092/10752 (66%)]	 Regressor Loss: -0.239338
Regressor Loss: -0.2393
Domain Loss: 0.0000
Train Epoch: 12 [7212/10752 (67%)]	 Regressor Loss: -0.551100
Regressor Loss: -0.5511
Domain Loss: 0.0000
Train Epoch: 12 [7332/10752 (68%)]	 Regressor Loss: -0.254100
Regressor Loss: -0.2541
Domain Loss: 0.0000
Train Epoch: 12 [7452/10752 (69%)]	 Regressor Loss: -0.428562
Regressor Loss: -0.4286
Domain Loss: 0.0000
Train Epoch: 12 [7572/10752 (70%)]	 Regressor Loss: -0.253801
Regressor Loss: -0.2538
Domain Loss: 0.0000
Train Epoch: 12 [7692/10752 (72%)]	 Regressor Loss: -0.306459
Regressor Loss: -0.3065
Domain Loss: 0.0000
Train Epoch: 12 [7812/10752 (73%)]	 Regressor Loss: -0.244716
Regressor Loss: -0.2447
Domain Loss: 0.0000
Train Epoch: 12 [7932/10752 (74%)]	 Regressor Loss: -0.443859
Regressor Loss: -0.4439
Domain Loss: 0.0000
Train Epoch: 12 [8052/10752 (75%)]	 Regressor Loss: -0.261423
Regressor Loss: -0.2614
Domain Loss: 0.0000
Train Epoch: 12 [8172/10752 (76%)]	 Regressor Loss: -0.273200
Regressor Loss: -0.2732
Domain Loss: 0.0000
Train Epoch: 12 [8292/10752 (77%)]	 Regressor Loss: -0.448919
Regressor Loss: -0.4489
Domain Loss: 0.0000
Train Epoch: 12 [8412/10752 (78%)]	 Regressor Loss: -0.326136
Regressor Loss: -0.3261
Domain Loss: 0.0002
Train Epoch: 12 [8532/10752 (79%)]	 Regressor Loss: -0.540443
Regressor Loss: -0.5404
Domain Loss: 0.0000
Train Epoch: 12 [8652/10752 (80%)]	 Regressor Loss: -0.412853
Regressor Loss: -0.4129
Domain Loss: 0.0000
Train Epoch: 12 [8772/10752 (82%)]	 Regressor Loss: -0.538867
Regressor Loss: -0.5389
Domain Loss: 0.0000
Train Epoch: 12 [8892/10752 (83%)]	 Regressor Loss: -0.315367
Regressor Loss: -0.3154
Domain Loss: 0.0000
Train Epoch: 12 [9012/10752 (84%)]	 Regressor Loss: -0.531132
Regressor Loss: -0.5311
Domain Loss: 0.0000
Train Epoch: 12 [9132/10752 (85%)]	 Regressor Loss: -0.184871
Regressor Loss: -0.1849
Domain Loss: 0.0000
Train Epoch: 12 [9252/10752 (86%)]	 Regressor Loss: -0.667503
Regressor Loss: -0.6675
Domain Loss: 0.0001
Train Epoch: 12 [9372/10752 (87%)]	 Regressor Loss: -0.159534
Regressor Loss: -0.1595
Domain Loss: 0.0000
Training set: Average loss: -0.3747
Training set: Average Domain loss: 0.0007
Training set: Average Acc: 0.9997
Validation set: Average loss: -0.3543
Validation set: Average Domain loss: 0.0958
 Validation set: Average Acc: 0.9750
Training Main Encoder
Epoch  13 / 300
Train Epoch: 13 [12/10752 (0%)]	 Regressor Loss: -0.443746
Regressor Loss: -0.4437
Domain Loss: 0.0002
Train Epoch: 13 [132/10752 (1%)]	 Regressor Loss: -0.261736
Regressor Loss: -0.2617
Domain Loss: 0.0000
Train Epoch: 13 [252/10752 (2%)]	 Regressor Loss: -0.664941
Regressor Loss: -0.6649
Domain Loss: 0.0000
Train Epoch: 13 [372/10752 (3%)]	 Regressor Loss: -0.171098
Regressor Loss: -0.1711
Domain Loss: 0.0000
Train Epoch: 13 [492/10752 (5%)]	 Regressor Loss: -0.635795
Regressor Loss: -0.6358
Domain Loss: 0.0000
Train Epoch: 13 [612/10752 (6%)]	 Regressor Loss: -0.223771
Regressor Loss: -0.2238
Domain Loss: 0.0000
Train Epoch: 13 [732/10752 (7%)]	 Regressor Loss: -0.705277
Regressor Loss: -0.7053
Domain Loss: 0.0001
Train Epoch: 13 [852/10752 (8%)]	 Regressor Loss: -0.269465
Regressor Loss: -0.2695
Domain Loss: 0.0000
Train Epoch: 13 [972/10752 (9%)]	 Regressor Loss: -0.338551
Regressor Loss: -0.3386
Domain Loss: 0.0000
Train Epoch: 13 [1092/10752 (10%)]	 Regressor Loss: -0.121893
Regressor Loss: -0.1219
Domain Loss: 0.0001
Train Epoch: 13 [1212/10752 (11%)]	 Regressor Loss: -0.264884
Regressor Loss: -0.2649
Domain Loss: 0.0000
Train Epoch: 13 [1332/10752 (12%)]	 Regressor Loss: -0.318775
Regressor Loss: -0.3188
Domain Loss: 0.0000
Train Epoch: 13 [1452/10752 (14%)]	 Regressor Loss: -0.238225
Regressor Loss: -0.2382
Domain Loss: 0.0000
Train Epoch: 13 [1572/10752 (15%)]	 Regressor Loss: -0.330346
Regressor Loss: -0.3303
Domain Loss: 0.0000
Train Epoch: 13 [1692/10752 (16%)]	 Regressor Loss: -0.289200
Regressor Loss: -0.2892
Domain Loss: 0.0000
Train Epoch: 13 [1812/10752 (17%)]	 Regressor Loss: -0.360801
Regressor Loss: -0.3608
Domain Loss: 0.0000
Train Epoch: 13 [1932/10752 (18%)]	 Regressor Loss: -0.255258
Regressor Loss: -0.2553
Domain Loss: 0.0000
Train Epoch: 13 [2052/10752 (19%)]	 Regressor Loss: -0.586050
Regressor Loss: -0.5860
Domain Loss: 0.0000
Train Epoch: 13 [2172/10752 (20%)]	 Regressor Loss: -0.134417
Regressor Loss: -0.1344
Domain Loss: 0.0000
Train Epoch: 13 [2292/10752 (21%)]	 Regressor Loss: -0.530010
Regressor Loss: -0.5300
Domain Loss: 0.0000
Train Epoch: 13 [2412/10752 (22%)]	 Regressor Loss: -0.259889
Regressor Loss: -0.2599
Domain Loss: 0.0000
Train Epoch: 13 [2532/10752 (24%)]	 Regressor Loss: -0.413577
Regressor Loss: -0.4136
Domain Loss: 0.0000
Train Epoch: 13 [2652/10752 (25%)]	 Regressor Loss: -0.268961
Regressor Loss: -0.2690
Domain Loss: 0.0004
Train Epoch: 13 [2772/10752 (26%)]	 Regressor Loss: -0.711255
Regressor Loss: -0.7113
Domain Loss: 0.0012
Train Epoch: 13 [2892/10752 (27%)]	 Regressor Loss: -0.290939
Regressor Loss: -0.2909
Domain Loss: 0.0001
Train Epoch: 13 [3012/10752 (28%)]	 Regressor Loss: -0.599980
Regressor Loss: -0.6000
Domain Loss: 0.0000
Train Epoch: 13 [3132/10752 (29%)]	 Regressor Loss: -0.468935
Regressor Loss: -0.4689
Domain Loss: 0.0000
Train Epoch: 13 [3252/10752 (30%)]	 Regressor Loss: -0.640841
Regressor Loss: -0.6408
Domain Loss: 0.0000
Train Epoch: 13 [3372/10752 (31%)]	 Regressor Loss: -0.348699
Regressor Loss: -0.3487
Domain Loss: 0.0000
Train Epoch: 13 [3492/10752 (32%)]	 Regressor Loss: -0.668294
Regressor Loss: -0.6683
Domain Loss: 0.0000
Train Epoch: 13 [3612/10752 (34%)]	 Regressor Loss: -0.185685
Regressor Loss: -0.1857
Domain Loss: 0.0000
Train Epoch: 13 [3732/10752 (35%)]	 Regressor Loss: -0.544966
Regressor Loss: -0.5450
Domain Loss: 0.0000
Train Epoch: 13 [3852/10752 (36%)]	 Regressor Loss: -0.282344
Regressor Loss: -0.2823
Domain Loss: 0.0002
Train Epoch: 13 [3972/10752 (37%)]	 Regressor Loss: -0.570050
Regressor Loss: -0.5701
Domain Loss: 0.0000
Train Epoch: 13 [4092/10752 (38%)]	 Regressor Loss: -0.293507
Regressor Loss: -0.2935
Domain Loss: 0.0002
Train Epoch: 13 [4212/10752 (39%)]	 Regressor Loss: -0.477817
Regressor Loss: -0.4778
Domain Loss: 0.0000
Train Epoch: 13 [4332/10752 (40%)]	 Regressor Loss: -0.197861
Regressor Loss: -0.1979
Domain Loss: 0.0001
Train Epoch: 13 [4452/10752 (41%)]	 Regressor Loss: -0.290171
Regressor Loss: -0.2902
Domain Loss: 0.0000
Train Epoch: 13 [4572/10752 (43%)]	 Regressor Loss: -0.044244
Regressor Loss: -0.0442
Domain Loss: 0.0000
Train Epoch: 13 [4692/10752 (44%)]	 Regressor Loss: -0.344825
Regressor Loss: -0.3448
Domain Loss: 0.0000
Train Epoch: 13 [4812/10752 (45%)]	 Regressor Loss: -0.119510
Regressor Loss: -0.1195
Domain Loss: 0.0000
Train Epoch: 13 [4932/10752 (46%)]	 Regressor Loss: -0.100823
Regressor Loss: -0.1008
Domain Loss: 0.0000
Train Epoch: 13 [5052/10752 (47%)]	 Regressor Loss: -0.241431
Regressor Loss: -0.2414
Domain Loss: 0.0000
Train Epoch: 13 [5172/10752 (48%)]	 Regressor Loss: -0.205386
Regressor Loss: -0.2054
Domain Loss: 0.0000
Train Epoch: 13 [5292/10752 (49%)]	 Regressor Loss: -0.580742
Regressor Loss: -0.5807
Domain Loss: 0.0000
Train Epoch: 13 [5412/10752 (50%)]	 Regressor Loss: -0.255030
Regressor Loss: -0.2550
Domain Loss: 0.0000
Train Epoch: 13 [5532/10752 (51%)]	 Regressor Loss: -0.641945
Regressor Loss: -0.6419
Domain Loss: 0.0000
Train Epoch: 13 [5652/10752 (53%)]	 Regressor Loss: -0.282246
Regressor Loss: -0.2822
Domain Loss: 0.0000
Train Epoch: 13 [5772/10752 (54%)]	 Regressor Loss: -0.658625
Regressor Loss: -0.6586
Domain Loss: 0.0002
Train Epoch: 13 [5892/10752 (55%)]	 Regressor Loss: -0.256851
Regressor Loss: -0.2569
Domain Loss: 0.0000
Train Epoch: 13 [6012/10752 (56%)]	 Regressor Loss: -0.420275
Regressor Loss: -0.4203
Domain Loss: 0.0000
Train Epoch: 13 [6132/10752 (57%)]	 Regressor Loss: -0.312717
Regressor Loss: -0.3127
Domain Loss: 0.0000
Train Epoch: 13 [6252/10752 (58%)]	 Regressor Loss: -0.714560
Regressor Loss: -0.7146
Domain Loss: 0.0005
Train Epoch: 13 [6372/10752 (59%)]	 Regressor Loss: -0.235675
Regressor Loss: -0.2357
Domain Loss: 0.0000
Train Epoch: 13 [6492/10752 (60%)]	 Regressor Loss: -0.587982
Regressor Loss: -0.5880
Domain Loss: 0.0001
Train Epoch: 13 [6612/10752 (61%)]	 Regressor Loss: -0.333779
Regressor Loss: -0.3338
Domain Loss: 0.0000
Train Epoch: 13 [6732/10752 (63%)]	 Regressor Loss: -0.628914
Regressor Loss: -0.6289
Domain Loss: 0.0001
Train Epoch: 13 [6852/10752 (64%)]	 Regressor Loss: -0.247932
Regressor Loss: -0.2479
Domain Loss: 0.0000
Train Epoch: 13 [6972/10752 (65%)]	 Regressor Loss: -0.659864
Regressor Loss: -0.6599
Domain Loss: 0.0000
Train Epoch: 13 [7092/10752 (66%)]	 Regressor Loss: -0.269480
Regressor Loss: -0.2695
Domain Loss: 0.0000
Train Epoch: 13 [7212/10752 (67%)]	 Regressor Loss: -0.593157
Regressor Loss: -0.5932
Domain Loss: 0.0000
Train Epoch: 13 [7332/10752 (68%)]	 Regressor Loss: -0.041542
Regressor Loss: -0.0415
Domain Loss: 0.0001
Train Epoch: 13 [7452/10752 (69%)]	 Regressor Loss: -0.476972
Regressor Loss: -0.4770
Domain Loss: 0.0000
Train Epoch: 13 [7572/10752 (70%)]	 Regressor Loss: -0.128695
Regressor Loss: -0.1287
Domain Loss: 0.0000
Train Epoch: 13 [7692/10752 (72%)]	 Regressor Loss: -0.467803
Regressor Loss: -0.4678
Domain Loss: 0.0000
Train Epoch: 13 [7812/10752 (73%)]	 Regressor Loss: -0.230336
Regressor Loss: -0.2303
Domain Loss: 0.0000
Train Epoch: 13 [7932/10752 (74%)]	 Regressor Loss: -0.372156
Regressor Loss: -0.3722
Domain Loss: 0.0000
Train Epoch: 13 [8052/10752 (75%)]	 Regressor Loss: -0.364039
Regressor Loss: -0.3640
Domain Loss: 0.0001
Train Epoch: 13 [8172/10752 (76%)]	 Regressor Loss: -0.240415
Regressor Loss: -0.2404
Domain Loss: 0.0000
Train Epoch: 13 [8292/10752 (77%)]	 Regressor Loss: -0.486722
Regressor Loss: -0.4867
Domain Loss: 0.0001
Train Epoch: 13 [8412/10752 (78%)]	 Regressor Loss: -0.230784
Regressor Loss: -0.2308
Domain Loss: 0.0000
Train Epoch: 13 [8532/10752 (79%)]	 Regressor Loss: -0.565609
Regressor Loss: -0.5656
Domain Loss: 0.0000
Train Epoch: 13 [8652/10752 (80%)]	 Regressor Loss: -0.239935
Regressor Loss: -0.2399
Domain Loss: 0.0000
Train Epoch: 13 [8772/10752 (82%)]	 Regressor Loss: -0.673677
Regressor Loss: -0.6737
Domain Loss: 0.0001
Train Epoch: 13 [8892/10752 (83%)]	 Regressor Loss: -0.146810
Regressor Loss: -0.1468
Domain Loss: 0.0000
Train Epoch: 13 [9012/10752 (84%)]	 Regressor Loss: -0.656402
Regressor Loss: -0.6564
Domain Loss: 0.0197
Train Epoch: 13 [9132/10752 (85%)]	 Regressor Loss: -0.182433
Regressor Loss: -0.1824
Domain Loss: 0.0000
Train Epoch: 13 [9252/10752 (86%)]	 Regressor Loss: -0.799220
Regressor Loss: -0.7992
Domain Loss: 0.0003
Train Epoch: 13 [9372/10752 (87%)]	 Regressor Loss: -0.304029
Regressor Loss: -0.3040
Domain Loss: 0.0002
Training set: Average loss: -0.3874
Training set: Average Domain loss: 0.0001
Training set: Average Acc: 1.0000
Validation set: Average loss: -0.3753
Validation set: Average Domain loss: 0.0342
 Validation set: Average Acc: 0.9883
Training Main Encoder
Epoch  14 / 300
Train Epoch: 14 [12/10752 (0%)]	 Regressor Loss: -0.625822
Regressor Loss: -0.6258
Domain Loss: 0.0000
Train Epoch: 14 [132/10752 (1%)]	 Regressor Loss: -0.326946
Regressor Loss: -0.3269
Domain Loss: 0.0008
Train Epoch: 14 [252/10752 (2%)]	 Regressor Loss: -0.652280
Regressor Loss: -0.6523
Domain Loss: 0.0000
Train Epoch: 14 [372/10752 (3%)]	 Regressor Loss: -0.263882
Regressor Loss: -0.2639
Domain Loss: 0.0001
Train Epoch: 14 [492/10752 (5%)]	 Regressor Loss: -0.749825
Regressor Loss: -0.7498
Domain Loss: 0.0001
Train Epoch: 14 [612/10752 (6%)]	 Regressor Loss: -0.338744
Regressor Loss: -0.3387
Domain Loss: 0.0000
Train Epoch: 14 [732/10752 (7%)]	 Regressor Loss: -0.539598
Regressor Loss: -0.5396
Domain Loss: 0.0073
Train Epoch: 14 [852/10752 (8%)]	 Regressor Loss: -0.094262
Regressor Loss: -0.0943
Domain Loss: 0.0000
Train Epoch: 14 [972/10752 (9%)]	 Regressor Loss: -0.397309
Regressor Loss: -0.3973
Domain Loss: 0.0000
Train Epoch: 14 [1092/10752 (10%)]	 Regressor Loss: -0.069871
Regressor Loss: -0.0699
Domain Loss: 0.0003
Train Epoch: 14 [1212/10752 (11%)]	 Regressor Loss: -0.248365
Regressor Loss: -0.2484
Domain Loss: 0.0000
Train Epoch: 14 [1332/10752 (12%)]	 Regressor Loss: -0.285677
Regressor Loss: -0.2857
Domain Loss: 0.0000
Train Epoch: 14 [1452/10752 (14%)]	 Regressor Loss: -0.223955
Regressor Loss: -0.2240
Domain Loss: 0.0000
Train Epoch: 14 [1572/10752 (15%)]	 Regressor Loss: -0.419341
Regressor Loss: -0.4193
Domain Loss: 0.0001
Train Epoch: 14 [1692/10752 (16%)]	 Regressor Loss: -0.261174
Regressor Loss: -0.2612
Domain Loss: 0.0000
Train Epoch: 14 [1812/10752 (17%)]	 Regressor Loss: -0.418014
Regressor Loss: -0.4180
Domain Loss: 0.0000
Train Epoch: 14 [1932/10752 (18%)]	 Regressor Loss: -0.228467
Regressor Loss: -0.2285
Domain Loss: 0.0000
Train Epoch: 14 [2052/10752 (19%)]	 Regressor Loss: -0.671138
Regressor Loss: -0.6711
Domain Loss: 0.0001
Train Epoch: 14 [2172/10752 (20%)]	 Regressor Loss: -0.184320
Regressor Loss: -0.1843
Domain Loss: 0.0003
Train Epoch: 14 [2292/10752 (21%)]	 Regressor Loss: -0.480162
Regressor Loss: -0.4802
Domain Loss: 0.0000
Train Epoch: 14 [2412/10752 (22%)]	 Regressor Loss: -0.337743
Regressor Loss: -0.3377
Domain Loss: 0.0004
Train Epoch: 14 [2532/10752 (24%)]	 Regressor Loss: -0.684075
Regressor Loss: -0.6841
Domain Loss: 0.0000
Train Epoch: 14 [2652/10752 (25%)]	 Regressor Loss: -0.225417
Regressor Loss: -0.2254
Domain Loss: 0.0000
Train Epoch: 14 [2772/10752 (26%)]	 Regressor Loss: -0.584790
Regressor Loss: -0.5848
Domain Loss: 0.0002
Train Epoch: 14 [2892/10752 (27%)]	 Regressor Loss: -0.239834
Regressor Loss: -0.2398
Domain Loss: 0.0002
Train Epoch: 14 [3012/10752 (28%)]	 Regressor Loss: -0.658239
Regressor Loss: -0.6582
Domain Loss: 0.0000
Train Epoch: 14 [3132/10752 (29%)]	 Regressor Loss: -0.481636
Regressor Loss: -0.4816
Domain Loss: 0.0000
Train Epoch: 14 [3252/10752 (30%)]	 Regressor Loss: -0.735839
Regressor Loss: -0.7358
Domain Loss: 0.0000
Train Epoch: 14 [3372/10752 (31%)]	 Regressor Loss: -0.420008
Regressor Loss: -0.4200
Domain Loss: 0.0001
Train Epoch: 14 [3492/10752 (32%)]	 Regressor Loss: -0.753391
Regressor Loss: -0.7534
Domain Loss: 0.0000
Train Epoch: 14 [3612/10752 (34%)]	 Regressor Loss: -0.344935
Regressor Loss: -0.3449
Domain Loss: 0.0000
Train Epoch: 14 [3732/10752 (35%)]	 Regressor Loss: -0.523733
Regressor Loss: -0.5237
Domain Loss: 0.0000
Train Epoch: 14 [3852/10752 (36%)]	 Regressor Loss: -0.245265
Regressor Loss: -0.2453
Domain Loss: 0.0000
Train Epoch: 14 [3972/10752 (37%)]	 Regressor Loss: -0.586027
Regressor Loss: -0.5860
Domain Loss: 0.0001
Train Epoch: 14 [4092/10752 (38%)]	 Regressor Loss: -0.214868
Regressor Loss: -0.2149
Domain Loss: 0.0000
Train Epoch: 14 [4212/10752 (39%)]	 Regressor Loss: -0.481925
Regressor Loss: -0.4819
Domain Loss: 0.0000
Train Epoch: 14 [4332/10752 (40%)]	 Regressor Loss: -0.280730
Regressor Loss: -0.2807
Domain Loss: 0.0000
Train Epoch: 14 [4452/10752 (41%)]	 Regressor Loss: -0.154734
Regressor Loss: -0.1547
Domain Loss: 0.0000
Train Epoch: 14 [4572/10752 (43%)]	 Regressor Loss: -0.222562
Regressor Loss: -0.2226
Domain Loss: 0.0018
Train Epoch: 14 [4692/10752 (44%)]	 Regressor Loss: -0.281639
Regressor Loss: -0.2816
Domain Loss: 0.0000
Train Epoch: 14 [4812/10752 (45%)]	 Regressor Loss: -0.318828
Regressor Loss: -0.3188
Domain Loss: 0.0000
Train Epoch: 14 [4932/10752 (46%)]	 Regressor Loss: -0.170830
Regressor Loss: -0.1708
Domain Loss: 0.0000
Train Epoch: 14 [5052/10752 (47%)]	 Regressor Loss: -0.392490
Regressor Loss: -0.3925
Domain Loss: 0.0000
Train Epoch: 14 [5172/10752 (48%)]	 Regressor Loss: -0.254256
Regressor Loss: -0.2543
Domain Loss: 0.0001
Train Epoch: 14 [5292/10752 (49%)]	 Regressor Loss: -0.568793
Regressor Loss: -0.5688
Domain Loss: 0.0012
Train Epoch: 14 [5412/10752 (50%)]	 Regressor Loss: -0.229751
Regressor Loss: -0.2298
Domain Loss: 0.0000
Train Epoch: 14 [5532/10752 (51%)]	 Regressor Loss: -0.588827
Regressor Loss: -0.5888
Domain Loss: 0.0000
Train Epoch: 14 [5652/10752 (53%)]	 Regressor Loss: -0.233424
Regressor Loss: -0.2334
Domain Loss: 0.0000
Train Epoch: 14 [5772/10752 (54%)]	 Regressor Loss: -0.683949
Regressor Loss: -0.6839
Domain Loss: 0.0002
Train Epoch: 14 [5892/10752 (55%)]	 Regressor Loss: -0.210568
Regressor Loss: -0.2106
Domain Loss: 0.0000
Train Epoch: 14 [6012/10752 (56%)]	 Regressor Loss: -0.748924
Regressor Loss: -0.7489
Domain Loss: 0.0009
Train Epoch: 14 [6132/10752 (57%)]	 Regressor Loss: -0.377594
Regressor Loss: -0.3776
Domain Loss: 0.0000
Train Epoch: 14 [6252/10752 (58%)]	 Regressor Loss: -0.733667
Regressor Loss: -0.7337
Domain Loss: 0.0001
Train Epoch: 14 [6372/10752 (59%)]	 Regressor Loss: -0.194228
Regressor Loss: -0.1942
Domain Loss: 0.0000
Train Epoch: 14 [6492/10752 (60%)]	 Regressor Loss: -0.595778
Regressor Loss: -0.5958
Domain Loss: 0.0000
Train Epoch: 14 [6612/10752 (61%)]	 Regressor Loss: -0.169019
Regressor Loss: -0.1690
Domain Loss: 0.0000
Train Epoch: 14 [6732/10752 (63%)]	 Regressor Loss: -0.639229
Regressor Loss: -0.6392
Domain Loss: 0.0000
Train Epoch: 14 [6852/10752 (64%)]	 Regressor Loss: -0.234497
Regressor Loss: -0.2345
Domain Loss: 0.0000
Train Epoch: 14 [6972/10752 (65%)]	 Regressor Loss: -0.433735
Regressor Loss: -0.4337
Domain Loss: 0.0000
Train Epoch: 14 [7092/10752 (66%)]	 Regressor Loss: -0.143913
Regressor Loss: -0.1439
Domain Loss: 0.0000
Train Epoch: 14 [7212/10752 (67%)]	 Regressor Loss: -0.536430
Regressor Loss: -0.5364
Domain Loss: 0.0000
Train Epoch: 14 [7332/10752 (68%)]	 Regressor Loss: -0.327995
Regressor Loss: -0.3280
Domain Loss: 0.0000
Train Epoch: 14 [7452/10752 (69%)]	 Regressor Loss: -0.425870
Regressor Loss: -0.4259
Domain Loss: 0.0000
Train Epoch: 14 [7572/10752 (70%)]	 Regressor Loss: -0.244386
Regressor Loss: -0.2444
Domain Loss: 0.0000
Train Epoch: 14 [7692/10752 (72%)]	 Regressor Loss: -0.335002
Regressor Loss: -0.3350
Domain Loss: 0.0000
Train Epoch: 14 [7812/10752 (73%)]	 Regressor Loss: -0.259444
Regressor Loss: -0.2594
Domain Loss: 0.0000
Train Epoch: 14 [7932/10752 (74%)]	 Regressor Loss: -0.285527
Regressor Loss: -0.2855
Domain Loss: 0.0001
Train Epoch: 14 [8052/10752 (75%)]	 Regressor Loss: -0.409128
Regressor Loss: -0.4091
Domain Loss: 0.0036
Train Epoch: 14 [8172/10752 (76%)]	 Regressor Loss: -0.207782
Regressor Loss: -0.2078
Domain Loss: 0.0003
Train Epoch: 14 [8292/10752 (77%)]	 Regressor Loss: -0.506215
Regressor Loss: -0.5062
Domain Loss: 0.0001
Train Epoch: 14 [8412/10752 (78%)]	 Regressor Loss: -0.309294
Regressor Loss: -0.3093
Domain Loss: 0.0000
Train Epoch: 14 [8532/10752 (79%)]	 Regressor Loss: -0.568887
Regressor Loss: -0.5689
Domain Loss: 0.0000
Train Epoch: 14 [8652/10752 (80%)]	 Regressor Loss: -0.300545
Regressor Loss: -0.3005
Domain Loss: 0.0000
Train Epoch: 14 [8772/10752 (82%)]	 Regressor Loss: -0.579212
Regressor Loss: -0.5792
Domain Loss: 0.0000
Train Epoch: 14 [8892/10752 (83%)]	 Regressor Loss: -0.125040
Regressor Loss: -0.1250
Domain Loss: 0.0000
Train Epoch: 14 [9012/10752 (84%)]	 Regressor Loss: -0.662471
Regressor Loss: -0.6625
Domain Loss: 0.0000
Train Epoch: 14 [9132/10752 (85%)]	 Regressor Loss: -0.223516
Regressor Loss: -0.2235
Domain Loss: 0.0000
Train Epoch: 14 [9252/10752 (86%)]	 Regressor Loss: -0.608817
Regressor Loss: -0.6088
Domain Loss: 0.0000
Train Epoch: 14 [9372/10752 (87%)]	 Regressor Loss: -0.249159
Regressor Loss: -0.2492
Domain Loss: 0.0000
Training set: Average loss: -0.3960
Training set: Average Domain loss: 0.0010
Training set: Average Acc: 0.9997
Validation set: Average loss: -0.3830
Validation set: Average Domain loss: 0.0162
 Validation set: Average Acc: 0.9925
Training Main Encoder
Epoch  15 / 300
Train Epoch: 15 [12/10752 (0%)]	 Regressor Loss: -0.603897
Regressor Loss: -0.6039
Domain Loss: 0.0000
Train Epoch: 15 [132/10752 (1%)]	 Regressor Loss: -0.150107
Regressor Loss: -0.1501
Domain Loss: 0.0000
Train Epoch: 15 [252/10752 (2%)]	 Regressor Loss: -0.701906
Regressor Loss: -0.7019
Domain Loss: 0.0000
Train Epoch: 15 [372/10752 (3%)]	 Regressor Loss: -0.253706
Regressor Loss: -0.2537
Domain Loss: 0.0003
Train Epoch: 15 [492/10752 (5%)]	 Regressor Loss: -0.700873
Regressor Loss: -0.7009
Domain Loss: 0.0000
Train Epoch: 15 [612/10752 (6%)]	 Regressor Loss: -0.262082
Regressor Loss: -0.2621
Domain Loss: 0.0000
Train Epoch: 15 [732/10752 (7%)]	 Regressor Loss: -0.766884
Regressor Loss: -0.7669
Domain Loss: 0.0001
Train Epoch: 15 [852/10752 (8%)]	 Regressor Loss: -0.348507
Regressor Loss: -0.3485
Domain Loss: 0.0001
Train Epoch: 15 [972/10752 (9%)]	 Regressor Loss: -0.398337
Regressor Loss: -0.3983
Domain Loss: 0.0000
Train Epoch: 15 [1092/10752 (10%)]	 Regressor Loss: -0.198203
Regressor Loss: -0.1982
Domain Loss: 0.0000
Train Epoch: 15 [1212/10752 (11%)]	 Regressor Loss: -0.199882
Regressor Loss: -0.1999
Domain Loss: 0.0000
Train Epoch: 15 [1332/10752 (12%)]	 Regressor Loss: -0.266939
Regressor Loss: -0.2669
Domain Loss: 0.0000
Train Epoch: 15 [1452/10752 (14%)]	 Regressor Loss: -0.211962
Regressor Loss: -0.2120
Domain Loss: 0.0000
Train Epoch: 15 [1572/10752 (15%)]	 Regressor Loss: -0.338140
Regressor Loss: -0.3381
Domain Loss: 0.0000
Train Epoch: 15 [1692/10752 (16%)]	 Regressor Loss: -0.235996
Regressor Loss: -0.2360
Domain Loss: 0.0000
Train Epoch: 15 [1812/10752 (17%)]	 Regressor Loss: -0.515795
Regressor Loss: -0.5158
Domain Loss: 0.0000
Train Epoch: 15 [1932/10752 (18%)]	 Regressor Loss: -0.128954
Regressor Loss: -0.1290
Domain Loss: 0.0000
Train Epoch: 15 [2052/10752 (19%)]	 Regressor Loss: -0.670656
Regressor Loss: -0.6707
Domain Loss: 0.0000
Train Epoch: 15 [2172/10752 (20%)]	 Regressor Loss: -0.189373
Regressor Loss: -0.1894
Domain Loss: 0.0000
Train Epoch: 15 [2292/10752 (21%)]	 Regressor Loss: -0.666942
Regressor Loss: -0.6669
Domain Loss: 0.0000
Train Epoch: 15 [2412/10752 (22%)]	 Regressor Loss: -0.348771
Regressor Loss: -0.3488
Domain Loss: 0.0000
Train Epoch: 15 [2532/10752 (24%)]	 Regressor Loss: -0.750936
Regressor Loss: -0.7509
Domain Loss: 0.0000
Train Epoch: 15 [2652/10752 (25%)]	 Regressor Loss: -0.235297
Regressor Loss: -0.2353
Domain Loss: 0.0000
Train Epoch: 15 [2772/10752 (26%)]	 Regressor Loss: -0.669997
Regressor Loss: -0.6700
Domain Loss: 0.0000
Train Epoch: 15 [2892/10752 (27%)]	 Regressor Loss: -0.277077
Regressor Loss: -0.2771
Domain Loss: 0.0000
Train Epoch: 15 [3012/10752 (28%)]	 Regressor Loss: -0.379386
Regressor Loss: -0.3794
Domain Loss: 0.0000
Train Epoch: 15 [3132/10752 (29%)]	 Regressor Loss: -0.582604
Regressor Loss: -0.5826
Domain Loss: 0.0000
Train Epoch: 15 [3252/10752 (30%)]	 Regressor Loss: -0.668874
Regressor Loss: -0.6689
Domain Loss: 0.0000
Train Epoch: 15 [3372/10752 (31%)]	 Regressor Loss: -0.204032
Regressor Loss: -0.2040
Domain Loss: 0.0000
Train Epoch: 15 [3492/10752 (32%)]	 Regressor Loss: -0.692007
Regressor Loss: -0.6920
Domain Loss: 0.0000
Train Epoch: 15 [3612/10752 (34%)]	 Regressor Loss: -0.000000
Regressor Loss: -0.0000
Domain Loss: 0.0000
Train Epoch: 15 [3732/10752 (35%)]	 Regressor Loss: -0.669872
Regressor Loss: -0.6699
Domain Loss: 0.0000
Train Epoch: 15 [3852/10752 (36%)]	 Regressor Loss: -0.329905
Regressor Loss: -0.3299
Domain Loss: 0.0000
Train Epoch: 15 [3972/10752 (37%)]	 Regressor Loss: -0.617455
Regressor Loss: -0.6175
Domain Loss: 0.0000
Train Epoch: 15 [4092/10752 (38%)]	 Regressor Loss: -0.268435
Regressor Loss: -0.2684
Domain Loss: 0.0000
Train Epoch: 15 [4212/10752 (39%)]	 Regressor Loss: -0.429624
Regressor Loss: -0.4296
Domain Loss: 0.0000
Train Epoch: 15 [4332/10752 (40%)]	 Regressor Loss: -0.299521
Regressor Loss: -0.2995
Domain Loss: 0.0000
Train Epoch: 15 [4452/10752 (41%)]	 Regressor Loss: -0.477728
Regressor Loss: -0.4777
Domain Loss: 0.0000
Train Epoch: 15 [4572/10752 (43%)]	 Regressor Loss: -0.246601
Regressor Loss: -0.2466
Domain Loss: 0.0000
Train Epoch: 15 [4692/10752 (44%)]	 Regressor Loss: -0.370989
Regressor Loss: -0.3710
Domain Loss: 0.0000
Train Epoch: 15 [4812/10752 (45%)]	 Regressor Loss: -0.326303
Regressor Loss: -0.3263
Domain Loss: 0.0002
Train Epoch: 15 [4932/10752 (46%)]	 Regressor Loss: -0.255926
Regressor Loss: -0.2559
Domain Loss: 0.1899
Train Epoch: 15 [5052/10752 (47%)]	 Regressor Loss: -0.379686
Regressor Loss: -0.3797
Domain Loss: 0.0000
Train Epoch: 15 [5172/10752 (48%)]	 Regressor Loss: -0.208094
Regressor Loss: -0.2081
Domain Loss: 0.0000
Train Epoch: 15 [5292/10752 (49%)]	 Regressor Loss: -0.428471
Regressor Loss: -0.4285
Domain Loss: 0.0000
Train Epoch: 15 [5412/10752 (50%)]	 Regressor Loss: -0.210630
Regressor Loss: -0.2106
Domain Loss: 0.0000
Train Epoch: 15 [5532/10752 (51%)]	 Regressor Loss: -0.739748
Regressor Loss: -0.7397
Domain Loss: 0.0000
Train Epoch: 15 [5652/10752 (53%)]	 Regressor Loss: -0.261239
Regressor Loss: -0.2612
Domain Loss: 0.0000
Train Epoch: 15 [5772/10752 (54%)]	 Regressor Loss: -0.412900
Regressor Loss: -0.4129
Domain Loss: 0.0000
Train Epoch: 15 [5892/10752 (55%)]	 Regressor Loss: -0.280115
Regressor Loss: -0.2801
Domain Loss: 0.0004
Train Epoch: 15 [6012/10752 (56%)]	 Regressor Loss: -0.706393
Regressor Loss: -0.7064
Domain Loss: 0.0000
Train Epoch: 15 [6132/10752 (57%)]	 Regressor Loss: -0.537328
Regressor Loss: -0.5373
Domain Loss: 0.0000
Train Epoch: 15 [6252/10752 (58%)]	 Regressor Loss: -0.736517
Regressor Loss: -0.7365
Domain Loss: 0.0000
Train Epoch: 15 [6372/10752 (59%)]	 Regressor Loss: -0.373384
Regressor Loss: -0.3734
Domain Loss: 0.0000
Train Epoch: 15 [6492/10752 (60%)]	 Regressor Loss: -0.781705
Regressor Loss: -0.7817
Domain Loss: 0.0001
Train Epoch: 15 [6612/10752 (61%)]	 Regressor Loss: -0.365403
Regressor Loss: -0.3654
Domain Loss: 0.0000
Train Epoch: 15 [6732/10752 (63%)]	 Regressor Loss: -0.420262
Regressor Loss: -0.4203
Domain Loss: 0.0000
Train Epoch: 15 [6852/10752 (64%)]	 Regressor Loss: -0.245415
Regressor Loss: -0.2454
Domain Loss: 0.0000
Train Epoch: 15 [6972/10752 (65%)]	 Regressor Loss: -0.645679
Regressor Loss: -0.6457
Domain Loss: 0.0000
Train Epoch: 15 [7092/10752 (66%)]	 Regressor Loss: -0.123255
Regressor Loss: -0.1233
Domain Loss: 0.0000
Train Epoch: 15 [7212/10752 (67%)]	 Regressor Loss: -0.492653
Regressor Loss: -0.4927
Domain Loss: 0.0000
Train Epoch: 15 [7332/10752 (68%)]	 Regressor Loss: -0.146181
Regressor Loss: -0.1462
Domain Loss: 0.0000
Train Epoch: 15 [7452/10752 (69%)]	 Regressor Loss: -0.626264
Regressor Loss: -0.6263
Domain Loss: 0.0000
Train Epoch: 15 [7572/10752 (70%)]	 Regressor Loss: -0.296344
Regressor Loss: -0.2963
Domain Loss: 0.0000
Train Epoch: 15 [7692/10752 (72%)]	 Regressor Loss: -0.271612
Regressor Loss: -0.2716
Domain Loss: 0.0000
Train Epoch: 15 [7812/10752 (73%)]	 Regressor Loss: -0.147740
Regressor Loss: -0.1477
Domain Loss: 0.0000
Train Epoch: 15 [7932/10752 (74%)]	 Regressor Loss: -0.414020
Regressor Loss: -0.4140
Domain Loss: 0.0000
Train Epoch: 15 [8052/10752 (75%)]	 Regressor Loss: -0.351731
Regressor Loss: -0.3517
Domain Loss: 0.0000
Train Epoch: 15 [8172/10752 (76%)]	 Regressor Loss: -0.357336
Regressor Loss: -0.3573
Domain Loss: 0.0000
Train Epoch: 15 [8292/10752 (77%)]	 Regressor Loss: -0.455706
Regressor Loss: -0.4557
Domain Loss: 0.0000
Train Epoch: 15 [8412/10752 (78%)]	 Regressor Loss: -0.126642
Regressor Loss: -0.1266
Domain Loss: 0.0000
Train Epoch: 15 [8532/10752 (79%)]	 Regressor Loss: -0.539448
Regressor Loss: -0.5394
Domain Loss: 0.0000
Train Epoch: 15 [8652/10752 (80%)]	 Regressor Loss: -0.411721
Regressor Loss: -0.4117
Domain Loss: 0.0000
Train Epoch: 15 [8772/10752 (82%)]	 Regressor Loss: -0.573999
Regressor Loss: -0.5740
Domain Loss: 0.0000
Train Epoch: 15 [8892/10752 (83%)]	 Regressor Loss: -0.225985
Regressor Loss: -0.2260
Domain Loss: 0.0000
Train Epoch: 15 [9012/10752 (84%)]	 Regressor Loss: -0.675573
Regressor Loss: -0.6756
Domain Loss: 0.0000
Train Epoch: 15 [9132/10752 (85%)]	 Regressor Loss: -0.270645
Regressor Loss: -0.2706
Domain Loss: 0.0000
Train Epoch: 15 [9252/10752 (86%)]	 Regressor Loss: -0.494841
Regressor Loss: -0.4948
Domain Loss: 0.0000
Train Epoch: 15 [9372/10752 (87%)]	 Regressor Loss: -0.347015
Regressor Loss: -0.3470
Domain Loss: 0.0000
Training set: Average loss: -0.4134
Training set: Average Domain loss: 0.0009
Training set: Average Acc: 0.9996
Validation set: Average loss: -0.3945
Validation set: Average Domain loss: 0.0058
 Validation set: Average Acc: 0.9983
Training Main Encoder
Epoch  16 / 300
Train Epoch: 16 [12/10752 (0%)]	 Regressor Loss: -0.495322
Regressor Loss: -0.4953
Domain Loss: 0.0000
Train Epoch: 16 [132/10752 (1%)]	 Regressor Loss: -0.199514
Regressor Loss: -0.1995
Domain Loss: 0.0000
Train Epoch: 16 [252/10752 (2%)]	 Regressor Loss: -0.590362
Regressor Loss: -0.5904
Domain Loss: 0.0000
Train Epoch: 16 [372/10752 (3%)]	 Regressor Loss: -0.228027
Regressor Loss: -0.2280
Domain Loss: 0.0000
Train Epoch: 16 [492/10752 (5%)]	 Regressor Loss: -0.735004
Regressor Loss: -0.7350
Domain Loss: 0.0000
Train Epoch: 16 [612/10752 (6%)]	 Regressor Loss: -0.353243
Regressor Loss: -0.3532
Domain Loss: 0.0000
Train Epoch: 16 [732/10752 (7%)]	 Regressor Loss: -0.674073
Regressor Loss: -0.6741
Domain Loss: 0.0000
Train Epoch: 16 [852/10752 (8%)]	 Regressor Loss: -0.457430
Regressor Loss: -0.4574
Domain Loss: 0.0003
Train Epoch: 16 [972/10752 (9%)]	 Regressor Loss: -0.351436
Regressor Loss: -0.3514
Domain Loss: 0.0000
Train Epoch: 16 [1092/10752 (10%)]	 Regressor Loss: -0.206506
Regressor Loss: -0.2065
Domain Loss: 0.0000
Train Epoch: 16 [1212/10752 (11%)]	 Regressor Loss: -0.258602
Regressor Loss: -0.2586
Domain Loss: 0.0000
Train Epoch: 16 [1332/10752 (12%)]	 Regressor Loss: -0.372170
Regressor Loss: -0.3722
Domain Loss: 0.0000
Train Epoch: 16 [1452/10752 (14%)]	 Regressor Loss: -0.298866
Regressor Loss: -0.2989
Domain Loss: 0.0000
Train Epoch: 16 [1572/10752 (15%)]	 Regressor Loss: -0.462624
Regressor Loss: -0.4626
Domain Loss: 0.0000
Train Epoch: 16 [1692/10752 (16%)]	 Regressor Loss: -0.296480
Regressor Loss: -0.2965
Domain Loss: 0.0000
Train Epoch: 16 [1812/10752 (17%)]	 Regressor Loss: -0.482621
Regressor Loss: -0.4826
Domain Loss: 0.0004
Train Epoch: 16 [1932/10752 (18%)]	 Regressor Loss: -0.249504
Regressor Loss: -0.2495
Domain Loss: 0.0000
Train Epoch: 16 [2052/10752 (19%)]	 Regressor Loss: -0.557208
Regressor Loss: -0.5572
Domain Loss: 0.0000
Train Epoch: 16 [2172/10752 (20%)]	 Regressor Loss: -0.278744
Regressor Loss: -0.2787
Domain Loss: 0.0000
Train Epoch: 16 [2292/10752 (21%)]	 Regressor Loss: -0.486372
Regressor Loss: -0.4864
Domain Loss: 0.0000
Train Epoch: 16 [2412/10752 (22%)]	 Regressor Loss: -0.266077
Regressor Loss: -0.2661
Domain Loss: 0.0000
Train Epoch: 16 [2532/10752 (24%)]	 Regressor Loss: -0.649698
Regressor Loss: -0.6497
Domain Loss: 0.0000
Train Epoch: 16 [2652/10752 (25%)]	 Regressor Loss: -0.277435
Regressor Loss: -0.2774
Domain Loss: 0.0000
Train Epoch: 16 [2772/10752 (26%)]	 Regressor Loss: -0.607567
Regressor Loss: -0.6076
Domain Loss: 0.0000
Train Epoch: 16 [2892/10752 (27%)]	 Regressor Loss: -0.327672
Regressor Loss: -0.3277
Domain Loss: 0.0001
Train Epoch: 16 [3012/10752 (28%)]	 Regressor Loss: -0.673285
Regressor Loss: -0.6733
Domain Loss: 0.0000
Train Epoch: 16 [3132/10752 (29%)]	 Regressor Loss: -0.279531
Regressor Loss: -0.2795
Domain Loss: 0.0000
Train Epoch: 16 [3252/10752 (30%)]	 Regressor Loss: -0.812278
Regressor Loss: -0.8123
Domain Loss: 0.0000
Train Epoch: 16 [3372/10752 (31%)]	 Regressor Loss: -0.163934
Regressor Loss: -0.1639
Domain Loss: 0.0002
Train Epoch: 16 [3492/10752 (32%)]	 Regressor Loss: -0.573717
Regressor Loss: -0.5737
Domain Loss: 0.0000
Train Epoch: 16 [3612/10752 (34%)]	 Regressor Loss: -0.234054
Regressor Loss: -0.2341
Domain Loss: 0.0000
Train Epoch: 16 [3732/10752 (35%)]	 Regressor Loss: -0.741568
Regressor Loss: -0.7416
Domain Loss: 0.0000
Train Epoch: 16 [3852/10752 (36%)]	 Regressor Loss: -0.356874
Regressor Loss: -0.3569
Domain Loss: 0.0000
Train Epoch: 16 [3972/10752 (37%)]	 Regressor Loss: -0.511034
Regressor Loss: -0.5110
Domain Loss: 0.0000
Train Epoch: 16 [4092/10752 (38%)]	 Regressor Loss: -0.345742
Regressor Loss: -0.3457
Domain Loss: 0.0000
Train Epoch: 16 [4212/10752 (39%)]	 Regressor Loss: -0.462378
Regressor Loss: -0.4624
Domain Loss: 0.0000
Train Epoch: 16 [4332/10752 (40%)]	 Regressor Loss: -0.351976
Regressor Loss: -0.3520
Domain Loss: 0.0000
Train Epoch: 16 [4452/10752 (41%)]	 Regressor Loss: -0.263240
Regressor Loss: -0.2632
Domain Loss: 0.0000
Train Epoch: 16 [4572/10752 (43%)]	 Regressor Loss: -0.196504
Regressor Loss: -0.1965
Domain Loss: 0.0000
Train Epoch: 16 [4692/10752 (44%)]	 Regressor Loss: -0.217981
Regressor Loss: -0.2180
Domain Loss: 0.0000
Train Epoch: 16 [4812/10752 (45%)]	 Regressor Loss: -0.384691
Regressor Loss: -0.3847
Domain Loss: 0.0000
Train Epoch: 16 [4932/10752 (46%)]	 Regressor Loss: -0.219172
Regressor Loss: -0.2192
Domain Loss: 0.0000
Train Epoch: 16 [5052/10752 (47%)]	 Regressor Loss: -0.378782
Regressor Loss: -0.3788
Domain Loss: 0.0000
Train Epoch: 16 [5172/10752 (48%)]	 Regressor Loss: -0.297332
Regressor Loss: -0.2973
Domain Loss: 0.0000
Train Epoch: 16 [5292/10752 (49%)]	 Regressor Loss: -0.623279
Regressor Loss: -0.6233
Domain Loss: 0.0000
Train Epoch: 16 [5412/10752 (50%)]	 Regressor Loss: -0.293094
Regressor Loss: -0.2931
Domain Loss: 0.0002
Train Epoch: 16 [5532/10752 (51%)]	 Regressor Loss: -0.753556
Regressor Loss: -0.7536
Domain Loss: 0.0000
Train Epoch: 16 [5652/10752 (53%)]	 Regressor Loss: -0.367071
Regressor Loss: -0.3671
Domain Loss: 0.0000
Train Epoch: 16 [5772/10752 (54%)]	 Regressor Loss: -0.754778
Regressor Loss: -0.7548
Domain Loss: 0.0002
Train Epoch: 16 [5892/10752 (55%)]	 Regressor Loss: -0.183404
Regressor Loss: -0.1834
Domain Loss: 0.0000
Train Epoch: 16 [6012/10752 (56%)]	 Regressor Loss: -0.689610
Regressor Loss: -0.6896
Domain Loss: 0.0000
Train Epoch: 16 [6132/10752 (57%)]	 Regressor Loss: -0.752555
Regressor Loss: -0.7526
Domain Loss: 0.0000
Train Epoch: 16 [6252/10752 (58%)]	 Regressor Loss: -0.702118
Regressor Loss: -0.7021
Domain Loss: 0.0001
Train Epoch: 16 [6372/10752 (59%)]	 Regressor Loss: -0.181858
Regressor Loss: -0.1819
Domain Loss: 0.0000
Train Epoch: 16 [6492/10752 (60%)]	 Regressor Loss: -0.625414
Regressor Loss: -0.6254
Domain Loss: 0.0002
Train Epoch: 16 [6612/10752 (61%)]	 Regressor Loss: -0.275702
Regressor Loss: -0.2757
Domain Loss: 0.0001
Train Epoch: 16 [6732/10752 (63%)]	 Regressor Loss: -0.628544
Regressor Loss: -0.6285
Domain Loss: 0.0000
Train Epoch: 16 [6852/10752 (64%)]	 Regressor Loss: -0.317574
Regressor Loss: -0.3176
Domain Loss: 0.0000
Train Epoch: 16 [6972/10752 (65%)]	 Regressor Loss: -0.749815
Regressor Loss: -0.7498
Domain Loss: 0.0000
Train Epoch: 16 [7092/10752 (66%)]	 Regressor Loss: -0.223057
Regressor Loss: -0.2231
Domain Loss: 0.0000
Train Epoch: 16 [7212/10752 (67%)]	 Regressor Loss: -0.647108
Regressor Loss: -0.6471
Domain Loss: 0.0001
Train Epoch: 16 [7332/10752 (68%)]	 Regressor Loss: -0.231794
Regressor Loss: -0.2318
Domain Loss: 0.0000
Train Epoch: 16 [7452/10752 (69%)]	 Regressor Loss: -0.581761
Regressor Loss: -0.5818
Domain Loss: 0.0000
Train Epoch: 16 [7572/10752 (70%)]	 Regressor Loss: -0.377084
Regressor Loss: -0.3771
Domain Loss: 0.0000
Train Epoch: 16 [7692/10752 (72%)]	 Regressor Loss: -0.373225
Regressor Loss: -0.3732
Domain Loss: 0.0001
Train Epoch: 16 [7812/10752 (73%)]	 Regressor Loss: -0.237815
Regressor Loss: -0.2378
Domain Loss: 0.0000
Train Epoch: 16 [7932/10752 (74%)]	 Regressor Loss: -0.090797
Regressor Loss: -0.0908
Domain Loss: 0.0000
Train Epoch: 16 [8052/10752 (75%)]	 Regressor Loss: -0.209240
Regressor Loss: -0.2092
Domain Loss: 0.0000
Train Epoch: 16 [8172/10752 (76%)]	 Regressor Loss: -0.225970
Regressor Loss: -0.2260
Domain Loss: 0.0000
Train Epoch: 16 [8292/10752 (77%)]	 Regressor Loss: -0.457094
Regressor Loss: -0.4571
Domain Loss: 0.0000
Train Epoch: 16 [8412/10752 (78%)]	 Regressor Loss: -0.266795
Regressor Loss: -0.2668
Domain Loss: 0.0000
Train Epoch: 16 [8532/10752 (79%)]	 Regressor Loss: -0.453299
Regressor Loss: -0.4533
Domain Loss: 0.0000
Train Epoch: 16 [8652/10752 (80%)]	 Regressor Loss: -0.332942
Regressor Loss: -0.3329
Domain Loss: 0.0000
Train Epoch: 16 [8772/10752 (82%)]	 Regressor Loss: -0.597154
Regressor Loss: -0.5972
Domain Loss: 0.0000
Train Epoch: 16 [8892/10752 (83%)]	 Regressor Loss: -0.299541
Regressor Loss: -0.2995
Domain Loss: 0.0000
Train Epoch: 16 [9012/10752 (84%)]	 Regressor Loss: -0.710971
Regressor Loss: -0.7110
Domain Loss: 0.0000
Train Epoch: 16 [9132/10752 (85%)]	 Regressor Loss: -0.303895
Regressor Loss: -0.3039
Domain Loss: 0.0001
Train Epoch: 16 [9252/10752 (86%)]	 Regressor Loss: -0.743526
Regressor Loss: -0.7435
Domain Loss: 0.0000
Train Epoch: 16 [9372/10752 (87%)]	 Regressor Loss: -0.325840
Regressor Loss: -0.3258
Domain Loss: 0.0000
Training set: Average loss: -0.4226
Training set: Average Domain loss: 0.0001
Training set: Average Acc: 1.0000
Validation set: Average loss: -0.3976
Validation set: Average Domain loss: 0.0091
 Validation set: Average Acc: 0.9975
Training Main Encoder
Epoch  17 / 300
Train Epoch: 17 [12/10752 (0%)]	 Regressor Loss: -0.618762
Regressor Loss: -0.6188
Domain Loss: 0.0001
Train Epoch: 17 [132/10752 (1%)]	 Regressor Loss: -0.306959
Regressor Loss: -0.3070
Domain Loss: 0.0000
Train Epoch: 17 [252/10752 (2%)]	 Regressor Loss: -0.629237
Regressor Loss: -0.6292
Domain Loss: 0.0003
Train Epoch: 17 [372/10752 (3%)]	 Regressor Loss: -0.338020
Regressor Loss: -0.3380
Domain Loss: 0.0000
Train Epoch: 17 [492/10752 (5%)]	 Regressor Loss: -0.618283
Regressor Loss: -0.6183
Domain Loss: 0.0001
Train Epoch: 17 [612/10752 (6%)]	 Regressor Loss: -0.339960
Regressor Loss: -0.3400
Domain Loss: 0.0002
Train Epoch: 17 [732/10752 (7%)]	 Regressor Loss: -0.768183
Regressor Loss: -0.7682
Domain Loss: 0.0003
Train Epoch: 17 [852/10752 (8%)]	 Regressor Loss: -0.354347
Regressor Loss: -0.3543
Domain Loss: 0.0000
Train Epoch: 17 [972/10752 (9%)]	 Regressor Loss: -0.445094
Regressor Loss: -0.4451
Domain Loss: 0.0000
Train Epoch: 17 [1092/10752 (10%)]	 Regressor Loss: -0.228214
Regressor Loss: -0.2282
Domain Loss: 0.0000
Train Epoch: 17 [1212/10752 (11%)]	 Regressor Loss: -0.468869
Regressor Loss: -0.4689
Domain Loss: 0.0000
Train Epoch: 17 [1332/10752 (12%)]	 Regressor Loss: -0.314418
Regressor Loss: -0.3144
Domain Loss: 0.0014
Train Epoch: 17 [1452/10752 (14%)]	 Regressor Loss: -0.201806
Regressor Loss: -0.2018
Domain Loss: 0.0000
Train Epoch: 17 [1572/10752 (15%)]	 Regressor Loss: -0.346563
Regressor Loss: -0.3466
Domain Loss: 0.0000
Train Epoch: 17 [1692/10752 (16%)]	 Regressor Loss: -0.375758
Regressor Loss: -0.3758
Domain Loss: 0.0000
Train Epoch: 17 [1812/10752 (17%)]	 Regressor Loss: -0.251421
Regressor Loss: -0.2514
Domain Loss: 0.0000
Train Epoch: 17 [1932/10752 (18%)]	 Regressor Loss: -0.227104
Regressor Loss: -0.2271
Domain Loss: 0.0002
Train Epoch: 17 [2052/10752 (19%)]	 Regressor Loss: -0.600368
Regressor Loss: -0.6004
Domain Loss: 0.0002
Train Epoch: 17 [2172/10752 (20%)]	 Regressor Loss: -0.165056
Regressor Loss: -0.1651
Domain Loss: 0.0000
Train Epoch: 17 [2292/10752 (21%)]	 Regressor Loss: -0.672784
Regressor Loss: -0.6728
Domain Loss: 0.0000
Train Epoch: 17 [2412/10752 (22%)]	 Regressor Loss: -0.278073
Regressor Loss: -0.2781
Domain Loss: 0.0001
Train Epoch: 17 [2532/10752 (24%)]	 Regressor Loss: -0.738797
Regressor Loss: -0.7388
Domain Loss: 0.0000
Train Epoch: 17 [2652/10752 (25%)]	 Regressor Loss: -0.258669
Regressor Loss: -0.2587
Domain Loss: 0.0000
Train Epoch: 17 [2772/10752 (26%)]	 Regressor Loss: -0.740202
Regressor Loss: -0.7402
Domain Loss: 0.0000
Train Epoch: 17 [2892/10752 (27%)]	 Regressor Loss: -0.317967
Regressor Loss: -0.3180
Domain Loss: 0.0000
Train Epoch: 17 [3012/10752 (28%)]	 Regressor Loss: -0.587877
Regressor Loss: -0.5879
Domain Loss: 0.0000
Train Epoch: 17 [3132/10752 (29%)]	 Regressor Loss: -0.427995
Regressor Loss: -0.4280
Domain Loss: 0.0001
Train Epoch: 17 [3252/10752 (30%)]	 Regressor Loss: -0.703199
Regressor Loss: -0.7032
Domain Loss: 0.0000
Train Epoch: 17 [3372/10752 (31%)]	 Regressor Loss: -0.337033
Regressor Loss: -0.3370
Domain Loss: 0.0002
Train Epoch: 17 [3492/10752 (32%)]	 Regressor Loss: -0.709180
Regressor Loss: -0.7092
Domain Loss: 0.0002
Train Epoch: 17 [3612/10752 (34%)]	 Regressor Loss: -0.367057
Regressor Loss: -0.3671
Domain Loss: 0.0000
Train Epoch: 17 [3732/10752 (35%)]	 Regressor Loss: -0.763870
Regressor Loss: -0.7639
Domain Loss: 0.0000
Train Epoch: 17 [3852/10752 (36%)]	 Regressor Loss: -0.366729
Regressor Loss: -0.3667
Domain Loss: 0.0000
Train Epoch: 17 [3972/10752 (37%)]	 Regressor Loss: -0.711722
Regressor Loss: -0.7117
Domain Loss: 0.0000
Train Epoch: 17 [4092/10752 (38%)]	 Regressor Loss: -0.286572
Regressor Loss: -0.2866
Domain Loss: 0.0000
Train Epoch: 17 [4212/10752 (39%)]	 Regressor Loss: -0.457369
Regressor Loss: -0.4574
Domain Loss: 0.0000
Train Epoch: 17 [4332/10752 (40%)]	 Regressor Loss: -0.275239
Regressor Loss: -0.2752
Domain Loss: 0.0000
Train Epoch: 17 [4452/10752 (41%)]	 Regressor Loss: -0.337846
Regressor Loss: -0.3378
Domain Loss: 0.0000
Train Epoch: 17 [4572/10752 (43%)]	 Regressor Loss: -0.224263
Regressor Loss: -0.2243
Domain Loss: 0.0000
Train Epoch: 17 [4692/10752 (44%)]	 Regressor Loss: -0.324325
Regressor Loss: -0.3243
Domain Loss: 0.0000
Train Epoch: 17 [4812/10752 (45%)]	 Regressor Loss: -0.391560
Regressor Loss: -0.3916
Domain Loss: 0.0000
Train Epoch: 17 [4932/10752 (46%)]	 Regressor Loss: -0.332602
Regressor Loss: -0.3326
Domain Loss: 0.0000
Train Epoch: 17 [5052/10752 (47%)]	 Regressor Loss: -0.443101
Regressor Loss: -0.4431
Domain Loss: 0.0000
Train Epoch: 17 [5172/10752 (48%)]	 Regressor Loss: -0.242798
Regressor Loss: -0.2428
Domain Loss: 0.0000
Train Epoch: 17 [5292/10752 (49%)]	 Regressor Loss: -0.546934
Regressor Loss: -0.5469
Domain Loss: 0.0000
Train Epoch: 17 [5412/10752 (50%)]	 Regressor Loss: -0.273735
Regressor Loss: -0.2737
Domain Loss: 0.0001
Train Epoch: 17 [5532/10752 (51%)]	 Regressor Loss: -0.593724
Regressor Loss: -0.5937
Domain Loss: 0.0000
Train Epoch: 17 [5652/10752 (53%)]	 Regressor Loss: -0.157082
Regressor Loss: -0.1571
Domain Loss: 0.0000
Train Epoch: 17 [5772/10752 (54%)]	 Regressor Loss: -0.641897
Regressor Loss: -0.6419
Domain Loss: 0.0000
Train Epoch: 17 [5892/10752 (55%)]	 Regressor Loss: -0.340929
Regressor Loss: -0.3409
Domain Loss: 0.0001
Train Epoch: 17 [6012/10752 (56%)]	 Regressor Loss: -0.782239
Regressor Loss: -0.7822
Domain Loss: 0.0000
Train Epoch: 17 [6132/10752 (57%)]	 Regressor Loss: -0.467213
Regressor Loss: -0.4672
Domain Loss: 0.0000
Train Epoch: 17 [6252/10752 (58%)]	 Regressor Loss: -0.754753
Regressor Loss: -0.7548
Domain Loss: 0.0003
Train Epoch: 17 [6372/10752 (59%)]	 Regressor Loss: -0.310723
Regressor Loss: -0.3107
Domain Loss: 0.0000
Train Epoch: 17 [6492/10752 (60%)]	 Regressor Loss: -0.672076
Regressor Loss: -0.6721
Domain Loss: 0.0000
Train Epoch: 17 [6612/10752 (61%)]	 Regressor Loss: -0.285938
Regressor Loss: -0.2859
Domain Loss: 0.0001
Train Epoch: 17 [6732/10752 (63%)]	 Regressor Loss: -0.276666
Regressor Loss: -0.2767
Domain Loss: 0.0001
Train Epoch: 17 [6852/10752 (64%)]	 Regressor Loss: -0.303986
Regressor Loss: -0.3040
Domain Loss: 0.0000
Train Epoch: 17 [6972/10752 (65%)]	 Regressor Loss: -0.651982
Regressor Loss: -0.6520
Domain Loss: 0.0000
Train Epoch: 17 [7092/10752 (66%)]	 Regressor Loss: -0.278687
Regressor Loss: -0.2787
Domain Loss: 0.0000
Train Epoch: 17 [7212/10752 (67%)]	 Regressor Loss: -0.676795
Regressor Loss: -0.6768
Domain Loss: 0.0000
Train Epoch: 17 [7332/10752 (68%)]	 Regressor Loss: -0.355102
Regressor Loss: -0.3551
Domain Loss: 0.0000
Train Epoch: 17 [7452/10752 (69%)]	 Regressor Loss: -0.597689
Regressor Loss: -0.5977
Domain Loss: 0.0000
Train Epoch: 17 [7572/10752 (70%)]	 Regressor Loss: -0.372733
Regressor Loss: -0.3727
Domain Loss: 0.0000
Train Epoch: 17 [7692/10752 (72%)]	 Regressor Loss: -0.409626
Regressor Loss: -0.4096
Domain Loss: 0.0000
Train Epoch: 17 [7812/10752 (73%)]	 Regressor Loss: -0.255788
Regressor Loss: -0.2558
Domain Loss: 0.0000
Train Epoch: 17 [7932/10752 (74%)]	 Regressor Loss: -0.163920
Regressor Loss: -0.1639
Domain Loss: 0.0000
Train Epoch: 17 [8052/10752 (75%)]	 Regressor Loss: -0.156041
Regressor Loss: -0.1560
Domain Loss: 0.0000
Train Epoch: 17 [8172/10752 (76%)]	 Regressor Loss: -0.487299
Regressor Loss: -0.4873
Domain Loss: 0.0000
Train Epoch: 17 [8292/10752 (77%)]	 Regressor Loss: -0.480013
Regressor Loss: -0.4800
Domain Loss: 0.0000
Train Epoch: 17 [8412/10752 (78%)]	 Regressor Loss: -0.427966
Regressor Loss: -0.4280
Domain Loss: 0.0000
Train Epoch: 17 [8532/10752 (79%)]	 Regressor Loss: -0.442306
Regressor Loss: -0.4423
Domain Loss: 0.0000
Train Epoch: 17 [8652/10752 (80%)]	 Regressor Loss: -0.396888
Regressor Loss: -0.3969
Domain Loss: 0.0000
Train Epoch: 17 [8772/10752 (82%)]	 Regressor Loss: -0.631304
Regressor Loss: -0.6313
Domain Loss: 0.0000
Train Epoch: 17 [8892/10752 (83%)]	 Regressor Loss: -0.170238
Regressor Loss: -0.1702
Domain Loss: 0.0000
Train Epoch: 17 [9012/10752 (84%)]	 Regressor Loss: -0.732783
Regressor Loss: -0.7328
Domain Loss: 0.0000
Train Epoch: 17 [9132/10752 (85%)]	 Regressor Loss: -0.170293
Regressor Loss: -0.1703
Domain Loss: 0.0000
Train Epoch: 17 [9252/10752 (86%)]	 Regressor Loss: -0.811664
Regressor Loss: -0.8117
Domain Loss: 0.0000
Train Epoch: 17 [9372/10752 (87%)]	 Regressor Loss: -0.335729
Regressor Loss: -0.3357
Domain Loss: 0.0000
Training set: Average loss: -0.4353
Training set: Average Domain loss: 0.0003
Training set: Average Acc: 0.9999
Validation set: Average loss: -0.4153
Validation set: Average Domain loss: 0.0179
 Validation set: Average Acc: 0.9933
Training Main Encoder
Epoch  18 / 300
Train Epoch: 18 [12/10752 (0%)]	 Regressor Loss: -0.480007
Regressor Loss: -0.4800
Domain Loss: 0.0000
Train Epoch: 18 [132/10752 (1%)]	 Regressor Loss: -0.309334
Regressor Loss: -0.3093
Domain Loss: 0.0000
Train Epoch: 18 [252/10752 (2%)]	 Regressor Loss: -0.742369
Regressor Loss: -0.7424
Domain Loss: 0.0000
Train Epoch: 18 [372/10752 (3%)]	 Regressor Loss: -0.298616
Regressor Loss: -0.2986
Domain Loss: 0.0000
Train Epoch: 18 [492/10752 (5%)]	 Regressor Loss: -0.773909
Regressor Loss: -0.7739
Domain Loss: 0.0000
Train Epoch: 18 [612/10752 (6%)]	 Regressor Loss: -0.436945
Regressor Loss: -0.4369
Domain Loss: 0.0000
Train Epoch: 18 [732/10752 (7%)]	 Regressor Loss: -0.724911
Regressor Loss: -0.7249
Domain Loss: 0.0000
Train Epoch: 18 [852/10752 (8%)]	 Regressor Loss: -0.365122
Regressor Loss: -0.3651
Domain Loss: 0.0000
Train Epoch: 18 [972/10752 (9%)]	 Regressor Loss: -0.531947
Regressor Loss: -0.5319
Domain Loss: 0.0000
Train Epoch: 18 [1092/10752 (10%)]	 Regressor Loss: -0.376987
Regressor Loss: -0.3770
Domain Loss: 0.0001
Train Epoch: 18 [1212/10752 (11%)]	 Regressor Loss: -0.277031
Regressor Loss: -0.2770
Domain Loss: 0.0000
Train Epoch: 18 [1332/10752 (12%)]	 Regressor Loss: -0.355433
Regressor Loss: -0.3554
Domain Loss: 0.0000
Train Epoch: 18 [1452/10752 (14%)]	 Regressor Loss: -0.000000
Regressor Loss: -0.0000
Domain Loss: 0.0000
Train Epoch: 18 [1572/10752 (15%)]	 Regressor Loss: -0.455012
Regressor Loss: -0.4550
Domain Loss: 0.0000
Train Epoch: 18 [1692/10752 (16%)]	 Regressor Loss: -0.287440
Regressor Loss: -0.2874
Domain Loss: 0.0000
Train Epoch: 18 [1812/10752 (17%)]	 Regressor Loss: -0.438349
Regressor Loss: -0.4383
Domain Loss: 0.0000
Train Epoch: 18 [1932/10752 (18%)]	 Regressor Loss: -0.240021
Regressor Loss: -0.2400
Domain Loss: 0.0000
Train Epoch: 18 [2052/10752 (19%)]	 Regressor Loss: -0.652424
Regressor Loss: -0.6524
Domain Loss: 0.0000
Train Epoch: 18 [2172/10752 (20%)]	 Regressor Loss: -0.257815
Regressor Loss: -0.2578
Domain Loss: 0.0000
Train Epoch: 18 [2292/10752 (21%)]	 Regressor Loss: -0.641032
Regressor Loss: -0.6410
Domain Loss: 0.0000
Train Epoch: 18 [2412/10752 (22%)]	 Regressor Loss: -0.311690
Regressor Loss: -0.3117
Domain Loss: 0.0000
Train Epoch: 18 [2532/10752 (24%)]	 Regressor Loss: -0.564095
Regressor Loss: -0.5641
Domain Loss: 0.0003
Train Epoch: 18 [2652/10752 (25%)]	 Regressor Loss: -0.344492
Regressor Loss: -0.3445
Domain Loss: 0.0000
Train Epoch: 18 [2772/10752 (26%)]	 Regressor Loss: -0.842027
Regressor Loss: -0.8420
Domain Loss: 0.0000
Train Epoch: 18 [2892/10752 (27%)]	 Regressor Loss: -0.251010
Regressor Loss: -0.2510
Domain Loss: 0.0000
Train Epoch: 18 [3012/10752 (28%)]	 Regressor Loss: -0.659921
Regressor Loss: -0.6599
Domain Loss: 0.0000
Train Epoch: 18 [3132/10752 (29%)]	 Regressor Loss: -0.240423
Regressor Loss: -0.2404
Domain Loss: 0.0000
Train Epoch: 18 [3252/10752 (30%)]	 Regressor Loss: -0.689561
Regressor Loss: -0.6896
Domain Loss: 0.0000
Train Epoch: 18 [3372/10752 (31%)]	 Regressor Loss: -0.197984
Regressor Loss: -0.1980
Domain Loss: 0.0000
Train Epoch: 18 [3492/10752 (32%)]	 Regressor Loss: -0.704762
Regressor Loss: -0.7048
Domain Loss: 0.0001
Train Epoch: 18 [3612/10752 (34%)]	 Regressor Loss: -0.197178
Regressor Loss: -0.1972
Domain Loss: 0.0000
Train Epoch: 18 [3732/10752 (35%)]	 Regressor Loss: -0.682959
Regressor Loss: -0.6830
Domain Loss: 0.0000
Train Epoch: 18 [3852/10752 (36%)]	 Regressor Loss: -0.329017
Regressor Loss: -0.3290
Domain Loss: 0.0001
Train Epoch: 18 [3972/10752 (37%)]	 Regressor Loss: -0.814827
Regressor Loss: -0.8148
Domain Loss: 0.0000
Train Epoch: 18 [4092/10752 (38%)]	 Regressor Loss: -0.297384
Regressor Loss: -0.2974
Domain Loss: 0.0000
Train Epoch: 18 [4212/10752 (39%)]	 Regressor Loss: -0.273238
Regressor Loss: -0.2732
Domain Loss: 0.0000
Train Epoch: 18 [4332/10752 (40%)]	 Regressor Loss: -0.286055
Regressor Loss: -0.2861
Domain Loss: 0.0000
Train Epoch: 18 [4452/10752 (41%)]	 Regressor Loss: -0.210986
Regressor Loss: -0.2110
Domain Loss: 0.0012
Train Epoch: 18 [4572/10752 (43%)]	 Regressor Loss: -0.242168
Regressor Loss: -0.2422
Domain Loss: 0.0000
Train Epoch: 18 [4692/10752 (44%)]	 Regressor Loss: -0.287889
Regressor Loss: -0.2879
Domain Loss: 0.0000
Train Epoch: 18 [4812/10752 (45%)]	 Regressor Loss: -0.239388
Regressor Loss: -0.2394
Domain Loss: 0.0000
Train Epoch: 18 [4932/10752 (46%)]	 Regressor Loss: -0.319114
Regressor Loss: -0.3191
Domain Loss: 0.0000
Train Epoch: 18 [5052/10752 (47%)]	 Regressor Loss: -0.422914
Regressor Loss: -0.4229
Domain Loss: 0.0008
Train Epoch: 18 [5172/10752 (48%)]	 Regressor Loss: -0.307261
Regressor Loss: -0.3073
Domain Loss: 0.0000
Train Epoch: 18 [5292/10752 (49%)]	 Regressor Loss: -0.669969
Regressor Loss: -0.6700
Domain Loss: 0.0001
Train Epoch: 18 [5412/10752 (50%)]	 Regressor Loss: -0.289718
Regressor Loss: -0.2897
Domain Loss: 0.0000
Train Epoch: 18 [5532/10752 (51%)]	 Regressor Loss: -0.787079
Regressor Loss: -0.7871
Domain Loss: 0.0000
Train Epoch: 18 [5652/10752 (53%)]	 Regressor Loss: -0.330524
Regressor Loss: -0.3305
Domain Loss: 0.0000
Train Epoch: 18 [5772/10752 (54%)]	 Regressor Loss: -0.756855
Regressor Loss: -0.7569
Domain Loss: 0.0000
Train Epoch: 18 [5892/10752 (55%)]	 Regressor Loss: -0.470731
Regressor Loss: -0.4707
Domain Loss: 0.0000
Train Epoch: 18 [6012/10752 (56%)]	 Regressor Loss: -0.478357
Regressor Loss: -0.4784
Domain Loss: 0.0001
Train Epoch: 18 [6132/10752 (57%)]	 Regressor Loss: -0.755615
Regressor Loss: -0.7556
Domain Loss: 0.0004
Train Epoch: 18 [6252/10752 (58%)]	 Regressor Loss: -0.801957
Regressor Loss: -0.8020
Domain Loss: 0.0001
Train Epoch: 18 [6372/10752 (59%)]	 Regressor Loss: -0.387405
Regressor Loss: -0.3874
Domain Loss: 0.0000
Train Epoch: 18 [6492/10752 (60%)]	 Regressor Loss: -0.558379
Regressor Loss: -0.5584
Domain Loss: 0.0000
Train Epoch: 18 [6612/10752 (61%)]	 Regressor Loss: -0.271391
Regressor Loss: -0.2714
Domain Loss: 0.0000
Train Epoch: 18 [6732/10752 (63%)]	 Regressor Loss: -0.541575
Regressor Loss: -0.5416
Domain Loss: 0.0000
Train Epoch: 18 [6852/10752 (64%)]	 Regressor Loss: -0.216851
Regressor Loss: -0.2169
Domain Loss: 0.0000
Train Epoch: 18 [6972/10752 (65%)]	 Regressor Loss: -0.827987
Regressor Loss: -0.8280
Domain Loss: 0.0000
Train Epoch: 18 [7092/10752 (66%)]	 Regressor Loss: -0.429382
Regressor Loss: -0.4294
Domain Loss: 0.0001
Train Epoch: 18 [7212/10752 (67%)]	 Regressor Loss: -0.740902
Regressor Loss: -0.7409
Domain Loss: 0.0000
Train Epoch: 18 [7332/10752 (68%)]	 Regressor Loss: -0.282437
Regressor Loss: -0.2824
Domain Loss: 0.0000
Train Epoch: 18 [7452/10752 (69%)]	 Regressor Loss: -0.574472
Regressor Loss: -0.5745
Domain Loss: 0.0000
Train Epoch: 18 [7572/10752 (70%)]	 Regressor Loss: -0.373917
Regressor Loss: -0.3739
Domain Loss: 0.0000
Train Epoch: 18 [7692/10752 (72%)]	 Regressor Loss: -0.437745
Regressor Loss: -0.4377
Domain Loss: 0.0000
Train Epoch: 18 [7812/10752 (73%)]	 Regressor Loss: -0.325238
Regressor Loss: -0.3252
Domain Loss: 0.0000
Train Epoch: 18 [7932/10752 (74%)]	 Regressor Loss: -0.506597
Regressor Loss: -0.5066
Domain Loss: 0.0000
Train Epoch: 18 [8052/10752 (75%)]	 Regressor Loss: -0.497551
Regressor Loss: -0.4976
Domain Loss: 0.0000
Train Epoch: 18 [8172/10752 (76%)]	 Regressor Loss: -0.141090
Regressor Loss: -0.1411
Domain Loss: 0.0000
Train Epoch: 18 [8292/10752 (77%)]	 Regressor Loss: -0.506349
Regressor Loss: -0.5063
Domain Loss: 0.0003
Train Epoch: 18 [8412/10752 (78%)]	 Regressor Loss: -0.293277
Regressor Loss: -0.2933
Domain Loss: 0.0000
Train Epoch: 18 [8532/10752 (79%)]	 Regressor Loss: -0.570924
Regressor Loss: -0.5709
Domain Loss: 0.0000
Train Epoch: 18 [8652/10752 (80%)]	 Regressor Loss: -0.542175
Regressor Loss: -0.5422
Domain Loss: 0.0000
Train Epoch: 18 [8772/10752 (82%)]	 Regressor Loss: -0.621848
Regressor Loss: -0.6218
Domain Loss: 0.0000
Train Epoch: 18 [8892/10752 (83%)]	 Regressor Loss: -0.271997
Regressor Loss: -0.2720
Domain Loss: 0.0000
Train Epoch: 18 [9012/10752 (84%)]	 Regressor Loss: -0.735542
Regressor Loss: -0.7355
Domain Loss: 0.0000
Train Epoch: 18 [9132/10752 (85%)]	 Regressor Loss: -0.307662
Regressor Loss: -0.3077
Domain Loss: 0.0000
Train Epoch: 18 [9252/10752 (86%)]	 Regressor Loss: -0.658903
Regressor Loss: -0.6589
Domain Loss: 0.0000
Train Epoch: 18 [9372/10752 (87%)]	 Regressor Loss: -0.262365
Regressor Loss: -0.2624
Domain Loss: 0.0000
Training set: Average loss: -0.4503
Training set: Average Domain loss: 0.0015
Training set: Average Acc: 0.9997
Validation set: Average loss: -0.4242
Validation set: Average Domain loss: 0.0073
 Validation set: Average Acc: 0.9975
Training Main Encoder
Epoch  19 / 300
Train Epoch: 19 [12/10752 (0%)]	 Regressor Loss: -0.532773
Regressor Loss: -0.5328
Domain Loss: 0.0000
Train Epoch: 19 [132/10752 (1%)]	 Regressor Loss: -0.277319
Regressor Loss: -0.2773
Domain Loss: 0.0002
Train Epoch: 19 [252/10752 (2%)]	 Regressor Loss: -0.758691
Regressor Loss: -0.7587
Domain Loss: 0.0000
Train Epoch: 19 [372/10752 (3%)]	 Regressor Loss: -0.399554
Regressor Loss: -0.3996
Domain Loss: 0.0000
Train Epoch: 19 [492/10752 (5%)]	 Regressor Loss: -0.835423
Regressor Loss: -0.8354
Domain Loss: 0.0000
Train Epoch: 19 [612/10752 (6%)]	 Regressor Loss: -0.154238
Regressor Loss: -0.1542
Domain Loss: 0.0000
Train Epoch: 19 [732/10752 (7%)]	 Regressor Loss: -0.809583
Regressor Loss: -0.8096
Domain Loss: 0.0000
Train Epoch: 19 [852/10752 (8%)]	 Regressor Loss: -0.237004
Regressor Loss: -0.2370
Domain Loss: 0.0005
Train Epoch: 19 [972/10752 (9%)]	 Regressor Loss: -0.259881
Regressor Loss: -0.2599
Domain Loss: 0.0000
Train Epoch: 19 [1092/10752 (10%)]	 Regressor Loss: -0.400714
Regressor Loss: -0.4007
Domain Loss: 0.0142
Train Epoch: 19 [1212/10752 (11%)]	 Regressor Loss: -0.294500
Regressor Loss: -0.2945
Domain Loss: 0.0000
Train Epoch: 19 [1332/10752 (12%)]	 Regressor Loss: -0.302961
Regressor Loss: -0.3030
Domain Loss: 0.0000
Train Epoch: 19 [1452/10752 (14%)]	 Regressor Loss: -0.000000
Regressor Loss: -0.0000
Domain Loss: 0.0000
Train Epoch: 19 [1572/10752 (15%)]	 Regressor Loss: -0.354789
Regressor Loss: -0.3548
Domain Loss: 0.0000
Train Epoch: 19 [1692/10752 (16%)]	 Regressor Loss: -0.385398
Regressor Loss: -0.3854
Domain Loss: 0.0000
Train Epoch: 19 [1812/10752 (17%)]	 Regressor Loss: -0.368298
Regressor Loss: -0.3683
Domain Loss: 0.0000
Train Epoch: 19 [1932/10752 (18%)]	 Regressor Loss: -0.232137
Regressor Loss: -0.2321
Domain Loss: 0.0000
Train Epoch: 19 [2052/10752 (19%)]	 Regressor Loss: -0.723883
Regressor Loss: -0.7239
Domain Loss: 0.0000
Train Epoch: 19 [2172/10752 (20%)]	 Regressor Loss: -0.383967
Regressor Loss: -0.3840
Domain Loss: 0.0000
Train Epoch: 19 [2292/10752 (21%)]	 Regressor Loss: -0.595698
Regressor Loss: -0.5957
Domain Loss: 0.0000
Train Epoch: 19 [2412/10752 (22%)]	 Regressor Loss: -0.234321
Regressor Loss: -0.2343
Domain Loss: 0.0000
Train Epoch: 19 [2532/10752 (24%)]	 Regressor Loss: -0.640906
Regressor Loss: -0.6409
Domain Loss: 0.0000
Train Epoch: 19 [2652/10752 (25%)]	 Regressor Loss: -0.308176
Regressor Loss: -0.3082
Domain Loss: 0.0000
Train Epoch: 19 [2772/10752 (26%)]	 Regressor Loss: -0.759385
Regressor Loss: -0.7594
Domain Loss: 0.0000
Train Epoch: 19 [2892/10752 (27%)]	 Regressor Loss: -0.305476
Regressor Loss: -0.3055
Domain Loss: 0.0000
Train Epoch: 19 [3012/10752 (28%)]	 Regressor Loss: -0.636953
Regressor Loss: -0.6370
Domain Loss: 0.0000
Train Epoch: 19 [3132/10752 (29%)]	 Regressor Loss: -0.476823
Regressor Loss: -0.4768
Domain Loss: 0.0012
Train Epoch: 19 [3252/10752 (30%)]	 Regressor Loss: -0.692168
Regressor Loss: -0.6922
Domain Loss: 0.0000
Train Epoch: 19 [3372/10752 (31%)]	 Regressor Loss: -0.095697
Regressor Loss: -0.0957
Domain Loss: 0.0099
Train Epoch: 19 [3492/10752 (32%)]	 Regressor Loss: -0.726798
Regressor Loss: -0.7268
Domain Loss: 0.0000
Train Epoch: 19 [3612/10752 (34%)]	 Regressor Loss: -0.210516
Regressor Loss: -0.2105
Domain Loss: 0.0000
Train Epoch: 19 [3732/10752 (35%)]	 Regressor Loss: -0.827412
Regressor Loss: -0.8274
Domain Loss: 0.0000
Train Epoch: 19 [3852/10752 (36%)]	 Regressor Loss: -0.244762
Regressor Loss: -0.2448
Domain Loss: 0.0000
Train Epoch: 19 [3972/10752 (37%)]	 Regressor Loss: -0.717151
Regressor Loss: -0.7172
Domain Loss: 0.0000
Train Epoch: 19 [4092/10752 (38%)]	 Regressor Loss: -0.217053
Regressor Loss: -0.2171
Domain Loss: 0.0000
Train Epoch: 19 [4212/10752 (39%)]	 Regressor Loss: -0.455322
Regressor Loss: -0.4553
Domain Loss: 0.0000
Train Epoch: 19 [4332/10752 (40%)]	 Regressor Loss: -0.262139
Regressor Loss: -0.2621
Domain Loss: 0.0000
Train Epoch: 19 [4452/10752 (41%)]	 Regressor Loss: -0.366056
Regressor Loss: -0.3661
Domain Loss: 0.0000
Train Epoch: 19 [4572/10752 (43%)]	 Regressor Loss: -0.325195
Regressor Loss: -0.3252
Domain Loss: 0.0000
Train Epoch: 19 [4692/10752 (44%)]	 Regressor Loss: -0.150591
Regressor Loss: -0.1506
Domain Loss: 0.0000
Train Epoch: 19 [4812/10752 (45%)]	 Regressor Loss: -0.189893
Regressor Loss: -0.1899
Domain Loss: 0.0000
Train Epoch: 19 [4932/10752 (46%)]	 Regressor Loss: -0.337336
Regressor Loss: -0.3373
Domain Loss: 0.0000
Train Epoch: 19 [5052/10752 (47%)]	 Regressor Loss: -0.536798
Regressor Loss: -0.5368
Domain Loss: 0.0000
Train Epoch: 19 [5172/10752 (48%)]	 Regressor Loss: -0.435665
Regressor Loss: -0.4357
Domain Loss: 0.0000
Train Epoch: 19 [5292/10752 (49%)]	 Regressor Loss: -0.683854
Regressor Loss: -0.6839
Domain Loss: 0.0000
Train Epoch: 19 [5412/10752 (50%)]	 Regressor Loss: -0.230878
Regressor Loss: -0.2309
Domain Loss: 0.0000
Train Epoch: 19 [5532/10752 (51%)]	 Regressor Loss: -0.788877
Regressor Loss: -0.7889
Domain Loss: 0.0000
Train Epoch: 19 [5652/10752 (53%)]	 Regressor Loss: -0.444515
Regressor Loss: -0.4445
Domain Loss: 0.0000
Train Epoch: 19 [5772/10752 (54%)]	 Regressor Loss: -0.804373
Regressor Loss: -0.8044
Domain Loss: 0.0000
Train Epoch: 19 [5892/10752 (55%)]	 Regressor Loss: -0.398185
Regressor Loss: -0.3982
Domain Loss: 0.0001
Train Epoch: 19 [6012/10752 (56%)]	 Regressor Loss: -0.739727
Regressor Loss: -0.7397
Domain Loss: 0.0000
Train Epoch: 19 [6132/10752 (57%)]	 Regressor Loss: -0.504773
Regressor Loss: -0.5048
Domain Loss: 0.0000
Train Epoch: 19 [6252/10752 (58%)]	 Regressor Loss: -0.854786
Regressor Loss: -0.8548
Domain Loss: 0.0000
Train Epoch: 19 [6372/10752 (59%)]	 Regressor Loss: -0.184742
Regressor Loss: -0.1847
Domain Loss: 0.0000
Train Epoch: 19 [6492/10752 (60%)]	 Regressor Loss: -0.842144
Regressor Loss: -0.8421
Domain Loss: 0.0030
Train Epoch: 19 [6612/10752 (61%)]	 Regressor Loss: -0.265806
Regressor Loss: -0.2658
Domain Loss: 0.0000
Train Epoch: 19 [6732/10752 (63%)]	 Regressor Loss: -0.758936
Regressor Loss: -0.7589
Domain Loss: 0.0000
Train Epoch: 19 [6852/10752 (64%)]	 Regressor Loss: -0.370403
Regressor Loss: -0.3704
Domain Loss: 0.0000
Train Epoch: 19 [6972/10752 (65%)]	 Regressor Loss: -0.909213
Regressor Loss: -0.9092
Domain Loss: 0.0000
Train Epoch: 19 [7092/10752 (66%)]	 Regressor Loss: -0.323381
Regressor Loss: -0.3234
Domain Loss: 0.0000
Train Epoch: 19 [7212/10752 (67%)]	 Regressor Loss: -0.600958
Regressor Loss: -0.6010
Domain Loss: 0.0000
Train Epoch: 19 [7332/10752 (68%)]	 Regressor Loss: -0.281869
Regressor Loss: -0.2819
Domain Loss: 0.0000
Train Epoch: 19 [7452/10752 (69%)]	 Regressor Loss: -0.605663
Regressor Loss: -0.6057
Domain Loss: 0.0000
Train Epoch: 19 [7572/10752 (70%)]	 Regressor Loss: -0.370972
Regressor Loss: -0.3710
Domain Loss: 0.0000
Train Epoch: 19 [7692/10752 (72%)]	 Regressor Loss: -0.424756
Regressor Loss: -0.4248
Domain Loss: 0.0000
Train Epoch: 19 [7812/10752 (73%)]	 Regressor Loss: -0.387645
Regressor Loss: -0.3876
Domain Loss: 0.0001
Train Epoch: 19 [7932/10752 (74%)]	 Regressor Loss: -0.364853
Regressor Loss: -0.3649
Domain Loss: 0.0002
Train Epoch: 19 [8052/10752 (75%)]	 Regressor Loss: -0.249996
Regressor Loss: -0.2500
Domain Loss: 0.0000
Train Epoch: 19 [8172/10752 (76%)]	 Regressor Loss: -0.547669
Regressor Loss: -0.5477
Domain Loss: 0.0000
Train Epoch: 19 [8292/10752 (77%)]	 Regressor Loss: -0.542411
Regressor Loss: -0.5424
Domain Loss: 0.0000
Train Epoch: 19 [8412/10752 (78%)]	 Regressor Loss: -0.287617
Regressor Loss: -0.2876
Domain Loss: 0.0000
Train Epoch: 19 [8532/10752 (79%)]	 Regressor Loss: -0.664963
Regressor Loss: -0.6650
Domain Loss: 0.0000
Train Epoch: 19 [8652/10752 (80%)]	 Regressor Loss: -0.291797
Regressor Loss: -0.2918
Domain Loss: 0.0000
Train Epoch: 19 [8772/10752 (82%)]	 Regressor Loss: -0.745731
Regressor Loss: -0.7457
Domain Loss: 0.0000
Train Epoch: 19 [8892/10752 (83%)]	 Regressor Loss: -0.276570
Regressor Loss: -0.2766
Domain Loss: 0.0000
Train Epoch: 19 [9012/10752 (84%)]	 Regressor Loss: -0.701973
Regressor Loss: -0.7020
Domain Loss: 0.0000
Train Epoch: 19 [9132/10752 (85%)]	 Regressor Loss: -0.200586
Regressor Loss: -0.2006
Domain Loss: 0.0000
Train Epoch: 19 [9252/10752 (86%)]	 Regressor Loss: -0.841569
Regressor Loss: -0.8416
Domain Loss: 0.0000
Train Epoch: 19 [9372/10752 (87%)]	 Regressor Loss: -0.290979
Regressor Loss: -0.2910
Domain Loss: 0.0000
Training set: Average loss: -0.4580
Training set: Average Domain loss: 0.0003
Training set: Average Acc: 0.9999
Validation set: Average loss: -0.4357
Validation set: Average Domain loss: 0.0012
 Validation set: Average Acc: 0.9992
Training Main Encoder
Epoch  20 / 300
Train Epoch: 20 [12/10752 (0%)]	 Regressor Loss: -0.544296
Regressor Loss: -0.5443
Domain Loss: 0.0000
Train Epoch: 20 [132/10752 (1%)]	 Regressor Loss: -0.220715
Regressor Loss: -0.2207
Domain Loss: 0.0000
Train Epoch: 20 [252/10752 (2%)]	 Regressor Loss: -0.772238
Regressor Loss: -0.7722
Domain Loss: 0.0000
Train Epoch: 20 [372/10752 (3%)]	 Regressor Loss: -0.360363
Regressor Loss: -0.3604
Domain Loss: 0.0000
Train Epoch: 20 [492/10752 (5%)]	 Regressor Loss: -0.762042
Regressor Loss: -0.7620
Domain Loss: 0.0000
Train Epoch: 20 [612/10752 (6%)]	 Regressor Loss: -0.181643
Regressor Loss: -0.1816
Domain Loss: 0.0000
Train Epoch: 20 [732/10752 (7%)]	 Regressor Loss: -0.789341
Regressor Loss: -0.7893
Domain Loss: 0.0000
Train Epoch: 20 [852/10752 (8%)]	 Regressor Loss: -0.281903
Regressor Loss: -0.2819
Domain Loss: 0.0000
Train Epoch: 20 [972/10752 (9%)]	 Regressor Loss: -0.411773
Regressor Loss: -0.4118
Domain Loss: 0.0000
Train Epoch: 20 [1092/10752 (10%)]	 Regressor Loss: -0.396955
Regressor Loss: -0.3970
Domain Loss: 0.0000
Train Epoch: 20 [1212/10752 (11%)]	 Regressor Loss: -0.360556
Regressor Loss: -0.3606
Domain Loss: 0.0000
Train Epoch: 20 [1332/10752 (12%)]	 Regressor Loss: -0.378292
Regressor Loss: -0.3783
Domain Loss: 0.0000
Train Epoch: 20 [1452/10752 (14%)]	 Regressor Loss: -0.244014
Regressor Loss: -0.2440
Domain Loss: 0.0000
Train Epoch: 20 [1572/10752 (15%)]	 Regressor Loss: -0.468723
Regressor Loss: -0.4687
Domain Loss: 0.0000
Train Epoch: 20 [1692/10752 (16%)]	 Regressor Loss: -0.189297
Regressor Loss: -0.1893
Domain Loss: 0.0000
Train Epoch: 20 [1812/10752 (17%)]	 Regressor Loss: -0.558232
Regressor Loss: -0.5582
Domain Loss: 0.0000
Train Epoch: 20 [1932/10752 (18%)]	 Regressor Loss: -0.309254
Regressor Loss: -0.3093
Domain Loss: 0.0000
Train Epoch: 20 [2052/10752 (19%)]	 Regressor Loss: -0.453248
Regressor Loss: -0.4532
Domain Loss: 0.0000
Train Epoch: 20 [2172/10752 (20%)]	 Regressor Loss: -0.322240
Regressor Loss: -0.3222
Domain Loss: 0.0000
Train Epoch: 20 [2292/10752 (21%)]	 Regressor Loss: -0.716457
Regressor Loss: -0.7165
Domain Loss: 0.0000
Train Epoch: 20 [2412/10752 (22%)]	 Regressor Loss: -0.441329
Regressor Loss: -0.4413
Domain Loss: 0.0000
Train Epoch: 20 [2532/10752 (24%)]	 Regressor Loss: -0.694368
Regressor Loss: -0.6944
Domain Loss: 0.0000
Train Epoch: 20 [2652/10752 (25%)]	 Regressor Loss: -0.260972
Regressor Loss: -0.2610
Domain Loss: 0.0000
Train Epoch: 20 [2772/10752 (26%)]	 Regressor Loss: -0.794415
Regressor Loss: -0.7944
Domain Loss: 0.0000
Train Epoch: 20 [2892/10752 (27%)]	 Regressor Loss: -0.353353
Regressor Loss: -0.3534
Domain Loss: 0.0002
Train Epoch: 20 [3012/10752 (28%)]	 Regressor Loss: -0.671128
Regressor Loss: -0.6711
Domain Loss: 0.0000
Train Epoch: 20 [3132/10752 (29%)]	 Regressor Loss: -0.395285
Regressor Loss: -0.3953
Domain Loss: 0.0000
Train Epoch: 20 [3252/10752 (30%)]	 Regressor Loss: -0.708649
Regressor Loss: -0.7086
Domain Loss: 0.0000
Train Epoch: 20 [3372/10752 (31%)]	 Regressor Loss: -0.445352
Regressor Loss: -0.4454
Domain Loss: 0.2297
Train Epoch: 20 [3492/10752 (32%)]	 Regressor Loss: -0.862790
Regressor Loss: -0.8628
Domain Loss: 0.0001
Train Epoch: 20 [3612/10752 (34%)]	 Regressor Loss: -0.335951
Regressor Loss: -0.3360
Domain Loss: 0.0000
Train Epoch: 20 [3732/10752 (35%)]	 Regressor Loss: -0.762119
Regressor Loss: -0.7621
Domain Loss: 0.0000
Train Epoch: 20 [3852/10752 (36%)]	 Regressor Loss: -0.406533
Regressor Loss: -0.4065
Domain Loss: 0.0005
Train Epoch: 20 [3972/10752 (37%)]	 Regressor Loss: -0.698550
Regressor Loss: -0.6985
Domain Loss: 0.0000
Train Epoch: 20 [4092/10752 (38%)]	 Regressor Loss: -0.242978
Regressor Loss: -0.2430
Domain Loss: 0.0000
Train Epoch: 20 [4212/10752 (39%)]	 Regressor Loss: -0.389010
Regressor Loss: -0.3890
Domain Loss: 0.0000
Train Epoch: 20 [4332/10752 (40%)]	 Regressor Loss: -0.357903
Regressor Loss: -0.3579
Domain Loss: 0.0000
Train Epoch: 20 [4452/10752 (41%)]	 Regressor Loss: -0.310090
Regressor Loss: -0.3101
Domain Loss: 0.0000
Train Epoch: 20 [4572/10752 (43%)]	 Regressor Loss: -0.366312
Regressor Loss: -0.3663
Domain Loss: 0.0000
Train Epoch: 20 [4692/10752 (44%)]	 Regressor Loss: -0.265657
Regressor Loss: -0.2657
Domain Loss: 0.0000
Train Epoch: 20 [4812/10752 (45%)]	 Regressor Loss: -0.359740
Regressor Loss: -0.3597
Domain Loss: 0.0000
Train Epoch: 20 [4932/10752 (46%)]	 Regressor Loss: -0.285024
Regressor Loss: -0.2850
Domain Loss: 0.0000
Train Epoch: 20 [5052/10752 (47%)]	 Regressor Loss: -0.414762
Regressor Loss: -0.4148
Domain Loss: 0.0000
Train Epoch: 20 [5172/10752 (48%)]	 Regressor Loss: -0.269114
Regressor Loss: -0.2691
Domain Loss: 0.0000
Train Epoch: 20 [5292/10752 (49%)]	 Regressor Loss: -0.681182
Regressor Loss: -0.6812
Domain Loss: 0.0000
Train Epoch: 20 [5412/10752 (50%)]	 Regressor Loss: -0.223832
Regressor Loss: -0.2238
Domain Loss: 0.0000
Train Epoch: 20 [5532/10752 (51%)]	 Regressor Loss: -0.752569
Regressor Loss: -0.7526
Domain Loss: 0.0000
Train Epoch: 20 [5652/10752 (53%)]	 Regressor Loss: -0.351691
Regressor Loss: -0.3517
Domain Loss: 0.0000
Train Epoch: 20 [5772/10752 (54%)]	 Regressor Loss: -0.878817
Regressor Loss: -0.8788
Domain Loss: 0.0000
Train Epoch: 20 [5892/10752 (55%)]	 Regressor Loss: -0.261053
Regressor Loss: -0.2611
Domain Loss: 0.0002
Train Epoch: 20 [6012/10752 (56%)]	 Regressor Loss: -0.868756
Regressor Loss: -0.8688
Domain Loss: 0.0001
Train Epoch: 20 [6132/10752 (57%)]	 Regressor Loss: -0.539537
Regressor Loss: -0.5395
Domain Loss: 0.0000
Train Epoch: 20 [6252/10752 (58%)]	 Regressor Loss: -0.852503
Regressor Loss: -0.8525
Domain Loss: 0.0000
Train Epoch: 20 [6372/10752 (59%)]	 Regressor Loss: -0.331041
Regressor Loss: -0.3310
Domain Loss: 0.0000
Train Epoch: 20 [6492/10752 (60%)]	 Regressor Loss: -0.711829
Regressor Loss: -0.7118
Domain Loss: 0.0000
Train Epoch: 20 [6612/10752 (61%)]	 Regressor Loss: -0.413250
Regressor Loss: -0.4132
Domain Loss: 0.0000
Train Epoch: 20 [6732/10752 (63%)]	 Regressor Loss: -0.769325
Regressor Loss: -0.7693
Domain Loss: 0.0000
Train Epoch: 20 [6852/10752 (64%)]	 Regressor Loss: -0.322302
Regressor Loss: -0.3223
Domain Loss: 0.0000
Train Epoch: 20 [6972/10752 (65%)]	 Regressor Loss: -0.731217
Regressor Loss: -0.7312
Domain Loss: 0.0000
Train Epoch: 20 [7092/10752 (66%)]	 Regressor Loss: -0.349369
Regressor Loss: -0.3494
Domain Loss: 0.0000
Train Epoch: 20 [7212/10752 (67%)]	 Regressor Loss: -0.641017
Regressor Loss: -0.6410
Domain Loss: 0.0000
Train Epoch: 20 [7332/10752 (68%)]	 Regressor Loss: -0.257804
Regressor Loss: -0.2578
Domain Loss: 0.0000
Train Epoch: 20 [7452/10752 (69%)]	 Regressor Loss: -0.611626
Regressor Loss: -0.6116
Domain Loss: 0.0000
Train Epoch: 20 [7572/10752 (70%)]	 Regressor Loss: -0.315497
Regressor Loss: -0.3155
Domain Loss: 0.0000
Train Epoch: 20 [7692/10752 (72%)]	 Regressor Loss: -0.325754
Regressor Loss: -0.3258
Domain Loss: 0.0000
Train Epoch: 20 [7812/10752 (73%)]	 Regressor Loss: -0.217583
Regressor Loss: -0.2176
Domain Loss: 0.0000
Train Epoch: 20 [7932/10752 (74%)]	 Regressor Loss: -0.329522
Regressor Loss: -0.3295
Domain Loss: 0.0000
Train Epoch: 20 [8052/10752 (75%)]	 Regressor Loss: -0.304053
Regressor Loss: -0.3041
Domain Loss: 0.0000
Train Epoch: 20 [8172/10752 (76%)]	 Regressor Loss: -0.280690
Regressor Loss: -0.2807
Domain Loss: 0.0000
Train Epoch: 20 [8292/10752 (77%)]	 Regressor Loss: -0.454616
Regressor Loss: -0.4546
Domain Loss: 0.0000
Train Epoch: 20 [8412/10752 (78%)]	 Regressor Loss: -0.283984
Regressor Loss: -0.2840
Domain Loss: 0.0000
Train Epoch: 20 [8532/10752 (79%)]	 Regressor Loss: -0.433711
Regressor Loss: -0.4337
Domain Loss: 0.0000
Train Epoch: 20 [8652/10752 (80%)]	 Regressor Loss: -0.309543
Regressor Loss: -0.3095
Domain Loss: 0.0000
Train Epoch: 20 [8772/10752 (82%)]	 Regressor Loss: -0.727126
Regressor Loss: -0.7271
Domain Loss: 0.0000
Train Epoch: 20 [8892/10752 (83%)]	 Regressor Loss: -0.193606
Regressor Loss: -0.1936
Domain Loss: 0.0000
Train Epoch: 20 [9012/10752 (84%)]	 Regressor Loss: -0.686279
Regressor Loss: -0.6863
Domain Loss: 0.0000
Train Epoch: 20 [9132/10752 (85%)]	 Regressor Loss: -0.334371
Regressor Loss: -0.3344
Domain Loss: 0.0000
Train Epoch: 20 [9252/10752 (86%)]	 Regressor Loss: -0.834447
Regressor Loss: -0.8344
Domain Loss: 0.0000
Train Epoch: 20 [9372/10752 (87%)]	 Regressor Loss: -0.323740
Regressor Loss: -0.3237
Domain Loss: 0.0000
Training set: Average loss: -0.4706
Training set: Average Domain loss: 0.0005
Training set: Average Acc: 0.9998
Validation set: Average loss: -0.4441
Validation set: Average Domain loss: 0.0020
 Validation set: Average Acc: 0.9992
Training Main Encoder
Epoch  21 / 300
Train Epoch: 21 [12/10752 (0%)]	 Regressor Loss: -0.521480
Regressor Loss: -0.5215
Domain Loss: 0.0000
Train Epoch: 21 [132/10752 (1%)]	 Regressor Loss: -0.350830
Regressor Loss: -0.3508
Domain Loss: 0.0001
Train Epoch: 21 [252/10752 (2%)]	 Regressor Loss: -0.603536
Regressor Loss: -0.6035
Domain Loss: 0.0000
Train Epoch: 21 [372/10752 (3%)]	 Regressor Loss: -0.413172
Regressor Loss: -0.4132
Domain Loss: 0.0000
Train Epoch: 21 [492/10752 (5%)]	 Regressor Loss: -0.847891
Regressor Loss: -0.8479
Domain Loss: 0.0000
Train Epoch: 21 [612/10752 (6%)]	 Regressor Loss: -0.419589
Regressor Loss: -0.4196
Domain Loss: 0.0000
Train Epoch: 21 [732/10752 (7%)]	 Regressor Loss: -0.778062
Regressor Loss: -0.7781
Domain Loss: 0.0000
Train Epoch: 21 [852/10752 (8%)]	 Regressor Loss: -0.338023
Regressor Loss: -0.3380
Domain Loss: 0.0000
Train Epoch: 21 [972/10752 (9%)]	 Regressor Loss: -0.423767
Regressor Loss: -0.4238
Domain Loss: 0.0000
Train Epoch: 21 [1092/10752 (10%)]	 Regressor Loss: -0.312849
Regressor Loss: -0.3128
Domain Loss: 0.0000
Train Epoch: 21 [1212/10752 (11%)]	 Regressor Loss: -0.275549
Regressor Loss: -0.2755
Domain Loss: 0.0000
Train Epoch: 21 [1332/10752 (12%)]	 Regressor Loss: -0.401965
Regressor Loss: -0.4020
Domain Loss: 0.0000
Train Epoch: 21 [1452/10752 (14%)]	 Regressor Loss: -0.279460
Regressor Loss: -0.2795
Domain Loss: 0.0000
Train Epoch: 21 [1572/10752 (15%)]	 Regressor Loss: -0.525814
Regressor Loss: -0.5258
Domain Loss: 0.0000
Train Epoch: 21 [1692/10752 (16%)]	 Regressor Loss: -0.396481
Regressor Loss: -0.3965
Domain Loss: 0.0000
Train Epoch: 21 [1812/10752 (17%)]	 Regressor Loss: -0.631976
Regressor Loss: -0.6320
Domain Loss: 0.0000
Train Epoch: 21 [1932/10752 (18%)]	 Regressor Loss: -0.250787
Regressor Loss: -0.2508
Domain Loss: 0.0000
Train Epoch: 21 [2052/10752 (19%)]	 Regressor Loss: -0.715244
Regressor Loss: -0.7152
Domain Loss: 0.0000
Train Epoch: 21 [2172/10752 (20%)]	 Regressor Loss: -0.000000
Regressor Loss: -0.0000
Domain Loss: 0.0000
Train Epoch: 21 [2292/10752 (21%)]	 Regressor Loss: -0.708919
Regressor Loss: -0.7089
Domain Loss: 0.0000
Train Epoch: 21 [2412/10752 (22%)]	 Regressor Loss: -0.296133
Regressor Loss: -0.2961
Domain Loss: 0.0000
Train Epoch: 21 [2532/10752 (24%)]	 Regressor Loss: -0.219820
Regressor Loss: -0.2198
Domain Loss: 0.0000
Train Epoch: 21 [2652/10752 (25%)]	 Regressor Loss: -0.324031
Regressor Loss: -0.3240
Domain Loss: 0.0000
Train Epoch: 21 [2772/10752 (26%)]	 Regressor Loss: -0.653421
Regressor Loss: -0.6534
Domain Loss: 0.0000
Train Epoch: 21 [2892/10752 (27%)]	 Regressor Loss: -0.380450
Regressor Loss: -0.3805
Domain Loss: 0.0000
Train Epoch: 21 [3012/10752 (28%)]	 Regressor Loss: -0.710000
Regressor Loss: -0.7100
Domain Loss: 0.0000
Train Epoch: 21 [3132/10752 (29%)]	 Regressor Loss: -0.416645
Regressor Loss: -0.4166
Domain Loss: 0.0001
Train Epoch: 21 [3252/10752 (30%)]	 Regressor Loss: -0.788452
Regressor Loss: -0.7885
Domain Loss: 0.0000
Train Epoch: 21 [3372/10752 (31%)]	 Regressor Loss: -0.383884
Regressor Loss: -0.3839
Domain Loss: 0.0000
Train Epoch: 21 [3492/10752 (32%)]	 Regressor Loss: -0.814481
Regressor Loss: -0.8145
Domain Loss: 0.0000
Train Epoch: 21 [3612/10752 (34%)]	 Regressor Loss: -0.273936
Regressor Loss: -0.2739
Domain Loss: 0.0000
Train Epoch: 21 [3732/10752 (35%)]	 Regressor Loss: -0.789875
Regressor Loss: -0.7899
Domain Loss: 0.0000
Train Epoch: 21 [3852/10752 (36%)]	 Regressor Loss: -0.493989
Regressor Loss: -0.4940
Domain Loss: 0.0000
Train Epoch: 21 [3972/10752 (37%)]	 Regressor Loss: -0.748303
Regressor Loss: -0.7483
Domain Loss: 0.0000
Train Epoch: 21 [4092/10752 (38%)]	 Regressor Loss: -0.441605
Regressor Loss: -0.4416
Domain Loss: 0.0000
Train Epoch: 21 [4212/10752 (39%)]	 Regressor Loss: -0.390310
Regressor Loss: -0.3903
Domain Loss: 0.0000
Train Epoch: 21 [4332/10752 (40%)]	 Regressor Loss: -0.339561
Regressor Loss: -0.3396
Domain Loss: 0.0000
Train Epoch: 21 [4452/10752 (41%)]	 Regressor Loss: -0.290446
Regressor Loss: -0.2904
Domain Loss: 0.0000
Train Epoch: 21 [4572/10752 (43%)]	 Regressor Loss: -0.274495
Regressor Loss: -0.2745
Domain Loss: 0.0000
Train Epoch: 21 [4692/10752 (44%)]	 Regressor Loss: -0.363797
Regressor Loss: -0.3638
Domain Loss: 0.0000
Train Epoch: 21 [4812/10752 (45%)]	 Regressor Loss: -0.217267
Regressor Loss: -0.2173
Domain Loss: 0.0000
Train Epoch: 21 [4932/10752 (46%)]	 Regressor Loss: -0.240647
Regressor Loss: -0.2406
Domain Loss: 0.0000
Train Epoch: 21 [5052/10752 (47%)]	 Regressor Loss: -0.593186
Regressor Loss: -0.5932
Domain Loss: 0.0000
Train Epoch: 21 [5172/10752 (48%)]	 Regressor Loss: -0.227952
Regressor Loss: -0.2280
Domain Loss: 0.0000
Train Epoch: 21 [5292/10752 (49%)]	 Regressor Loss: -0.764770
Regressor Loss: -0.7648
Domain Loss: 0.0000
Train Epoch: 21 [5412/10752 (50%)]	 Regressor Loss: -0.313485
Regressor Loss: -0.3135
Domain Loss: 0.0000
Train Epoch: 21 [5532/10752 (51%)]	 Regressor Loss: -0.819935
Regressor Loss: -0.8199
Domain Loss: 0.0000
Train Epoch: 21 [5652/10752 (53%)]	 Regressor Loss: -0.348357
Regressor Loss: -0.3484
Domain Loss: 0.0000
Train Epoch: 21 [5772/10752 (54%)]	 Regressor Loss: -0.789149
Regressor Loss: -0.7891
Domain Loss: 0.0000
Train Epoch: 21 [5892/10752 (55%)]	 Regressor Loss: -0.300326
Regressor Loss: -0.3003
Domain Loss: 0.0000
Train Epoch: 21 [6012/10752 (56%)]	 Regressor Loss: -0.788576
Regressor Loss: -0.7886
Domain Loss: 0.0000
Train Epoch: 21 [6132/10752 (57%)]	 Regressor Loss: -0.480886
Regressor Loss: -0.4809
Domain Loss: 0.0000
Train Epoch: 21 [6252/10752 (58%)]	 Regressor Loss: -0.781739
Regressor Loss: -0.7817
Domain Loss: 0.0000
Train Epoch: 21 [6372/10752 (59%)]	 Regressor Loss: -0.370276
Regressor Loss: -0.3703
Domain Loss: 0.0000
Train Epoch: 21 [6492/10752 (60%)]	 Regressor Loss: -0.774614
Regressor Loss: -0.7746
Domain Loss: 0.0000
Train Epoch: 21 [6612/10752 (61%)]	 Regressor Loss: -0.380058
Regressor Loss: -0.3801
Domain Loss: 0.0000
Train Epoch: 21 [6732/10752 (63%)]	 Regressor Loss: -0.648105
Regressor Loss: -0.6481
Domain Loss: 0.0000
Train Epoch: 21 [6852/10752 (64%)]	 Regressor Loss: -0.090611
Regressor Loss: -0.0906
Domain Loss: 0.0000
Train Epoch: 21 [6972/10752 (65%)]	 Regressor Loss: -0.872038
Regressor Loss: -0.8720
Domain Loss: 0.0000
Train Epoch: 21 [7092/10752 (66%)]	 Regressor Loss: -0.264068
Regressor Loss: -0.2641
Domain Loss: 0.0000
Train Epoch: 21 [7212/10752 (67%)]	 Regressor Loss: -0.716562
Regressor Loss: -0.7166
Domain Loss: 0.0000
Train Epoch: 21 [7332/10752 (68%)]	 Regressor Loss: -0.305505
Regressor Loss: -0.3055
Domain Loss: 0.0000
Train Epoch: 21 [7452/10752 (69%)]	 Regressor Loss: -0.594456
Regressor Loss: -0.5945
Domain Loss: 0.0000
Train Epoch: 21 [7572/10752 (70%)]	 Regressor Loss: -0.293835
Regressor Loss: -0.2938
Domain Loss: 0.0000
Train Epoch: 21 [7692/10752 (72%)]	 Regressor Loss: -0.427183
Regressor Loss: -0.4272
Domain Loss: 0.0000
Train Epoch: 21 [7812/10752 (73%)]	 Regressor Loss: -0.389119
Regressor Loss: -0.3891
Domain Loss: 0.0000
Train Epoch: 21 [7932/10752 (74%)]	 Regressor Loss: -0.470377
Regressor Loss: -0.4704
Domain Loss: 0.0000
Train Epoch: 21 [8052/10752 (75%)]	 Regressor Loss: -0.578235
Regressor Loss: -0.5782
Domain Loss: 0.0000
Train Epoch: 21 [8172/10752 (76%)]	 Regressor Loss: -0.469489
Regressor Loss: -0.4695
Domain Loss: 0.0000
Train Epoch: 21 [8292/10752 (77%)]	 Regressor Loss: -0.230273
Regressor Loss: -0.2303
Domain Loss: 0.0000
Train Epoch: 21 [8412/10752 (78%)]	 Regressor Loss: -0.308653
Regressor Loss: -0.3087
Domain Loss: 0.0000
Train Epoch: 21 [8532/10752 (79%)]	 Regressor Loss: -0.732922
Regressor Loss: -0.7329
Domain Loss: 0.0000
Train Epoch: 21 [8652/10752 (80%)]	 Regressor Loss: -0.360608
Regressor Loss: -0.3606
Domain Loss: 0.0000
Train Epoch: 21 [8772/10752 (82%)]	 Regressor Loss: -0.763744
Regressor Loss: -0.7637
Domain Loss: 0.0000
Train Epoch: 21 [8892/10752 (83%)]	 Regressor Loss: -0.263012
Regressor Loss: -0.2630
Domain Loss: 0.0000
Train Epoch: 21 [9012/10752 (84%)]	 Regressor Loss: -0.710467
Regressor Loss: -0.7105
Domain Loss: 0.0000
Train Epoch: 21 [9132/10752 (85%)]	 Regressor Loss: -0.338536
Regressor Loss: -0.3385
Domain Loss: 0.0000
Train Epoch: 21 [9252/10752 (86%)]	 Regressor Loss: -0.698719
Regressor Loss: -0.6987
Domain Loss: 0.0000
Train Epoch: 21 [9372/10752 (87%)]	 Regressor Loss: -0.306307
Regressor Loss: -0.3063
Domain Loss: 0.0000
Training set: Average loss: -0.4809
Training set: Average Domain loss: 0.0008
Training set: Average Acc: 0.9998
Validation set: Average loss: -0.4572
Validation set: Average Domain loss: 0.0723
 Validation set: Average Acc: 0.9850
Training Main Encoder
Epoch  22 / 300
Train Epoch: 22 [12/10752 (0%)]	 Regressor Loss: -0.666044
Regressor Loss: -0.6660
Domain Loss: 0.0000
Train Epoch: 22 [132/10752 (1%)]	 Regressor Loss: -0.203062
Regressor Loss: -0.2031
Domain Loss: 0.0000
Train Epoch: 22 [252/10752 (2%)]	 Regressor Loss: -0.586677
Regressor Loss: -0.5867
Domain Loss: 0.0000
Train Epoch: 22 [372/10752 (3%)]	 Regressor Loss: -0.301452
Regressor Loss: -0.3015
Domain Loss: 0.0000
Train Epoch: 22 [492/10752 (5%)]	 Regressor Loss: -0.844646
Regressor Loss: -0.8446
Domain Loss: 0.0000
Train Epoch: 22 [612/10752 (6%)]	 Regressor Loss: -0.429476
Regressor Loss: -0.4295
Domain Loss: 0.0001
Train Epoch: 22 [732/10752 (7%)]	 Regressor Loss: -0.857066
Regressor Loss: -0.8571
Domain Loss: 0.0000
Train Epoch: 22 [852/10752 (8%)]	 Regressor Loss: -0.389005
Regressor Loss: -0.3890
Domain Loss: 0.0000
Train Epoch: 22 [972/10752 (9%)]	 Regressor Loss: -0.641661
Regressor Loss: -0.6417
Domain Loss: 0.0000
Train Epoch: 22 [1092/10752 (10%)]	 Regressor Loss: -0.293029
Regressor Loss: -0.2930
Domain Loss: 0.0000
Train Epoch: 22 [1212/10752 (11%)]	 Regressor Loss: -0.286551
Regressor Loss: -0.2866
Domain Loss: 0.0000
Train Epoch: 22 [1332/10752 (12%)]	 Regressor Loss: -0.458739
Regressor Loss: -0.4587
Domain Loss: 0.0000
Train Epoch: 22 [1452/10752 (14%)]	 Regressor Loss: -0.331021
Regressor Loss: -0.3310
Domain Loss: 0.0000
Train Epoch: 22 [1572/10752 (15%)]	 Regressor Loss: -0.387734
Regressor Loss: -0.3877
Domain Loss: 0.0000
Train Epoch: 22 [1692/10752 (16%)]	 Regressor Loss: -0.326959
Regressor Loss: -0.3270
Domain Loss: 0.0000
Train Epoch: 22 [1812/10752 (17%)]	 Regressor Loss: -0.293772
Regressor Loss: -0.2938
Domain Loss: 0.0000
Train Epoch: 22 [1932/10752 (18%)]	 Regressor Loss: -0.317697
Regressor Loss: -0.3177
Domain Loss: 0.0000
Train Epoch: 22 [2052/10752 (19%)]	 Regressor Loss: -0.680550
Regressor Loss: -0.6806
Domain Loss: 0.0000
Train Epoch: 22 [2172/10752 (20%)]	 Regressor Loss: -0.339929
Regressor Loss: -0.3399
Domain Loss: 0.0000
Train Epoch: 22 [2292/10752 (21%)]	 Regressor Loss: -0.857082
Regressor Loss: -0.8571
Domain Loss: 0.0000
Train Epoch: 22 [2412/10752 (22%)]	 Regressor Loss: -0.228732
Regressor Loss: -0.2287
Domain Loss: 0.0000
Train Epoch: 22 [2532/10752 (24%)]	 Regressor Loss: -0.366191
Regressor Loss: -0.3662
Domain Loss: 0.0000
Train Epoch: 22 [2652/10752 (25%)]	 Regressor Loss: -0.423174
Regressor Loss: -0.4232
Domain Loss: 0.0000
Train Epoch: 22 [2772/10752 (26%)]	 Regressor Loss: -0.767585
Regressor Loss: -0.7676
Domain Loss: 0.0000
Train Epoch: 22 [2892/10752 (27%)]	 Regressor Loss: -0.333021
Regressor Loss: -0.3330
Domain Loss: 0.0000
Train Epoch: 22 [3012/10752 (28%)]	 Regressor Loss: -0.777210
Regressor Loss: -0.7772
Domain Loss: 0.0000
Train Epoch: 22 [3132/10752 (29%)]	 Regressor Loss: -0.288073
Regressor Loss: -0.2881
Domain Loss: 0.0000
Train Epoch: 22 [3252/10752 (30%)]	 Regressor Loss: -0.740185
Regressor Loss: -0.7402
Domain Loss: 0.0000
Train Epoch: 22 [3372/10752 (31%)]	 Regressor Loss: -0.376377
Regressor Loss: -0.3764
Domain Loss: 0.0002
Train Epoch: 22 [3492/10752 (32%)]	 Regressor Loss: -0.896495
Regressor Loss: -0.8965
Domain Loss: 0.0000
Train Epoch: 22 [3612/10752 (34%)]	 Regressor Loss: -0.321414
Regressor Loss: -0.3214
Domain Loss: 0.0000
Train Epoch: 22 [3732/10752 (35%)]	 Regressor Loss: -0.935075
Regressor Loss: -0.9351
Domain Loss: 0.0000
Train Epoch: 22 [3852/10752 (36%)]	 Regressor Loss: -0.358807
Regressor Loss: -0.3588
Domain Loss: 0.0000
Train Epoch: 22 [3972/10752 (37%)]	 Regressor Loss: -0.712341
Regressor Loss: -0.7123
Domain Loss: 0.0000
Train Epoch: 22 [4092/10752 (38%)]	 Regressor Loss: -0.299122
Regressor Loss: -0.2991
Domain Loss: 0.0000
Train Epoch: 22 [4212/10752 (39%)]	 Regressor Loss: -0.572130
Regressor Loss: -0.5721
Domain Loss: 0.0000
Train Epoch: 22 [4332/10752 (40%)]	 Regressor Loss: -0.372324
Regressor Loss: -0.3723
Domain Loss: 0.0000
Train Epoch: 22 [4452/10752 (41%)]	 Regressor Loss: -0.150555
Regressor Loss: -0.1506
Domain Loss: 0.0000
Train Epoch: 22 [4572/10752 (43%)]	 Regressor Loss: -0.034216
Regressor Loss: -0.0342
Domain Loss: 0.0000
Train Epoch: 22 [4692/10752 (44%)]	 Regressor Loss: -0.241936
Regressor Loss: -0.2419
Domain Loss: 0.0000
Train Epoch: 22 [4812/10752 (45%)]	 Regressor Loss: -0.261616
Regressor Loss: -0.2616
Domain Loss: 0.0000
Train Epoch: 22 [4932/10752 (46%)]	 Regressor Loss: -0.382646
Regressor Loss: -0.3826
Domain Loss: 0.0000
Train Epoch: 22 [5052/10752 (47%)]	 Regressor Loss: -0.542713
Regressor Loss: -0.5427
Domain Loss: 0.0000
Train Epoch: 22 [5172/10752 (48%)]	 Regressor Loss: -0.385846
Regressor Loss: -0.3858
Domain Loss: 0.0000
Train Epoch: 22 [5292/10752 (49%)]	 Regressor Loss: -0.644073
Regressor Loss: -0.6441
Domain Loss: 0.0000
Train Epoch: 22 [5412/10752 (50%)]	 Regressor Loss: -0.412542
Regressor Loss: -0.4125
Domain Loss: 0.0000
Train Epoch: 22 [5532/10752 (51%)]	 Regressor Loss: -0.805619
Regressor Loss: -0.8056
Domain Loss: 0.0000
Train Epoch: 22 [5652/10752 (53%)]	 Regressor Loss: -0.253811
Regressor Loss: -0.2538
Domain Loss: 0.0000
Train Epoch: 22 [5772/10752 (54%)]	 Regressor Loss: -0.690090
Regressor Loss: -0.6901
Domain Loss: 0.0000
Train Epoch: 22 [5892/10752 (55%)]	 Regressor Loss: -0.564847
Regressor Loss: -0.5648
Domain Loss: 0.0000
Train Epoch: 22 [6012/10752 (56%)]	 Regressor Loss: -0.833946
Regressor Loss: -0.8339
Domain Loss: 0.0000
Train Epoch: 22 [6132/10752 (57%)]	 Regressor Loss: -0.567936
Regressor Loss: -0.5679
Domain Loss: 0.0000
Train Epoch: 22 [6252/10752 (58%)]	 Regressor Loss: -0.487110
Regressor Loss: -0.4871
Domain Loss: 0.0000
Train Epoch: 22 [6372/10752 (59%)]	 Regressor Loss: -0.374065
Regressor Loss: -0.3741
Domain Loss: 0.0000
Train Epoch: 22 [6492/10752 (60%)]	 Regressor Loss: -0.786355
Regressor Loss: -0.7864
Domain Loss: 0.0000
Train Epoch: 22 [6612/10752 (61%)]	 Regressor Loss: -0.270996
Regressor Loss: -0.2710
Domain Loss: 0.0000
Train Epoch: 22 [6732/10752 (63%)]	 Regressor Loss: -0.817254
Regressor Loss: -0.8173
Domain Loss: 0.0000
Train Epoch: 22 [6852/10752 (64%)]	 Regressor Loss: -0.105894
Regressor Loss: -0.1059
Domain Loss: 0.0000
Train Epoch: 22 [6972/10752 (65%)]	 Regressor Loss: -0.770994
Regressor Loss: -0.7710
Domain Loss: 0.0000
Train Epoch: 22 [7092/10752 (66%)]	 Regressor Loss: -0.367544
Regressor Loss: -0.3675
Domain Loss: 0.0000
Train Epoch: 22 [7212/10752 (67%)]	 Regressor Loss: -0.668464
Regressor Loss: -0.6685
Domain Loss: 0.0000
Train Epoch: 22 [7332/10752 (68%)]	 Regressor Loss: -0.307845
Regressor Loss: -0.3078
Domain Loss: 0.0000
Train Epoch: 22 [7452/10752 (69%)]	 Regressor Loss: -0.604228
Regressor Loss: -0.6042
Domain Loss: 0.0000
Train Epoch: 22 [7572/10752 (70%)]	 Regressor Loss: -0.236960
Regressor Loss: -0.2370
Domain Loss: 0.0000
Train Epoch: 22 [7692/10752 (72%)]	 Regressor Loss: -0.404130
Regressor Loss: -0.4041
Domain Loss: 0.0000
Train Epoch: 22 [7812/10752 (73%)]	 Regressor Loss: -0.346536
Regressor Loss: -0.3465
Domain Loss: 0.0000
Train Epoch: 22 [7932/10752 (74%)]	 Regressor Loss: -0.417875
Regressor Loss: -0.4179
Domain Loss: 0.0000
Train Epoch: 22 [8052/10752 (75%)]	 Regressor Loss: -0.398231
Regressor Loss: -0.3982
Domain Loss: 0.0000
Train Epoch: 22 [8172/10752 (76%)]	 Regressor Loss: -0.550007
Regressor Loss: -0.5500
Domain Loss: 0.0000
Train Epoch: 22 [8292/10752 (77%)]	 Regressor Loss: -0.576564
Regressor Loss: -0.5766
Domain Loss: 0.0000
Train Epoch: 22 [8412/10752 (78%)]	 Regressor Loss: -0.276501
Regressor Loss: -0.2765
Domain Loss: 0.0000
Train Epoch: 22 [8532/10752 (79%)]	 Regressor Loss: -0.634996
Regressor Loss: -0.6350
Domain Loss: 0.0000
Train Epoch: 22 [8652/10752 (80%)]	 Regressor Loss: -0.601469
Regressor Loss: -0.6015
Domain Loss: 0.0000
Train Epoch: 22 [8772/10752 (82%)]	 Regressor Loss: -0.664372
Regressor Loss: -0.6644
Domain Loss: 0.0000
Train Epoch: 22 [8892/10752 (83%)]	 Regressor Loss: -0.316414
Regressor Loss: -0.3164
Domain Loss: 0.0000
Train Epoch: 22 [9012/10752 (84%)]	 Regressor Loss: -0.851048
Regressor Loss: -0.8510
Domain Loss: 0.0000
Train Epoch: 22 [9132/10752 (85%)]	 Regressor Loss: -0.270994
Regressor Loss: -0.2710
Domain Loss: 0.0001
Train Epoch: 22 [9252/10752 (86%)]	 Regressor Loss: -0.761809
Regressor Loss: -0.7618
Domain Loss: 0.0000
Train Epoch: 22 [9372/10752 (87%)]	 Regressor Loss: -0.357484
Regressor Loss: -0.3575
Domain Loss: 0.0000
Training set: Average loss: -0.4919
Training set: Average Domain loss: 0.0007
Training set: Average Acc: 0.9999
Validation set: Average loss: -0.4567
Validation set: Average Domain loss: 0.0193
 Validation set: Average Acc: 0.9917
Training Main Encoder
Epoch  23 / 300
Train Epoch: 23 [12/10752 (0%)]	 Regressor Loss: -0.728477
Regressor Loss: -0.7285
Domain Loss: 0.0000
Train Epoch: 23 [132/10752 (1%)]	 Regressor Loss: -0.419207
Regressor Loss: -0.4192
Domain Loss: 0.0000
Train Epoch: 23 [252/10752 (2%)]	 Regressor Loss: -0.771293
Regressor Loss: -0.7713
Domain Loss: 0.0000
Train Epoch: 23 [372/10752 (3%)]	 Regressor Loss: -0.314451
Regressor Loss: -0.3145
Domain Loss: 0.0000
Train Epoch: 23 [492/10752 (5%)]	 Regressor Loss: -0.921731
Regressor Loss: -0.9217
Domain Loss: 0.0000
Train Epoch: 23 [612/10752 (6%)]	 Regressor Loss: -0.247568
Regressor Loss: -0.2476
Domain Loss: 0.0000
Train Epoch: 23 [732/10752 (7%)]	 Regressor Loss: -0.889062
Regressor Loss: -0.8891
Domain Loss: 0.0000
Train Epoch: 23 [852/10752 (8%)]	 Regressor Loss: -0.440121
Regressor Loss: -0.4401
Domain Loss: 0.0000
Train Epoch: 23 [972/10752 (9%)]	 Regressor Loss: -0.334706
Regressor Loss: -0.3347
Domain Loss: 0.0000
Train Epoch: 23 [1092/10752 (10%)]	 Regressor Loss: -0.349463
Regressor Loss: -0.3495
Domain Loss: 0.0000
Train Epoch: 23 [1212/10752 (11%)]	 Regressor Loss: -0.345235
Regressor Loss: -0.3452
Domain Loss: 0.0000
Train Epoch: 23 [1332/10752 (12%)]	 Regressor Loss: -0.431322
Regressor Loss: -0.4313
Domain Loss: 0.0000
Train Epoch: 23 [1452/10752 (14%)]	 Regressor Loss: -0.368252
Regressor Loss: -0.3683
Domain Loss: 0.0000
Train Epoch: 23 [1572/10752 (15%)]	 Regressor Loss: -0.525541
Regressor Loss: -0.5255
Domain Loss: 0.0000
Train Epoch: 23 [1692/10752 (16%)]	 Regressor Loss: -0.272669
Regressor Loss: -0.2727
Domain Loss: 0.0000
Train Epoch: 23 [1812/10752 (17%)]	 Regressor Loss: -0.606824
Regressor Loss: -0.6068
Domain Loss: 0.0000
Train Epoch: 23 [1932/10752 (18%)]	 Regressor Loss: -0.291043
Regressor Loss: -0.2910
Domain Loss: 0.0000
Train Epoch: 23 [2052/10752 (19%)]	 Regressor Loss: -0.744174
Regressor Loss: -0.7442
Domain Loss: 0.0000
Train Epoch: 23 [2172/10752 (20%)]	 Regressor Loss: -0.378889
Regressor Loss: -0.3789
Domain Loss: 0.0000
Train Epoch: 23 [2292/10752 (21%)]	 Regressor Loss: -0.742182
Regressor Loss: -0.7422
Domain Loss: 0.0000
Train Epoch: 23 [2412/10752 (22%)]	 Regressor Loss: -0.298372
Regressor Loss: -0.2984
Domain Loss: 0.0000
Train Epoch: 23 [2532/10752 (24%)]	 Regressor Loss: -0.686625
Regressor Loss: -0.6866
Domain Loss: 0.0000
Train Epoch: 23 [2652/10752 (25%)]	 Regressor Loss: -0.331472
Regressor Loss: -0.3315
Domain Loss: 0.0000
Train Epoch: 23 [2772/10752 (26%)]	 Regressor Loss: -0.862716
Regressor Loss: -0.8627
Domain Loss: 0.0000
Train Epoch: 23 [2892/10752 (27%)]	 Regressor Loss: -0.370168
Regressor Loss: -0.3702
Domain Loss: 0.0000
Train Epoch: 23 [3012/10752 (28%)]	 Regressor Loss: -0.785565
Regressor Loss: -0.7856
Domain Loss: 0.0000
Train Epoch: 23 [3132/10752 (29%)]	 Regressor Loss: -0.447168
Regressor Loss: -0.4472
Domain Loss: 0.0000
Train Epoch: 23 [3252/10752 (30%)]	 Regressor Loss: -0.929164
Regressor Loss: -0.9292
Domain Loss: 0.0000
Train Epoch: 23 [3372/10752 (31%)]	 Regressor Loss: -0.246395
Regressor Loss: -0.2464
Domain Loss: 0.0000
Train Epoch: 23 [3492/10752 (32%)]	 Regressor Loss: -0.853990
Regressor Loss: -0.8540
Domain Loss: 0.0000
Train Epoch: 23 [3612/10752 (34%)]	 Regressor Loss: -0.603250
Regressor Loss: -0.6032
Domain Loss: 0.0002
Train Epoch: 23 [3732/10752 (35%)]	 Regressor Loss: -0.845515
Regressor Loss: -0.8455
Domain Loss: 0.0000
Train Epoch: 23 [3852/10752 (36%)]	 Regressor Loss: -0.331967
Regressor Loss: -0.3320
Domain Loss: 0.0000
Train Epoch: 23 [3972/10752 (37%)]	 Regressor Loss: -0.641797
Regressor Loss: -0.6418
Domain Loss: 0.0000
Train Epoch: 23 [4092/10752 (38%)]	 Regressor Loss: -0.337599
Regressor Loss: -0.3376
Domain Loss: 0.0000
Train Epoch: 23 [4212/10752 (39%)]	 Regressor Loss: -0.478242
Regressor Loss: -0.4782
Domain Loss: 0.0000
Train Epoch: 23 [4332/10752 (40%)]	 Regressor Loss: -0.322374
Regressor Loss: -0.3224
Domain Loss: 0.0000
Train Epoch: 23 [4452/10752 (41%)]	 Regressor Loss: -0.383256
Regressor Loss: -0.3833
Domain Loss: 0.0000
Train Epoch: 23 [4572/10752 (43%)]	 Regressor Loss: -0.330292
Regressor Loss: -0.3303
Domain Loss: 0.0000
Train Epoch: 23 [4692/10752 (44%)]	 Regressor Loss: -0.363499
Regressor Loss: -0.3635
Domain Loss: 0.0000
Train Epoch: 23 [4812/10752 (45%)]	 Regressor Loss: -0.365818
Regressor Loss: -0.3658
Domain Loss: 0.0000
Train Epoch: 23 [4932/10752 (46%)]	 Regressor Loss: -0.361162
Regressor Loss: -0.3612
Domain Loss: 0.0000
Train Epoch: 23 [5052/10752 (47%)]	 Regressor Loss: -0.429091
Regressor Loss: -0.4291
Domain Loss: 0.0000
Train Epoch: 23 [5172/10752 (48%)]	 Regressor Loss: -0.342278
Regressor Loss: -0.3423
Domain Loss: 0.0000
Train Epoch: 23 [5292/10752 (49%)]	 Regressor Loss: -0.572262
Regressor Loss: -0.5723
Domain Loss: 0.0000
Train Epoch: 23 [5412/10752 (50%)]	 Regressor Loss: -0.340930
Regressor Loss: -0.3409
Domain Loss: 0.0000
Train Epoch: 23 [5532/10752 (51%)]	 Regressor Loss: -0.955667
Regressor Loss: -0.9557
Domain Loss: 0.0000
Train Epoch: 23 [5652/10752 (53%)]	 Regressor Loss: -0.177781
Regressor Loss: -0.1778
Domain Loss: 0.0000
Train Epoch: 23 [5772/10752 (54%)]	 Regressor Loss: -0.702509
Regressor Loss: -0.7025
Domain Loss: 0.0000
Train Epoch: 23 [5892/10752 (55%)]	 Regressor Loss: -0.293162
Regressor Loss: -0.2932
Domain Loss: 0.0000
Train Epoch: 23 [6012/10752 (56%)]	 Regressor Loss: -0.849214
Regressor Loss: -0.8492
Domain Loss: 0.0000
Train Epoch: 23 [6132/10752 (57%)]	 Regressor Loss: -0.694585
Regressor Loss: -0.6946
Domain Loss: 0.0000
Train Epoch: 23 [6252/10752 (58%)]	 Regressor Loss: -0.906584
Regressor Loss: -0.9066
Domain Loss: 0.0000
Train Epoch: 23 [6372/10752 (59%)]	 Regressor Loss: -0.223271
Regressor Loss: -0.2233
Domain Loss: 0.0000
Train Epoch: 23 [6492/10752 (60%)]	 Regressor Loss: -0.852823
Regressor Loss: -0.8528
Domain Loss: 0.0000
Train Epoch: 23 [6612/10752 (61%)]	 Regressor Loss: -0.324385
Regressor Loss: -0.3244
Domain Loss: 0.0000
Train Epoch: 23 [6732/10752 (63%)]	 Regressor Loss: -0.697976
Regressor Loss: -0.6980
Domain Loss: 0.0000
Train Epoch: 23 [6852/10752 (64%)]	 Regressor Loss: -0.415250
Regressor Loss: -0.4153
Domain Loss: 0.0000
Train Epoch: 23 [6972/10752 (65%)]	 Regressor Loss: -0.827746
Regressor Loss: -0.8277
Domain Loss: 0.0000
Train Epoch: 23 [7092/10752 (66%)]	 Regressor Loss: -0.269946
Regressor Loss: -0.2699
Domain Loss: 0.0000
Train Epoch: 23 [7212/10752 (67%)]	 Regressor Loss: -0.894917
Regressor Loss: -0.8949
Domain Loss: 0.0000
Train Epoch: 23 [7332/10752 (68%)]	 Regressor Loss: -0.387504
Regressor Loss: -0.3875
Domain Loss: 0.0000
Train Epoch: 23 [7452/10752 (69%)]	 Regressor Loss: -0.831579
Regressor Loss: -0.8316
Domain Loss: 0.0000
Train Epoch: 23 [7572/10752 (70%)]	 Regressor Loss: -0.255820
Regressor Loss: -0.2558
Domain Loss: 0.0002
Train Epoch: 23 [7692/10752 (72%)]	 Regressor Loss: -0.543310
Regressor Loss: -0.5433
Domain Loss: 0.0000
Train Epoch: 23 [7812/10752 (73%)]	 Regressor Loss: -0.199783
Regressor Loss: -0.1998
Domain Loss: 0.0000
Train Epoch: 23 [7932/10752 (74%)]	 Regressor Loss: -0.529204
Regressor Loss: -0.5292
Domain Loss: 0.0000
Train Epoch: 23 [8052/10752 (75%)]	 Regressor Loss: -0.404197
Regressor Loss: -0.4042
Domain Loss: 0.0000
Train Epoch: 23 [8172/10752 (76%)]	 Regressor Loss: -0.315688
Regressor Loss: -0.3157
Domain Loss: 0.0000
Train Epoch: 23 [8292/10752 (77%)]	 Regressor Loss: -0.675759
Regressor Loss: -0.6758
Domain Loss: 0.0900
Train Epoch: 23 [8412/10752 (78%)]	 Regressor Loss: -0.287114
Regressor Loss: -0.2871
Domain Loss: 0.0000
Train Epoch: 23 [8532/10752 (79%)]	 Regressor Loss: -0.669490
Regressor Loss: -0.6695
Domain Loss: 0.0000
Train Epoch: 23 [8652/10752 (80%)]	 Regressor Loss: -0.266635
Regressor Loss: -0.2666
Domain Loss: 0.0000
Train Epoch: 23 [8772/10752 (82%)]	 Regressor Loss: -0.658695
Regressor Loss: -0.6587
Domain Loss: 0.0000
Train Epoch: 23 [8892/10752 (83%)]	 Regressor Loss: -0.442747
Regressor Loss: -0.4427
Domain Loss: 0.0000
Train Epoch: 23 [9012/10752 (84%)]	 Regressor Loss: -0.791437
Regressor Loss: -0.7914
Domain Loss: 0.0000
Train Epoch: 23 [9132/10752 (85%)]	 Regressor Loss: -0.165481
Regressor Loss: -0.1655
Domain Loss: 0.0000
Train Epoch: 23 [9252/10752 (86%)]	 Regressor Loss: -0.768832
Regressor Loss: -0.7688
Domain Loss: 0.0000
Train Epoch: 23 [9372/10752 (87%)]	 Regressor Loss: -0.458939
Regressor Loss: -0.4589
Domain Loss: 0.0000
Training set: Average loss: -0.5024
Training set: Average Domain loss: 0.0005
Training set: Average Acc: 0.9997
Validation set: Average loss: -0.4736
Validation set: Average Domain loss: 0.0177
 Validation set: Average Acc: 0.9958
Training Main Encoder
Epoch  24 / 300
Train Epoch: 24 [12/10752 (0%)]	 Regressor Loss: -0.657522
Regressor Loss: -0.6575
Domain Loss: 0.0000
Train Epoch: 24 [132/10752 (1%)]	 Regressor Loss: -0.264132
Regressor Loss: -0.2641
Domain Loss: 0.0000
Train Epoch: 24 [252/10752 (2%)]	 Regressor Loss: -0.826537
Regressor Loss: -0.8265
Domain Loss: 0.0000
Train Epoch: 24 [372/10752 (3%)]	 Regressor Loss: -0.339888
Regressor Loss: -0.3399
Domain Loss: 0.0000
Train Epoch: 24 [492/10752 (5%)]	 Regressor Loss: -0.577198
Regressor Loss: -0.5772
Domain Loss: 0.0000
Train Epoch: 24 [612/10752 (6%)]	 Regressor Loss: -0.310129
Regressor Loss: -0.3101
Domain Loss: 0.0000
Train Epoch: 24 [732/10752 (7%)]	 Regressor Loss: -0.805257
Regressor Loss: -0.8053
Domain Loss: 0.0000
Train Epoch: 24 [852/10752 (8%)]	 Regressor Loss: -0.577352
Regressor Loss: -0.5774
Domain Loss: 0.0000
Train Epoch: 24 [972/10752 (9%)]	 Regressor Loss: -0.452556
Regressor Loss: -0.4526
Domain Loss: 0.0000
Train Epoch: 24 [1092/10752 (10%)]	 Regressor Loss: -0.082476
Regressor Loss: -0.0825
Domain Loss: 0.0000
Train Epoch: 24 [1212/10752 (11%)]	 Regressor Loss: -0.416812
Regressor Loss: -0.4168
Domain Loss: 0.0000
Train Epoch: 24 [1332/10752 (12%)]	 Regressor Loss: -0.401192
Regressor Loss: -0.4012
Domain Loss: 0.0000
Train Epoch: 24 [1452/10752 (14%)]	 Regressor Loss: -0.269873
Regressor Loss: -0.2699
Domain Loss: 0.0000
Train Epoch: 24 [1572/10752 (15%)]	 Regressor Loss: -0.297730
Regressor Loss: -0.2977
Domain Loss: 0.0000
Train Epoch: 24 [1692/10752 (16%)]	 Regressor Loss: -0.308761
Regressor Loss: -0.3088
Domain Loss: 0.0000
Train Epoch: 24 [1812/10752 (17%)]	 Regressor Loss: -0.474157
Regressor Loss: -0.4742
Domain Loss: 0.0000
Train Epoch: 24 [1932/10752 (18%)]	 Regressor Loss: -0.293283
Regressor Loss: -0.2933
Domain Loss: 0.0000
Train Epoch: 24 [2052/10752 (19%)]	 Regressor Loss: -0.673350
Regressor Loss: -0.6734
Domain Loss: 0.0000
Train Epoch: 24 [2172/10752 (20%)]	 Regressor Loss: -0.362576
Regressor Loss: -0.3626
Domain Loss: 0.0000
Train Epoch: 24 [2292/10752 (21%)]	 Regressor Loss: -0.731132
Regressor Loss: -0.7311
Domain Loss: 0.0000
Train Epoch: 24 [2412/10752 (22%)]	 Regressor Loss: -0.287837
Regressor Loss: -0.2878
Domain Loss: 0.0000
Train Epoch: 24 [2532/10752 (24%)]	 Regressor Loss: -0.304474
Regressor Loss: -0.3045
Domain Loss: 0.0000
Train Epoch: 24 [2652/10752 (25%)]	 Regressor Loss: -0.317370
Regressor Loss: -0.3174
Domain Loss: 0.0000
Train Epoch: 24 [2772/10752 (26%)]	 Regressor Loss: -0.840679
Regressor Loss: -0.8407
Domain Loss: 0.0000
Train Epoch: 24 [2892/10752 (27%)]	 Regressor Loss: -0.301278
Regressor Loss: -0.3013
Domain Loss: 0.0000
Train Epoch: 24 [3012/10752 (28%)]	 Regressor Loss: -0.788347
Regressor Loss: -0.7883
Domain Loss: 0.0000
Train Epoch: 24 [3132/10752 (29%)]	 Regressor Loss: -0.626806
Regressor Loss: -0.6268
Domain Loss: 0.0000
Train Epoch: 24 [3252/10752 (30%)]	 Regressor Loss: -0.861157
Regressor Loss: -0.8612
Domain Loss: 0.0000
Train Epoch: 24 [3372/10752 (31%)]	 Regressor Loss: -0.463577
Regressor Loss: -0.4636
Domain Loss: 0.0000
Train Epoch: 24 [3492/10752 (32%)]	 Regressor Loss: -0.856617
Regressor Loss: -0.8566
Domain Loss: 0.0000
Train Epoch: 24 [3612/10752 (34%)]	 Regressor Loss: -0.357059
Regressor Loss: -0.3571
Domain Loss: 0.0000
Train Epoch: 24 [3732/10752 (35%)]	 Regressor Loss: -0.801650
Regressor Loss: -0.8016
Domain Loss: 0.0000
Train Epoch: 24 [3852/10752 (36%)]	 Regressor Loss: -0.469140
Regressor Loss: -0.4691
Domain Loss: 0.0000
Train Epoch: 24 [3972/10752 (37%)]	 Regressor Loss: -0.833821
Regressor Loss: -0.8338
Domain Loss: 0.0000
Train Epoch: 24 [4092/10752 (38%)]	 Regressor Loss: -0.366825
Regressor Loss: -0.3668
Domain Loss: 0.0000
Train Epoch: 24 [4212/10752 (39%)]	 Regressor Loss: -0.658795
Regressor Loss: -0.6588
Domain Loss: 0.0000
Train Epoch: 24 [4332/10752 (40%)]	 Regressor Loss: -0.421898
Regressor Loss: -0.4219
Domain Loss: 0.0000
Train Epoch: 24 [4452/10752 (41%)]	 Regressor Loss: -0.348324
Regressor Loss: -0.3483
Domain Loss: 0.0000
Train Epoch: 24 [4572/10752 (43%)]	 Regressor Loss: -0.233920
Regressor Loss: -0.2339
Domain Loss: 0.0000
Train Epoch: 24 [4692/10752 (44%)]	 Regressor Loss: -0.208766
Regressor Loss: -0.2088
Domain Loss: 0.0000
Train Epoch: 24 [4812/10752 (45%)]	 Regressor Loss: -0.387703
Regressor Loss: -0.3877
Domain Loss: 0.0000
Train Epoch: 24 [4932/10752 (46%)]	 Regressor Loss: -0.312020
Regressor Loss: -0.3120
Domain Loss: 0.0000
Train Epoch: 24 [5052/10752 (47%)]	 Regressor Loss: -0.504856
Regressor Loss: -0.5049
Domain Loss: 0.0000
Train Epoch: 24 [5172/10752 (48%)]	 Regressor Loss: -0.221529
Regressor Loss: -0.2215
Domain Loss: 0.0000
Train Epoch: 24 [5292/10752 (49%)]	 Regressor Loss: -0.769273
Regressor Loss: -0.7693
Domain Loss: 0.0003
Train Epoch: 24 [5412/10752 (50%)]	 Regressor Loss: -0.398262
Regressor Loss: -0.3983
Domain Loss: 0.0000
Train Epoch: 24 [5532/10752 (51%)]	 Regressor Loss: -0.763676
Regressor Loss: -0.7637
Domain Loss: 0.0000
Train Epoch: 24 [5652/10752 (53%)]	 Regressor Loss: -0.375351
Regressor Loss: -0.3754
Domain Loss: 0.0000
Train Epoch: 24 [5772/10752 (54%)]	 Regressor Loss: -0.932504
Regressor Loss: -0.9325
Domain Loss: 0.0000
Train Epoch: 24 [5892/10752 (55%)]	 Regressor Loss: -0.288066
Regressor Loss: -0.2881
Domain Loss: 0.0000
Train Epoch: 24 [6012/10752 (56%)]	 Regressor Loss: -1.011909
Regressor Loss: -1.0119
Domain Loss: 0.0000
Train Epoch: 24 [6132/10752 (57%)]	 Regressor Loss: -0.097195
Regressor Loss: -0.0972
Domain Loss: 0.0010
Train Epoch: 24 [6252/10752 (58%)]	 Regressor Loss: -0.878741
Regressor Loss: -0.8787
Domain Loss: 0.0000
Train Epoch: 24 [6372/10752 (59%)]	 Regressor Loss: -0.494564
Regressor Loss: -0.4946
Domain Loss: 0.0000
Train Epoch: 24 [6492/10752 (60%)]	 Regressor Loss: -0.935074
Regressor Loss: -0.9351
Domain Loss: 0.0000
Train Epoch: 24 [6612/10752 (61%)]	 Regressor Loss: -0.258435
Regressor Loss: -0.2584
Domain Loss: 0.0000
Train Epoch: 24 [6732/10752 (63%)]	 Regressor Loss: -0.874490
Regressor Loss: -0.8745
Domain Loss: 0.0000
Train Epoch: 24 [6852/10752 (64%)]	 Regressor Loss: -0.089011
Regressor Loss: -0.0890
Domain Loss: 0.0000
Train Epoch: 24 [6972/10752 (65%)]	 Regressor Loss: -0.880449
Regressor Loss: -0.8804
Domain Loss: 0.0000
Train Epoch: 24 [7092/10752 (66%)]	 Regressor Loss: -0.264352
Regressor Loss: -0.2644
Domain Loss: 0.0000
Train Epoch: 24 [7212/10752 (67%)]	 Regressor Loss: -0.763608
Regressor Loss: -0.7636
Domain Loss: 0.0000
Train Epoch: 24 [7332/10752 (68%)]	 Regressor Loss: -0.116942
Regressor Loss: -0.1169
Domain Loss: 0.0000
Train Epoch: 24 [7452/10752 (69%)]	 Regressor Loss: -0.903097
Regressor Loss: -0.9031
Domain Loss: 0.0000
Train Epoch: 24 [7572/10752 (70%)]	 Regressor Loss: -0.327182
Regressor Loss: -0.3272
Domain Loss: 0.0000
Train Epoch: 24 [7692/10752 (72%)]	 Regressor Loss: -0.503926
Regressor Loss: -0.5039
Domain Loss: 0.0000
Train Epoch: 24 [7812/10752 (73%)]	 Regressor Loss: -0.386683
Regressor Loss: -0.3867
Domain Loss: 0.0000
Train Epoch: 24 [7932/10752 (74%)]	 Regressor Loss: -0.082519
Regressor Loss: -0.0825
Domain Loss: 0.0001
Train Epoch: 24 [8052/10752 (75%)]	 Regressor Loss: -0.175226
Regressor Loss: -0.1752
Domain Loss: 0.0000
Train Epoch: 24 [8172/10752 (76%)]	 Regressor Loss: -0.346478
Regressor Loss: -0.3465
Domain Loss: 0.0000
Train Epoch: 24 [8292/10752 (77%)]	 Regressor Loss: -0.718453
Regressor Loss: -0.7185
Domain Loss: 0.0000
Train Epoch: 24 [8412/10752 (78%)]	 Regressor Loss: -0.334966
Regressor Loss: -0.3350
Domain Loss: 0.0000
Train Epoch: 24 [8532/10752 (79%)]	 Regressor Loss: -0.575532
Regressor Loss: -0.5755
Domain Loss: 0.0000
Train Epoch: 24 [8652/10752 (80%)]	 Regressor Loss: -0.623732
Regressor Loss: -0.6237
Domain Loss: 0.0000
Train Epoch: 24 [8772/10752 (82%)]	 Regressor Loss: -0.512911
Regressor Loss: -0.5129
Domain Loss: 0.0000
Train Epoch: 24 [8892/10752 (83%)]	 Regressor Loss: -0.273645
Regressor Loss: -0.2736
Domain Loss: 0.0000
Train Epoch: 24 [9012/10752 (84%)]	 Regressor Loss: -0.868119
Regressor Loss: -0.8681
Domain Loss: 0.0001
Train Epoch: 24 [9132/10752 (85%)]	 Regressor Loss: -0.374360
Regressor Loss: -0.3744
Domain Loss: 0.0000
Train Epoch: 24 [9252/10752 (86%)]	 Regressor Loss: -0.753320
Regressor Loss: -0.7533
Domain Loss: 0.0000
Train Epoch: 24 [9372/10752 (87%)]	 Regressor Loss: -0.271487
Regressor Loss: -0.2715
Domain Loss: 0.0000
Training set: Average loss: -0.5055
Training set: Average Domain loss: 0.0000
Training set: Average Acc: 1.0000
Validation set: Average loss: -0.4937
Validation set: Average Domain loss: 0.0046
 Validation set: Average Acc: 0.9967
Training Main Encoder
Epoch  25 / 300
Train Epoch: 25 [12/10752 (0%)]	 Regressor Loss: -0.695294
Regressor Loss: -0.6953
Domain Loss: 0.0000
Train Epoch: 25 [132/10752 (1%)]	 Regressor Loss: -0.375697
Regressor Loss: -0.3757
Domain Loss: 0.0000
Train Epoch: 25 [252/10752 (2%)]	 Regressor Loss: -0.910063
Regressor Loss: -0.9101
Domain Loss: 0.0000
Train Epoch: 25 [372/10752 (3%)]	 Regressor Loss: -0.378530
Regressor Loss: -0.3785
Domain Loss: 0.0000
Train Epoch: 25 [492/10752 (5%)]	 Regressor Loss: -0.914998
Regressor Loss: -0.9150
Domain Loss: 0.0000
Train Epoch: 25 [612/10752 (6%)]	 Regressor Loss: -0.333133
Regressor Loss: -0.3331
Domain Loss: 0.0000
Train Epoch: 25 [732/10752 (7%)]	 Regressor Loss: -0.856496
Regressor Loss: -0.8565
Domain Loss: 0.0001
Train Epoch: 25 [852/10752 (8%)]	 Regressor Loss: -0.601981
Regressor Loss: -0.6020
Domain Loss: 0.0000
Train Epoch: 25 [972/10752 (9%)]	 Regressor Loss: -0.419934
Regressor Loss: -0.4199
Domain Loss: 0.0000
Train Epoch: 25 [1092/10752 (10%)]	 Regressor Loss: -0.203775
Regressor Loss: -0.2038
Domain Loss: 0.0000
Train Epoch: 25 [1212/10752 (11%)]	 Regressor Loss: -0.420545
Regressor Loss: -0.4205
Domain Loss: 0.0000
Train Epoch: 25 [1332/10752 (12%)]	 Regressor Loss: -0.358829
Regressor Loss: -0.3588
Domain Loss: 0.0000
Train Epoch: 25 [1452/10752 (14%)]	 Regressor Loss: -0.436938
Regressor Loss: -0.4369
Domain Loss: 0.0000
Train Epoch: 25 [1572/10752 (15%)]	 Regressor Loss: -0.387868
Regressor Loss: -0.3879
Domain Loss: 0.0000
Train Epoch: 25 [1692/10752 (16%)]	 Regressor Loss: -0.222398
Regressor Loss: -0.2224
Domain Loss: 0.0000
Train Epoch: 25 [1812/10752 (17%)]	 Regressor Loss: -0.461398
Regressor Loss: -0.4614
Domain Loss: 0.0001
Train Epoch: 25 [1932/10752 (18%)]	 Regressor Loss: -0.375462
Regressor Loss: -0.3755
Domain Loss: 0.0000
Train Epoch: 25 [2052/10752 (19%)]	 Regressor Loss: -0.765584
Regressor Loss: -0.7656
Domain Loss: 0.0000
Train Epoch: 25 [2172/10752 (20%)]	 Regressor Loss: -0.314867
Regressor Loss: -0.3149
Domain Loss: 0.0000
Train Epoch: 25 [2292/10752 (21%)]	 Regressor Loss: -0.892257
Regressor Loss: -0.8923
Domain Loss: 0.0000
Train Epoch: 25 [2412/10752 (22%)]	 Regressor Loss: -0.235125
Regressor Loss: -0.2351
Domain Loss: 0.0000
Train Epoch: 25 [2532/10752 (24%)]	 Regressor Loss: -0.734956
Regressor Loss: -0.7350
Domain Loss: 0.0000
Train Epoch: 25 [2652/10752 (25%)]	 Regressor Loss: -0.257236
Regressor Loss: -0.2572
Domain Loss: 0.0000
Train Epoch: 25 [2772/10752 (26%)]	 Regressor Loss: -0.910854
Regressor Loss: -0.9109
Domain Loss: 0.0000
Train Epoch: 25 [2892/10752 (27%)]	 Regressor Loss: -0.436433
Regressor Loss: -0.4364
Domain Loss: 0.0000
Train Epoch: 25 [3012/10752 (28%)]	 Regressor Loss: -0.812275
Regressor Loss: -0.8123
Domain Loss: 0.0000
Train Epoch: 25 [3132/10752 (29%)]	 Regressor Loss: -0.708231
Regressor Loss: -0.7082
Domain Loss: 0.0000
Train Epoch: 25 [3252/10752 (30%)]	 Regressor Loss: -0.778427
Regressor Loss: -0.7784
Domain Loss: 0.0000
Train Epoch: 25 [3372/10752 (31%)]	 Regressor Loss: -0.199784
Regressor Loss: -0.1998
Domain Loss: 0.0000
Train Epoch: 25 [3492/10752 (32%)]	 Regressor Loss: -0.879720
Regressor Loss: -0.8797
Domain Loss: 0.0000
Train Epoch: 25 [3612/10752 (34%)]	 Regressor Loss: -0.233115
Regressor Loss: -0.2331
Domain Loss: 0.0000
Train Epoch: 25 [3732/10752 (35%)]	 Regressor Loss: -0.736387
Regressor Loss: -0.7364
Domain Loss: 0.0000
Train Epoch: 25 [3852/10752 (36%)]	 Regressor Loss: -0.157115
Regressor Loss: -0.1571
Domain Loss: 0.0000
Train Epoch: 25 [3972/10752 (37%)]	 Regressor Loss: -0.786166
Regressor Loss: -0.7862
Domain Loss: 0.0000
Train Epoch: 25 [4092/10752 (38%)]	 Regressor Loss: -0.235220
Regressor Loss: -0.2352
Domain Loss: 0.0000
Train Epoch: 25 [4212/10752 (39%)]	 Regressor Loss: -0.480319
Regressor Loss: -0.4803
Domain Loss: 0.0000
Train Epoch: 25 [4332/10752 (40%)]	 Regressor Loss: -0.000000
Regressor Loss: -0.0000
Domain Loss: 0.0000
Train Epoch: 25 [4452/10752 (41%)]	 Regressor Loss: -0.209173
Regressor Loss: -0.2092
Domain Loss: 0.0000
Train Epoch: 25 [4572/10752 (43%)]	 Regressor Loss: -0.341575
Regressor Loss: -0.3416
Domain Loss: 0.0000
Train Epoch: 25 [4692/10752 (44%)]	 Regressor Loss: -0.317637
Regressor Loss: -0.3176
Domain Loss: 0.0000
Train Epoch: 25 [4812/10752 (45%)]	 Regressor Loss: -0.430362
Regressor Loss: -0.4304
Domain Loss: 0.0000
Train Epoch: 25 [4932/10752 (46%)]	 Regressor Loss: -0.384404
Regressor Loss: -0.3844
Domain Loss: 0.0000
Train Epoch: 25 [5052/10752 (47%)]	 Regressor Loss: -0.590404
Regressor Loss: -0.5904
Domain Loss: 0.0000
Train Epoch: 25 [5172/10752 (48%)]	 Regressor Loss: -0.326181
Regressor Loss: -0.3262
Domain Loss: 0.0000
Train Epoch: 25 [5292/10752 (49%)]	 Regressor Loss: -0.757945
Regressor Loss: -0.7579
Domain Loss: 0.0000
Train Epoch: 25 [5412/10752 (50%)]	 Regressor Loss: -0.355273
Regressor Loss: -0.3553
Domain Loss: 0.0000
Train Epoch: 25 [5532/10752 (51%)]	 Regressor Loss: -0.922409
Regressor Loss: -0.9224
Domain Loss: 0.0000
Train Epoch: 25 [5652/10752 (53%)]	 Regressor Loss: -0.345233
Regressor Loss: -0.3452
Domain Loss: 0.0000
Train Epoch: 25 [5772/10752 (54%)]	 Regressor Loss: -0.869523
Regressor Loss: -0.8695
Domain Loss: 0.0001
Train Epoch: 25 [5892/10752 (55%)]	 Regressor Loss: -0.289448
Regressor Loss: -0.2894
Domain Loss: 0.0000
Train Epoch: 25 [6012/10752 (56%)]	 Regressor Loss: -0.864845
Regressor Loss: -0.8648
Domain Loss: 0.0000
Train Epoch: 25 [6132/10752 (57%)]	 Regressor Loss: -0.619726
Regressor Loss: -0.6197
Domain Loss: 0.0000
Train Epoch: 25 [6252/10752 (58%)]	 Regressor Loss: -0.831033
Regressor Loss: -0.8310
Domain Loss: 0.0001
Train Epoch: 25 [6372/10752 (59%)]	 Regressor Loss: -0.204497
Regressor Loss: -0.2045
Domain Loss: 0.0000
Train Epoch: 25 [6492/10752 (60%)]	 Regressor Loss: -0.881462
Regressor Loss: -0.8815
Domain Loss: 0.0000
Train Epoch: 25 [6612/10752 (61%)]	 Regressor Loss: -0.300139
Regressor Loss: -0.3001
Domain Loss: 0.0000
Train Epoch: 25 [6732/10752 (63%)]	 Regressor Loss: -0.756440
Regressor Loss: -0.7564
Domain Loss: 0.0000
Train Epoch: 25 [6852/10752 (64%)]	 Regressor Loss: -0.233534
Regressor Loss: -0.2335
Domain Loss: 0.0000
Train Epoch: 25 [6972/10752 (65%)]	 Regressor Loss: -0.937202
Regressor Loss: -0.9372
Domain Loss: 0.0000
Train Epoch: 25 [7092/10752 (66%)]	 Regressor Loss: -0.345363
Regressor Loss: -0.3454
Domain Loss: 0.0000
Train Epoch: 25 [7212/10752 (67%)]	 Regressor Loss: -0.726340
Regressor Loss: -0.7263
Domain Loss: 0.0000
Train Epoch: 25 [7332/10752 (68%)]	 Regressor Loss: -0.419928
Regressor Loss: -0.4199
Domain Loss: 0.0000
Train Epoch: 25 [7452/10752 (69%)]	 Regressor Loss: -0.875668
Regressor Loss: -0.8757
Domain Loss: 0.0000
Train Epoch: 25 [7572/10752 (70%)]	 Regressor Loss: -0.218604
Regressor Loss: -0.2186
Domain Loss: 0.0000
Train Epoch: 25 [7692/10752 (72%)]	 Regressor Loss: -0.568642
Regressor Loss: -0.5686
Domain Loss: 0.0000
Train Epoch: 25 [7812/10752 (73%)]	 Regressor Loss: -0.449626
Regressor Loss: -0.4496
Domain Loss: 0.0000
Train Epoch: 25 [7932/10752 (74%)]	 Regressor Loss: -0.242242
Regressor Loss: -0.2422
Domain Loss: 0.0000
Train Epoch: 25 [8052/10752 (75%)]	 Regressor Loss: -0.523555
Regressor Loss: -0.5236
Domain Loss: 0.0000
Train Epoch: 25 [8172/10752 (76%)]	 Regressor Loss: -0.386507
Regressor Loss: -0.3865
Domain Loss: 0.0000
Train Epoch: 25 [8292/10752 (77%)]	 Regressor Loss: -0.676574
Regressor Loss: -0.6766
Domain Loss: 0.0000
Train Epoch: 25 [8412/10752 (78%)]	 Regressor Loss: -0.206373
Regressor Loss: -0.2064
Domain Loss: 0.0000
Train Epoch: 25 [8532/10752 (79%)]	 Regressor Loss: -0.670604
Regressor Loss: -0.6706
Domain Loss: 0.0000
Train Epoch: 25 [8652/10752 (80%)]	 Regressor Loss: -0.400141
Regressor Loss: -0.4001
Domain Loss: 0.0000
Train Epoch: 25 [8772/10752 (82%)]	 Regressor Loss: -0.852236
Regressor Loss: -0.8522
Domain Loss: 0.0000
Train Epoch: 25 [8892/10752 (83%)]	 Regressor Loss: -0.421644
Regressor Loss: -0.4216
Domain Loss: 0.0000
Train Epoch: 25 [9012/10752 (84%)]	 Regressor Loss: -0.933241
Regressor Loss: -0.9332
Domain Loss: 0.0000
Train Epoch: 25 [9132/10752 (85%)]	 Regressor Loss: -0.344638
Regressor Loss: -0.3446
Domain Loss: 0.0000
Train Epoch: 25 [9252/10752 (86%)]	 Regressor Loss: -0.888702
Regressor Loss: -0.8887
Domain Loss: 0.0000
Train Epoch: 25 [9372/10752 (87%)]	 Regressor Loss: -0.464022
Regressor Loss: -0.4640
Domain Loss: 0.0000
Training set: Average loss: -0.5157
Training set: Average Domain loss: 0.0000
Training set: Average Acc: 1.0000
Validation set: Average loss: -0.4952
Validation set: Average Domain loss: 0.0007
 Validation set: Average Acc: 0.9992
Training Main Encoder
Epoch  26 / 300
Train Epoch: 26 [12/10752 (0%)]	 Regressor Loss: -0.589947
Regressor Loss: -0.5899
Domain Loss: 0.0000
Train Epoch: 26 [132/10752 (1%)]	 Regressor Loss: -0.362716
Regressor Loss: -0.3627
Domain Loss: 0.0000
Train Epoch: 26 [252/10752 (2%)]	 Regressor Loss: -0.816400
Regressor Loss: -0.8164
Domain Loss: 0.0000
Train Epoch: 26 [372/10752 (3%)]	 Regressor Loss: -0.336809
Regressor Loss: -0.3368
Domain Loss: 0.0000
Train Epoch: 26 [492/10752 (5%)]	 Regressor Loss: -0.814644
Regressor Loss: -0.8146
Domain Loss: 0.0000
Train Epoch: 26 [612/10752 (6%)]	 Regressor Loss: -0.301807
Regressor Loss: -0.3018
Domain Loss: 0.0000
Train Epoch: 26 [732/10752 (7%)]	 Regressor Loss: -0.900134
Regressor Loss: -0.9001
Domain Loss: 0.0000
Train Epoch: 26 [852/10752 (8%)]	 Regressor Loss: -0.330380
Regressor Loss: -0.3304
Domain Loss: 0.0000
Train Epoch: 26 [972/10752 (9%)]	 Regressor Loss: -0.466189
Regressor Loss: -0.4662
Domain Loss: 0.0000
Train Epoch: 26 [1092/10752 (10%)]	 Regressor Loss: -0.375606
Regressor Loss: -0.3756
Domain Loss: 0.0000
Train Epoch: 26 [1212/10752 (11%)]	 Regressor Loss: -0.295725
Regressor Loss: -0.2957
Domain Loss: 0.0000
Train Epoch: 26 [1332/10752 (12%)]	 Regressor Loss: -0.531466
Regressor Loss: -0.5315
Domain Loss: 0.0000
Train Epoch: 26 [1452/10752 (14%)]	 Regressor Loss: -0.283518
Regressor Loss: -0.2835
Domain Loss: 0.0000
Train Epoch: 26 [1572/10752 (15%)]	 Regressor Loss: -0.521461
Regressor Loss: -0.5215
Domain Loss: 0.0000
Train Epoch: 26 [1692/10752 (16%)]	 Regressor Loss: -0.364182
Regressor Loss: -0.3642
Domain Loss: 0.0000
Train Epoch: 26 [1812/10752 (17%)]	 Regressor Loss: -0.351432
Regressor Loss: -0.3514
Domain Loss: 0.0000
Train Epoch: 26 [1932/10752 (18%)]	 Regressor Loss: -0.320367
Regressor Loss: -0.3204
Domain Loss: 0.0000
Train Epoch: 26 [2052/10752 (19%)]	 Regressor Loss: -0.835979
Regressor Loss: -0.8360
Domain Loss: 0.0000
Train Epoch: 26 [2172/10752 (20%)]	 Regressor Loss: -0.428292
Regressor Loss: -0.4283
Domain Loss: 0.0000
Train Epoch: 26 [2292/10752 (21%)]	 Regressor Loss: -0.781218
Regressor Loss: -0.7812
Domain Loss: 0.0000
Train Epoch: 26 [2412/10752 (22%)]	 Regressor Loss: -0.053000
Regressor Loss: -0.0530
Domain Loss: 0.0000
Train Epoch: 26 [2532/10752 (24%)]	 Regressor Loss: -0.736083
Regressor Loss: -0.7361
Domain Loss: 0.0000
Train Epoch: 26 [2652/10752 (25%)]	 Regressor Loss: -0.278836
Regressor Loss: -0.2788
Domain Loss: 0.0000
Train Epoch: 26 [2772/10752 (26%)]	 Regressor Loss: -0.988954
Regressor Loss: -0.9890
Domain Loss: 0.0000
Train Epoch: 26 [2892/10752 (27%)]	 Regressor Loss: -0.223799
Regressor Loss: -0.2238
Domain Loss: 0.0000
Train Epoch: 26 [3012/10752 (28%)]	 Regressor Loss: -0.777775
Regressor Loss: -0.7778
Domain Loss: 0.0000
Train Epoch: 26 [3132/10752 (29%)]	 Regressor Loss: -0.730751
Regressor Loss: -0.7308
Domain Loss: 0.0000
Train Epoch: 26 [3252/10752 (30%)]	 Regressor Loss: -0.822379
Regressor Loss: -0.8224
Domain Loss: 0.0000
Train Epoch: 26 [3372/10752 (31%)]	 Regressor Loss: -0.352342
Regressor Loss: -0.3523
Domain Loss: 0.0000
Train Epoch: 26 [3492/10752 (32%)]	 Regressor Loss: -0.954130
Regressor Loss: -0.9541
Domain Loss: 0.0000
Train Epoch: 26 [3612/10752 (34%)]	 Regressor Loss: -0.301314
Regressor Loss: -0.3013
Domain Loss: 0.0000
Train Epoch: 26 [3732/10752 (35%)]	 Regressor Loss: -0.845132
Regressor Loss: -0.8451
Domain Loss: 0.0000
Train Epoch: 26 [3852/10752 (36%)]	 Regressor Loss: -0.459660
Regressor Loss: -0.4597
Domain Loss: 0.0000
Train Epoch: 26 [3972/10752 (37%)]	 Regressor Loss: -0.829544
Regressor Loss: -0.8295
Domain Loss: 0.0000
Train Epoch: 26 [4092/10752 (38%)]	 Regressor Loss: -0.397131
Regressor Loss: -0.3971
Domain Loss: 0.0000
Train Epoch: 26 [4212/10752 (39%)]	 Regressor Loss: -0.664950
Regressor Loss: -0.6649
Domain Loss: 0.0000
Train Epoch: 26 [4332/10752 (40%)]	 Regressor Loss: -0.008244
Regressor Loss: -0.0082
Domain Loss: 0.0000
Train Epoch: 26 [4452/10752 (41%)]	 Regressor Loss: -0.477231
Regressor Loss: -0.4772
Domain Loss: 0.0000
Train Epoch: 26 [4572/10752 (43%)]	 Regressor Loss: -0.493910
Regressor Loss: -0.4939
Domain Loss: 0.0000
Train Epoch: 26 [4692/10752 (44%)]	 Regressor Loss: -0.414963
Regressor Loss: -0.4150
Domain Loss: 0.0000
Train Epoch: 26 [4812/10752 (45%)]	 Regressor Loss: -0.465729
Regressor Loss: -0.4657
Domain Loss: 0.0000
Train Epoch: 26 [4932/10752 (46%)]	 Regressor Loss: -0.361862
Regressor Loss: -0.3619
Domain Loss: 0.0000
Train Epoch: 26 [5052/10752 (47%)]	 Regressor Loss: -0.591501
Regressor Loss: -0.5915
Domain Loss: 0.0000
Train Epoch: 26 [5172/10752 (48%)]	 Regressor Loss: -0.377555
Regressor Loss: -0.3776
Domain Loss: 0.0000
Train Epoch: 26 [5292/10752 (49%)]	 Regressor Loss: -0.396074
Regressor Loss: -0.3961
Domain Loss: 0.0000
Train Epoch: 26 [5412/10752 (50%)]	 Regressor Loss: -0.399650
Regressor Loss: -0.3996
Domain Loss: 0.0000
Train Epoch: 26 [5532/10752 (51%)]	 Regressor Loss: -0.650954
Regressor Loss: -0.6510
Domain Loss: 0.0000
Train Epoch: 26 [5652/10752 (53%)]	 Regressor Loss: -0.653981
Regressor Loss: -0.6540
Domain Loss: 0.0000
Train Epoch: 26 [5772/10752 (54%)]	 Regressor Loss: -0.694796
Regressor Loss: -0.6948
Domain Loss: 0.0000
Train Epoch: 26 [5892/10752 (55%)]	 Regressor Loss: -0.353555
Regressor Loss: -0.3536
Domain Loss: 0.0000
Train Epoch: 26 [6012/10752 (56%)]	 Regressor Loss: -0.851038
Regressor Loss: -0.8510
Domain Loss: 0.0001
Train Epoch: 26 [6132/10752 (57%)]	 Regressor Loss: -0.629404
Regressor Loss: -0.6294
Domain Loss: 0.0000
Train Epoch: 26 [6252/10752 (58%)]	 Regressor Loss: -0.782026
Regressor Loss: -0.7820
Domain Loss: 0.0000
Train Epoch: 26 [6372/10752 (59%)]	 Regressor Loss: -0.226474
Regressor Loss: -0.2265
Domain Loss: 0.0000
Train Epoch: 26 [6492/10752 (60%)]	 Regressor Loss: -0.842750
Regressor Loss: -0.8428
Domain Loss: 0.0000
Train Epoch: 26 [6612/10752 (61%)]	 Regressor Loss: -0.471150
Regressor Loss: -0.4712
Domain Loss: 0.0000
Train Epoch: 26 [6732/10752 (63%)]	 Regressor Loss: -0.994944
Regressor Loss: -0.9949
Domain Loss: 0.0000
Train Epoch: 26 [6852/10752 (64%)]	 Regressor Loss: -0.245754
Regressor Loss: -0.2458
Domain Loss: 0.0000
Train Epoch: 26 [6972/10752 (65%)]	 Regressor Loss: -0.918012
Regressor Loss: -0.9180
Domain Loss: 0.0000
Train Epoch: 26 [7092/10752 (66%)]	 Regressor Loss: -0.165921
Regressor Loss: -0.1659
Domain Loss: 0.0000
Train Epoch: 26 [7212/10752 (67%)]	 Regressor Loss: -0.652646
Regressor Loss: -0.6526
Domain Loss: 0.0000
Train Epoch: 26 [7332/10752 (68%)]	 Regressor Loss: -0.252468
Regressor Loss: -0.2525
Domain Loss: 0.0000
Train Epoch: 26 [7452/10752 (69%)]	 Regressor Loss: -0.722997
Regressor Loss: -0.7230
Domain Loss: 0.0000
Train Epoch: 26 [7572/10752 (70%)]	 Regressor Loss: -0.503752
Regressor Loss: -0.5038
Domain Loss: 0.0000
Train Epoch: 26 [7692/10752 (72%)]	 Regressor Loss: -0.554647
Regressor Loss: -0.5546
Domain Loss: 0.0000
Train Epoch: 26 [7812/10752 (73%)]	 Regressor Loss: -0.330714
Regressor Loss: -0.3307
Domain Loss: 0.0000
Train Epoch: 26 [7932/10752 (74%)]	 Regressor Loss: -0.598084
Regressor Loss: -0.5981
Domain Loss: 0.0000
Train Epoch: 26 [8052/10752 (75%)]	 Regressor Loss: -0.200832
Regressor Loss: -0.2008
Domain Loss: 0.0000
Train Epoch: 26 [8172/10752 (76%)]	 Regressor Loss: -0.540261
Regressor Loss: -0.5403
Domain Loss: 0.0000
Train Epoch: 26 [8292/10752 (77%)]	 Regressor Loss: -0.739804
Regressor Loss: -0.7398
Domain Loss: 0.0000
Train Epoch: 26 [8412/10752 (78%)]	 Regressor Loss: -0.322426
Regressor Loss: -0.3224
Domain Loss: 0.0000
Train Epoch: 26 [8532/10752 (79%)]	 Regressor Loss: -0.826490
Regressor Loss: -0.8265
Domain Loss: 0.0000
Train Epoch: 26 [8652/10752 (80%)]	 Regressor Loss: -0.550274
Regressor Loss: -0.5503
Domain Loss: 0.0000
Train Epoch: 26 [8772/10752 (82%)]	 Regressor Loss: -0.762838
Regressor Loss: -0.7628
Domain Loss: 0.0000
Train Epoch: 26 [8892/10752 (83%)]	 Regressor Loss: -0.349906
Regressor Loss: -0.3499
Domain Loss: 0.0000
Train Epoch: 26 [9012/10752 (84%)]	 Regressor Loss: -0.974753
Regressor Loss: -0.9748
Domain Loss: 0.0090
Train Epoch: 26 [9132/10752 (85%)]	 Regressor Loss: -0.329717
Regressor Loss: -0.3297
Domain Loss: 0.0000
Train Epoch: 26 [9252/10752 (86%)]	 Regressor Loss: -0.869247
Regressor Loss: -0.8692
Domain Loss: 0.0001
Train Epoch: 26 [9372/10752 (87%)]	 Regressor Loss: -0.513129
Regressor Loss: -0.5131
Domain Loss: 0.0000
Training set: Average loss: -0.5270
Training set: Average Domain loss: 0.0000
Training set: Average Acc: 1.0000
Validation set: Average loss: -0.5058
Validation set: Average Domain loss: 0.0002
 Validation set: Average Acc: 1.0000
Training Main Encoder
Epoch  27 / 300
Train Epoch: 27 [12/10752 (0%)]	 Regressor Loss: -0.602901
Regressor Loss: -0.6029
Domain Loss: 0.0000
Train Epoch: 27 [132/10752 (1%)]	 Regressor Loss: -0.405157
Regressor Loss: -0.4052
Domain Loss: 0.0033
Train Epoch: 27 [252/10752 (2%)]	 Regressor Loss: -0.903701
Regressor Loss: -0.9037
Domain Loss: 0.0000
Train Epoch: 27 [372/10752 (3%)]	 Regressor Loss: -0.380958
Regressor Loss: -0.3810
Domain Loss: 0.0000
Train Epoch: 27 [492/10752 (5%)]	 Regressor Loss: -0.930302
Regressor Loss: -0.9303
Domain Loss: 0.0000
Train Epoch: 27 [612/10752 (6%)]	 Regressor Loss: -0.302544
Regressor Loss: -0.3025
Domain Loss: 0.0000
Train Epoch: 27 [732/10752 (7%)]	 Regressor Loss: -0.937677
Regressor Loss: -0.9377
Domain Loss: 0.0000
Train Epoch: 27 [852/10752 (8%)]	 Regressor Loss: -0.391242
Regressor Loss: -0.3912
Domain Loss: 0.0000
Train Epoch: 27 [972/10752 (9%)]	 Regressor Loss: -0.333254
Regressor Loss: -0.3333
Domain Loss: 0.0000
Train Epoch: 27 [1092/10752 (10%)]	 Regressor Loss: -0.391955
Regressor Loss: -0.3920
Domain Loss: 0.0000
Train Epoch: 27 [1212/10752 (11%)]	 Regressor Loss: -0.298977
Regressor Loss: -0.2990
Domain Loss: 0.0000
Train Epoch: 27 [1332/10752 (12%)]	 Regressor Loss: -0.540363
Regressor Loss: -0.5404
Domain Loss: 0.0000
Train Epoch: 27 [1452/10752 (14%)]	 Regressor Loss: -0.394038
Regressor Loss: -0.3940
Domain Loss: 0.0000
Train Epoch: 27 [1572/10752 (15%)]	 Regressor Loss: -0.520555
Regressor Loss: -0.5206
Domain Loss: 0.0040
Train Epoch: 27 [1692/10752 (16%)]	 Regressor Loss: -0.379477
Regressor Loss: -0.3795
Domain Loss: 0.0000
Train Epoch: 27 [1812/10752 (17%)]	 Regressor Loss: -0.612839
Regressor Loss: -0.6128
Domain Loss: 0.0000
Train Epoch: 27 [1932/10752 (18%)]	 Regressor Loss: -0.297349
Regressor Loss: -0.2973
Domain Loss: 0.0000
Train Epoch: 27 [2052/10752 (19%)]	 Regressor Loss: -0.852113
Regressor Loss: -0.8521
Domain Loss: 0.0000
Train Epoch: 27 [2172/10752 (20%)]	 Regressor Loss: -0.319604
Regressor Loss: -0.3196
Domain Loss: 0.0000
Train Epoch: 27 [2292/10752 (21%)]	 Regressor Loss: -0.712518
Regressor Loss: -0.7125
Domain Loss: 0.0000
Train Epoch: 27 [2412/10752 (22%)]	 Regressor Loss: -0.119415
Regressor Loss: -0.1194
Domain Loss: 0.0000
Train Epoch: 27 [2532/10752 (24%)]	 Regressor Loss: -0.713743
Regressor Loss: -0.7137
Domain Loss: 0.0000
Train Epoch: 27 [2652/10752 (25%)]	 Regressor Loss: -0.288504
Regressor Loss: -0.2885
Domain Loss: 0.0000
Train Epoch: 27 [2772/10752 (26%)]	 Regressor Loss: -0.662573
Regressor Loss: -0.6626
Domain Loss: 0.0000
Train Epoch: 27 [2892/10752 (27%)]	 Regressor Loss: -0.430273
Regressor Loss: -0.4303
Domain Loss: 0.0000
Train Epoch: 27 [3012/10752 (28%)]	 Regressor Loss: -0.881085
Regressor Loss: -0.8811
Domain Loss: 0.0000
Train Epoch: 27 [3132/10752 (29%)]	 Regressor Loss: -0.548116
Regressor Loss: -0.5481
Domain Loss: 0.0000
Train Epoch: 27 [3252/10752 (30%)]	 Regressor Loss: -0.897242
Regressor Loss: -0.8972
Domain Loss: 0.0000
Train Epoch: 27 [3372/10752 (31%)]	 Regressor Loss: -0.296460
Regressor Loss: -0.2965
Domain Loss: 0.0000
Train Epoch: 27 [3492/10752 (32%)]	 Regressor Loss: -1.015725
Regressor Loss: -1.0157
Domain Loss: 0.0000
Train Epoch: 27 [3612/10752 (34%)]	 Regressor Loss: -0.326690
Regressor Loss: -0.3267
Domain Loss: 0.0000
Train Epoch: 27 [3732/10752 (35%)]	 Regressor Loss: -0.820868
Regressor Loss: -0.8209
Domain Loss: 0.0000
Train Epoch: 27 [3852/10752 (36%)]	 Regressor Loss: -0.498768
Regressor Loss: -0.4988
Domain Loss: 0.0000
Train Epoch: 27 [3972/10752 (37%)]	 Regressor Loss: -0.806715
Regressor Loss: -0.8067
Domain Loss: 0.0000
Train Epoch: 27 [4092/10752 (38%)]	 Regressor Loss: -0.158237
Regressor Loss: -0.1582
Domain Loss: 0.0000
Train Epoch: 27 [4212/10752 (39%)]	 Regressor Loss: -0.577803
Regressor Loss: -0.5778
Domain Loss: 0.0000
Train Epoch: 27 [4332/10752 (40%)]	 Regressor Loss: -0.323058
Regressor Loss: -0.3231
Domain Loss: 0.0000
Train Epoch: 27 [4452/10752 (41%)]	 Regressor Loss: -0.428094
Regressor Loss: -0.4281
Domain Loss: 0.0000
Train Epoch: 27 [4572/10752 (43%)]	 Regressor Loss: -0.370078
Regressor Loss: -0.3701
Domain Loss: 0.0000
Train Epoch: 27 [4692/10752 (44%)]	 Regressor Loss: -0.412927
Regressor Loss: -0.4129
Domain Loss: 0.0000
Train Epoch: 27 [4812/10752 (45%)]	 Regressor Loss: -0.372980
Regressor Loss: -0.3730
Domain Loss: 0.0000
Train Epoch: 27 [4932/10752 (46%)]	 Regressor Loss: -0.425035
Regressor Loss: -0.4250
Domain Loss: 0.0000
Train Epoch: 27 [5052/10752 (47%)]	 Regressor Loss: -0.699935
Regressor Loss: -0.6999
Domain Loss: 0.0000
Train Epoch: 27 [5172/10752 (48%)]	 Regressor Loss: -0.272259
Regressor Loss: -0.2723
Domain Loss: 0.0000
Train Epoch: 27 [5292/10752 (49%)]	 Regressor Loss: -0.833087
Regressor Loss: -0.8331
Domain Loss: 0.0000
Train Epoch: 27 [5412/10752 (50%)]	 Regressor Loss: -0.320583
Regressor Loss: -0.3206
Domain Loss: 0.0000
Train Epoch: 27 [5532/10752 (51%)]	 Regressor Loss: -0.853977
Regressor Loss: -0.8540
Domain Loss: 0.0000
Train Epoch: 27 [5652/10752 (53%)]	 Regressor Loss: -0.331104
Regressor Loss: -0.3311
Domain Loss: 0.0000
Train Epoch: 27 [5772/10752 (54%)]	 Regressor Loss: -0.724144
Regressor Loss: -0.7241
Domain Loss: 0.0000
Train Epoch: 27 [5892/10752 (55%)]	 Regressor Loss: -0.431890
Regressor Loss: -0.4319
Domain Loss: 0.0000
Train Epoch: 27 [6012/10752 (56%)]	 Regressor Loss: -1.056936
Regressor Loss: -1.0569
Domain Loss: 0.0000
Train Epoch: 27 [6132/10752 (57%)]	 Regressor Loss: -0.647179
Regressor Loss: -0.6472
Domain Loss: 0.0000
Train Epoch: 27 [6252/10752 (58%)]	 Regressor Loss: -0.882836
Regressor Loss: -0.8828
Domain Loss: 0.0000
Train Epoch: 27 [6372/10752 (59%)]	 Regressor Loss: -0.572864
Regressor Loss: -0.5729
Domain Loss: 0.0000
Train Epoch: 27 [6492/10752 (60%)]	 Regressor Loss: -0.996683
Regressor Loss: -0.9967
Domain Loss: 0.0000
Train Epoch: 27 [6612/10752 (61%)]	 Regressor Loss: -0.403423
Regressor Loss: -0.4034
Domain Loss: 0.0000
Train Epoch: 27 [6732/10752 (63%)]	 Regressor Loss: -0.415475
Regressor Loss: -0.4155
Domain Loss: 0.0000
Train Epoch: 27 [6852/10752 (64%)]	 Regressor Loss: -0.356328
Regressor Loss: -0.3563
Domain Loss: 0.0000
Train Epoch: 27 [6972/10752 (65%)]	 Regressor Loss: -1.057750
Regressor Loss: -1.0578
Domain Loss: 0.0000
Train Epoch: 27 [7092/10752 (66%)]	 Regressor Loss: -0.215154
Regressor Loss: -0.2152
Domain Loss: 0.0000
Train Epoch: 27 [7212/10752 (67%)]	 Regressor Loss: -0.941739
Regressor Loss: -0.9417
Domain Loss: 0.0000
Train Epoch: 27 [7332/10752 (68%)]	 Regressor Loss: -0.354086
Regressor Loss: -0.3541
Domain Loss: 0.0000
Train Epoch: 27 [7452/10752 (69%)]	 Regressor Loss: -0.710882
Regressor Loss: -0.7109
Domain Loss: 0.0000
Train Epoch: 27 [7572/10752 (70%)]	 Regressor Loss: -0.322529
Regressor Loss: -0.3225
Domain Loss: 0.0000
Train Epoch: 27 [7692/10752 (72%)]	 Regressor Loss: -0.543012
Regressor Loss: -0.5430
Domain Loss: 0.0000
Train Epoch: 27 [7812/10752 (73%)]	 Regressor Loss: -0.529000
Regressor Loss: -0.5290
Domain Loss: 0.0000
Train Epoch: 27 [7932/10752 (74%)]	 Regressor Loss: -0.496197
Regressor Loss: -0.4962
Domain Loss: 0.0000
Train Epoch: 27 [8052/10752 (75%)]	 Regressor Loss: -0.506419
Regressor Loss: -0.5064
Domain Loss: 0.0000
Train Epoch: 27 [8172/10752 (76%)]	 Regressor Loss: -0.583738
Regressor Loss: -0.5837
Domain Loss: 0.0000
Train Epoch: 27 [8292/10752 (77%)]	 Regressor Loss: -0.669571
Regressor Loss: -0.6696
Domain Loss: 0.0000
Train Epoch: 27 [8412/10752 (78%)]	 Regressor Loss: -0.300985
Regressor Loss: -0.3010
Domain Loss: 0.0000
Train Epoch: 27 [8532/10752 (79%)]	 Regressor Loss: -0.457069
Regressor Loss: -0.4571
Domain Loss: 0.0000
Train Epoch: 27 [8652/10752 (80%)]	 Regressor Loss: -0.636669
Regressor Loss: -0.6367
Domain Loss: 0.0000
Train Epoch: 27 [8772/10752 (82%)]	 Regressor Loss: -0.624779
Regressor Loss: -0.6248
Domain Loss: 0.0000
Train Epoch: 27 [8892/10752 (83%)]	 Regressor Loss: -0.349140
Regressor Loss: -0.3491
Domain Loss: 0.0000
Train Epoch: 27 [9012/10752 (84%)]	 Regressor Loss: -0.905757
Regressor Loss: -0.9058
Domain Loss: 0.0000
Train Epoch: 27 [9132/10752 (85%)]	 Regressor Loss: -0.378423
Regressor Loss: -0.3784
Domain Loss: 0.0000
Train Epoch: 27 [9252/10752 (86%)]	 Regressor Loss: -0.698670
Regressor Loss: -0.6987
Domain Loss: 0.0000
Train Epoch: 27 [9372/10752 (87%)]	 Regressor Loss: -0.300369
Regressor Loss: -0.3004
Domain Loss: 0.0000
Training set: Average loss: -0.5504
Training set: Average Domain loss: 0.0000
Training set: Average Acc: 1.0000
Validation set: Average loss: -0.5239
Validation set: Average Domain loss: 0.0053
 Validation set: Average Acc: 0.9975
Training Main Encoder
Epoch  28 / 300
Train Epoch: 28 [12/10752 (0%)]	 Regressor Loss: -0.808936
Regressor Loss: -0.8089
Domain Loss: 0.0000
Train Epoch: 28 [132/10752 (1%)]	 Regressor Loss: -0.480901
Regressor Loss: -0.4809
Domain Loss: 0.0000
Train Epoch: 28 [252/10752 (2%)]	 Regressor Loss: -0.896675
Regressor Loss: -0.8967
Domain Loss: 0.0000
Train Epoch: 28 [372/10752 (3%)]	 Regressor Loss: -0.376676
Regressor Loss: -0.3767
Domain Loss: 0.0000
Train Epoch: 28 [492/10752 (5%)]	 Regressor Loss: -0.992898
Regressor Loss: -0.9929
Domain Loss: 0.0000
Train Epoch: 28 [612/10752 (6%)]	 Regressor Loss: -0.405921
Regressor Loss: -0.4059
Domain Loss: 0.0000
Train Epoch: 28 [732/10752 (7%)]	 Regressor Loss: -0.840374
Regressor Loss: -0.8404
Domain Loss: 0.0000
Train Epoch: 28 [852/10752 (8%)]	 Regressor Loss: -0.628909
Regressor Loss: -0.6289
Domain Loss: 0.0000
Train Epoch: 28 [972/10752 (9%)]	 Regressor Loss: -0.645873
Regressor Loss: -0.6459
Domain Loss: 0.0000
Train Epoch: 28 [1092/10752 (10%)]	 Regressor Loss: -0.295468
Regressor Loss: -0.2955
Domain Loss: 0.0000
Train Epoch: 28 [1212/10752 (11%)]	 Regressor Loss: -0.335101
Regressor Loss: -0.3351
Domain Loss: 0.0000
Train Epoch: 28 [1332/10752 (12%)]	 Regressor Loss: -0.215235
Regressor Loss: -0.2152
Domain Loss: 0.0000
Train Epoch: 28 [1452/10752 (14%)]	 Regressor Loss: -0.293338
Regressor Loss: -0.2933
Domain Loss: 0.0000
Train Epoch: 28 [1572/10752 (15%)]	 Regressor Loss: -0.624891
Regressor Loss: -0.6249
Domain Loss: 0.0000
Train Epoch: 28 [1692/10752 (16%)]	 Regressor Loss: -0.224281
Regressor Loss: -0.2243
Domain Loss: 0.0049
Train Epoch: 28 [1812/10752 (17%)]	 Regressor Loss: -0.573776
Regressor Loss: -0.5738
Domain Loss: 0.0000
Train Epoch: 28 [1932/10752 (18%)]	 Regressor Loss: -0.411630
Regressor Loss: -0.4116
Domain Loss: 0.0000
Train Epoch: 28 [2052/10752 (19%)]	 Regressor Loss: -0.796618
Regressor Loss: -0.7966
Domain Loss: 0.0000
Train Epoch: 28 [2172/10752 (20%)]	 Regressor Loss: -0.268300
Regressor Loss: -0.2683
Domain Loss: 0.0000
Train Epoch: 28 [2292/10752 (21%)]	 Regressor Loss: -0.800442
Regressor Loss: -0.8004
Domain Loss: 0.0000
Train Epoch: 28 [2412/10752 (22%)]	 Regressor Loss: -0.439259
Regressor Loss: -0.4393
Domain Loss: 0.0000
Train Epoch: 28 [2532/10752 (24%)]	 Regressor Loss: -0.833757
Regressor Loss: -0.8338
Domain Loss: 0.0000
Train Epoch: 28 [2652/10752 (25%)]	 Regressor Loss: -0.323669
Regressor Loss: -0.3237
Domain Loss: 0.0000
Train Epoch: 28 [2772/10752 (26%)]	 Regressor Loss: -0.921140
Regressor Loss: -0.9211
Domain Loss: 0.0000
Train Epoch: 28 [2892/10752 (27%)]	 Regressor Loss: -0.395369
Regressor Loss: -0.3954
Domain Loss: 0.0000
Train Epoch: 28 [3012/10752 (28%)]	 Regressor Loss: -0.859207
Regressor Loss: -0.8592
Domain Loss: 0.0000
Train Epoch: 28 [3132/10752 (29%)]	 Regressor Loss: -0.130123
Regressor Loss: -0.1301
Domain Loss: 0.0001
Train Epoch: 28 [3252/10752 (30%)]	 Regressor Loss: -0.809505
Regressor Loss: -0.8095
Domain Loss: 0.0000
Train Epoch: 28 [3372/10752 (31%)]	 Regressor Loss: -0.392241
Regressor Loss: -0.3922
Domain Loss: 0.0000
Train Epoch: 28 [3492/10752 (32%)]	 Regressor Loss: -1.011977
Regressor Loss: -1.0120
Domain Loss: 0.0000
Train Epoch: 28 [3612/10752 (34%)]	 Regressor Loss: -0.213403
Regressor Loss: -0.2134
Domain Loss: 0.0000
Train Epoch: 28 [3732/10752 (35%)]	 Regressor Loss: -0.858284
Regressor Loss: -0.8583
Domain Loss: 0.0000
Train Epoch: 28 [3852/10752 (36%)]	 Regressor Loss: -0.325891
Regressor Loss: -0.3259
Domain Loss: 0.0000
Train Epoch: 28 [3972/10752 (37%)]	 Regressor Loss: -0.874330
Regressor Loss: -0.8743
Domain Loss: 0.0000
Train Epoch: 28 [4092/10752 (38%)]	 Regressor Loss: -0.158920
Regressor Loss: -0.1589
Domain Loss: 0.0000
Train Epoch: 28 [4212/10752 (39%)]	 Regressor Loss: -0.312315
Regressor Loss: -0.3123
Domain Loss: 0.0000
Train Epoch: 28 [4332/10752 (40%)]	 Regressor Loss: -0.294299
Regressor Loss: -0.2943
Domain Loss: 0.0000
Train Epoch: 28 [4452/10752 (41%)]	 Regressor Loss: -0.396982
Regressor Loss: -0.3970
Domain Loss: 0.0000
Train Epoch: 28 [4572/10752 (43%)]	 Regressor Loss: -0.359229
Regressor Loss: -0.3592
Domain Loss: 0.0000
Train Epoch: 28 [4692/10752 (44%)]	 Regressor Loss: -0.420336
Regressor Loss: -0.4203
Domain Loss: 0.0000
Train Epoch: 28 [4812/10752 (45%)]	 Regressor Loss: -0.399638
Regressor Loss: -0.3996
Domain Loss: 0.0000
Train Epoch: 28 [4932/10752 (46%)]	 Regressor Loss: -0.227344
Regressor Loss: -0.2273
Domain Loss: 0.0000
Train Epoch: 28 [5052/10752 (47%)]	 Regressor Loss: -0.529400
Regressor Loss: -0.5294
Domain Loss: 0.0000
Train Epoch: 28 [5172/10752 (48%)]	 Regressor Loss: -0.330196
Regressor Loss: -0.3302
Domain Loss: 0.0000
Train Epoch: 28 [5292/10752 (49%)]	 Regressor Loss: -0.646066
Regressor Loss: -0.6461
Domain Loss: 0.0000
Train Epoch: 28 [5412/10752 (50%)]	 Regressor Loss: -0.050800
Regressor Loss: -0.0508
Domain Loss: 0.0000
Train Epoch: 28 [5532/10752 (51%)]	 Regressor Loss: -0.710903
Regressor Loss: -0.7109
Domain Loss: 0.0000
Train Epoch: 28 [5652/10752 (53%)]	 Regressor Loss: -0.551964
Regressor Loss: -0.5520
Domain Loss: 0.0000
Train Epoch: 28 [5772/10752 (54%)]	 Regressor Loss: -0.793424
Regressor Loss: -0.7934
Domain Loss: 0.0000
Train Epoch: 28 [5892/10752 (55%)]	 Regressor Loss: -0.395802
Regressor Loss: -0.3958
Domain Loss: 0.0000
Train Epoch: 28 [6012/10752 (56%)]	 Regressor Loss: -0.973391
Regressor Loss: -0.9734
Domain Loss: 0.0000
Train Epoch: 28 [6132/10752 (57%)]	 Regressor Loss: -0.622589
Regressor Loss: -0.6226
Domain Loss: 0.0000
Train Epoch: 28 [6252/10752 (58%)]	 Regressor Loss: -0.874355
Regressor Loss: -0.8744
Domain Loss: 0.0000
Train Epoch: 28 [6372/10752 (59%)]	 Regressor Loss: -0.337002
Regressor Loss: -0.3370
Domain Loss: 0.0000
Train Epoch: 28 [6492/10752 (60%)]	 Regressor Loss: -0.788060
Regressor Loss: -0.7881
Domain Loss: 0.0000
Train Epoch: 28 [6612/10752 (61%)]	 Regressor Loss: -0.421251
Regressor Loss: -0.4213
Domain Loss: 0.0000
Train Epoch: 28 [6732/10752 (63%)]	 Regressor Loss: -0.868668
Regressor Loss: -0.8687
Domain Loss: 0.0000
Train Epoch: 28 [6852/10752 (64%)]	 Regressor Loss: -0.428310
Regressor Loss: -0.4283
Domain Loss: 0.0000
Train Epoch: 28 [6972/10752 (65%)]	 Regressor Loss: -1.050999
Regressor Loss: -1.0510
Domain Loss: 0.0000
Train Epoch: 28 [7092/10752 (66%)]	 Regressor Loss: -0.325291
Regressor Loss: -0.3253
Domain Loss: 0.0000
Train Epoch: 28 [7212/10752 (67%)]	 Regressor Loss: -0.671341
Regressor Loss: -0.6713
Domain Loss: 0.0000
Train Epoch: 28 [7332/10752 (68%)]	 Regressor Loss: -0.292398
Regressor Loss: -0.2924
Domain Loss: 0.0000
Train Epoch: 28 [7452/10752 (69%)]	 Regressor Loss: -0.781670
Regressor Loss: -0.7817
Domain Loss: 0.0000
Train Epoch: 28 [7572/10752 (70%)]	 Regressor Loss: -0.317488
Regressor Loss: -0.3175
Domain Loss: 0.0000
Train Epoch: 28 [7692/10752 (72%)]	 Regressor Loss: -0.472145
Regressor Loss: -0.4721
Domain Loss: 0.0000
Train Epoch: 28 [7812/10752 (73%)]	 Regressor Loss: -0.358786
Regressor Loss: -0.3588
Domain Loss: 0.0000
Train Epoch: 28 [7932/10752 (74%)]	 Regressor Loss: -0.521959
Regressor Loss: -0.5220
Domain Loss: 0.0000
Train Epoch: 28 [8052/10752 (75%)]	 Regressor Loss: -0.564410
Regressor Loss: -0.5644
Domain Loss: 0.0000
Train Epoch: 28 [8172/10752 (76%)]	 Regressor Loss: -0.577665
Regressor Loss: -0.5777
Domain Loss: 0.0000
Train Epoch: 28 [8292/10752 (77%)]	 Regressor Loss: -0.745058
Regressor Loss: -0.7451
Domain Loss: 0.0000
Train Epoch: 28 [8412/10752 (78%)]	 Regressor Loss: -0.362753
Regressor Loss: -0.3628
Domain Loss: 0.0000
Train Epoch: 28 [8532/10752 (79%)]	 Regressor Loss: -0.624346
Regressor Loss: -0.6243
Domain Loss: 0.0000
Train Epoch: 28 [8652/10752 (80%)]	 Regressor Loss: -0.653526
Regressor Loss: -0.6535
Domain Loss: 0.0000
Train Epoch: 28 [8772/10752 (82%)]	 Regressor Loss: -0.920650
Regressor Loss: -0.9206
Domain Loss: 0.0000
Train Epoch: 28 [8892/10752 (83%)]	 Regressor Loss: -0.265421
Regressor Loss: -0.2654
Domain Loss: 0.0000
Train Epoch: 28 [9012/10752 (84%)]	 Regressor Loss: -0.946497
Regressor Loss: -0.9465
Domain Loss: 0.0000
Train Epoch: 28 [9132/10752 (85%)]	 Regressor Loss: -0.399287
Regressor Loss: -0.3993
Domain Loss: 0.0000
Train Epoch: 28 [9252/10752 (86%)]	 Regressor Loss: -0.854007
Regressor Loss: -0.8540
Domain Loss: 0.0000
Train Epoch: 28 [9372/10752 (87%)]	 Regressor Loss: -0.445007
Regressor Loss: -0.4450
Domain Loss: 0.0000
Training set: Average loss: -0.5580
Training set: Average Domain loss: 0.0020
Training set: Average Acc: 0.9995
Validation set: Average loss: -0.5242
Validation set: Average Domain loss: 0.0042
 Validation set: Average Acc: 0.9983
Training Main Encoder
Epoch  29 / 300
Train Epoch: 29 [12/10752 (0%)]	 Regressor Loss: -0.827073
Regressor Loss: -0.8271
Domain Loss: 0.0000
Train Epoch: 29 [132/10752 (1%)]	 Regressor Loss: -0.102255
Regressor Loss: -0.1023
Domain Loss: 0.0000
Train Epoch: 29 [252/10752 (2%)]	 Regressor Loss: -0.783468
Regressor Loss: -0.7835
Domain Loss: 0.0000
Train Epoch: 29 [372/10752 (3%)]	 Regressor Loss: -0.340855
Regressor Loss: -0.3409
Domain Loss: 0.0000
Train Epoch: 29 [492/10752 (5%)]	 Regressor Loss: -0.844492
Regressor Loss: -0.8445
Domain Loss: 0.0000
Train Epoch: 29 [612/10752 (6%)]	 Regressor Loss: -0.422580
Regressor Loss: -0.4226
Domain Loss: 0.0000
Train Epoch: 29 [732/10752 (7%)]	 Regressor Loss: -1.046972
Regressor Loss: -1.0470
Domain Loss: 0.0002
Train Epoch: 29 [852/10752 (8%)]	 Regressor Loss: -0.597171
Regressor Loss: -0.5972
Domain Loss: 0.0000
Train Epoch: 29 [972/10752 (9%)]	 Regressor Loss: -0.467593
Regressor Loss: -0.4676
Domain Loss: 0.0000
Train Epoch: 29 [1092/10752 (10%)]	 Regressor Loss: -0.406924
Regressor Loss: -0.4069
Domain Loss: 0.0000
Train Epoch: 29 [1212/10752 (11%)]	 Regressor Loss: -0.447429
Regressor Loss: -0.4474
Domain Loss: 0.0000
Train Epoch: 29 [1332/10752 (12%)]	 Regressor Loss: -0.537690
Regressor Loss: -0.5377
Domain Loss: 0.0000
Train Epoch: 29 [1452/10752 (14%)]	 Regressor Loss: -0.468478
Regressor Loss: -0.4685
Domain Loss: 0.0000
Train Epoch: 29 [1572/10752 (15%)]	 Regressor Loss: -0.558170
Regressor Loss: -0.5582
Domain Loss: 0.0000
Train Epoch: 29 [1692/10752 (16%)]	 Regressor Loss: -0.255481
Regressor Loss: -0.2555
Domain Loss: 0.0000
Train Epoch: 29 [1812/10752 (17%)]	 Regressor Loss: -0.669928
Regressor Loss: -0.6699
Domain Loss: 0.0000
Train Epoch: 29 [1932/10752 (18%)]	 Regressor Loss: -0.399845
Regressor Loss: -0.3998
Domain Loss: 0.0000
Train Epoch: 29 [2052/10752 (19%)]	 Regressor Loss: -0.827988
Regressor Loss: -0.8280
Domain Loss: 0.0012
Train Epoch: 29 [2172/10752 (20%)]	 Regressor Loss: -0.341447
Regressor Loss: -0.3414
Domain Loss: 0.0000
Train Epoch: 29 [2292/10752 (21%)]	 Regressor Loss: -0.906743
Regressor Loss: -0.9067
Domain Loss: 0.0000
Train Epoch: 29 [2412/10752 (22%)]	 Regressor Loss: -0.524815
Regressor Loss: -0.5248
Domain Loss: 0.0000
Train Epoch: 29 [2532/10752 (24%)]	 Regressor Loss: -0.798746
Regressor Loss: -0.7987
Domain Loss: 0.0000
Train Epoch: 29 [2652/10752 (25%)]	 Regressor Loss: -0.325782
Regressor Loss: -0.3258
Domain Loss: 0.0000
Train Epoch: 29 [2772/10752 (26%)]	 Regressor Loss: -1.083949
Regressor Loss: -1.0839
Domain Loss: 0.0000
Train Epoch: 29 [2892/10752 (27%)]	 Regressor Loss: -0.344254
Regressor Loss: -0.3443
Domain Loss: 0.0000
Train Epoch: 29 [3012/10752 (28%)]	 Regressor Loss: -0.919105
Regressor Loss: -0.9191
Domain Loss: 0.0000
Train Epoch: 29 [3132/10752 (29%)]	 Regressor Loss: -0.131603
Regressor Loss: -0.1316
Domain Loss: 0.0004
Train Epoch: 29 [3252/10752 (30%)]	 Regressor Loss: -0.952244
Regressor Loss: -0.9522
Domain Loss: 0.0000
Train Epoch: 29 [3372/10752 (31%)]	 Regressor Loss: -0.302372
Regressor Loss: -0.3024
Domain Loss: 0.0000
Train Epoch: 29 [3492/10752 (32%)]	 Regressor Loss: -0.964242
Regressor Loss: -0.9642
Domain Loss: 0.0000
Train Epoch: 29 [3612/10752 (34%)]	 Regressor Loss: -0.309534
Regressor Loss: -0.3095
Domain Loss: 0.0000
Train Epoch: 29 [3732/10752 (35%)]	 Regressor Loss: -1.018075
Regressor Loss: -1.0181
Domain Loss: 0.0000
Train Epoch: 29 [3852/10752 (36%)]	 Regressor Loss: -0.551777
Regressor Loss: -0.5518
Domain Loss: 0.0000
Train Epoch: 29 [3972/10752 (37%)]	 Regressor Loss: -0.813748
Regressor Loss: -0.8137
Domain Loss: 0.0000
Train Epoch: 29 [4092/10752 (38%)]	 Regressor Loss: -0.131901
Regressor Loss: -0.1319
Domain Loss: 0.0000
Train Epoch: 29 [4212/10752 (39%)]	 Regressor Loss: -0.846328
Regressor Loss: -0.8463
Domain Loss: 0.0000
Train Epoch: 29 [4332/10752 (40%)]	 Regressor Loss: -0.371362
Regressor Loss: -0.3714
Domain Loss: 0.0000
Train Epoch: 29 [4452/10752 (41%)]	 Regressor Loss: -0.576830
Regressor Loss: -0.5768
Domain Loss: 0.0000
Train Epoch: 29 [4572/10752 (43%)]	 Regressor Loss: -0.407616
Regressor Loss: -0.4076
Domain Loss: 0.0000
Train Epoch: 29 [4692/10752 (44%)]	 Regressor Loss: -0.352270
Regressor Loss: -0.3523
Domain Loss: 0.0000
Train Epoch: 29 [4812/10752 (45%)]	 Regressor Loss: -0.356113
Regressor Loss: -0.3561
Domain Loss: 0.0000
Train Epoch: 29 [4932/10752 (46%)]	 Regressor Loss: -0.234246
Regressor Loss: -0.2342
Domain Loss: 0.0000
Train Epoch: 29 [5052/10752 (47%)]	 Regressor Loss: -0.579495
Regressor Loss: -0.5795
Domain Loss: 0.0000
Train Epoch: 29 [5172/10752 (48%)]	 Regressor Loss: -0.490667
Regressor Loss: -0.4907
Domain Loss: 0.0000
Train Epoch: 29 [5292/10752 (49%)]	 Regressor Loss: -0.737407
Regressor Loss: -0.7374
Domain Loss: 0.0000
Train Epoch: 29 [5412/10752 (50%)]	 Regressor Loss: -0.414267
Regressor Loss: -0.4143
Domain Loss: 0.0000
Train Epoch: 29 [5532/10752 (51%)]	 Regressor Loss: -0.905998
Regressor Loss: -0.9060
Domain Loss: 0.0000
Train Epoch: 29 [5652/10752 (53%)]	 Regressor Loss: -0.606404
Regressor Loss: -0.6064
Domain Loss: 0.0000
Train Epoch: 29 [5772/10752 (54%)]	 Regressor Loss: -0.909015
Regressor Loss: -0.9090
Domain Loss: 0.0000
Train Epoch: 29 [5892/10752 (55%)]	 Regressor Loss: -0.660963
Regressor Loss: -0.6610
Domain Loss: 0.0000
Train Epoch: 29 [6012/10752 (56%)]	 Regressor Loss: -0.578579
Regressor Loss: -0.5786
Domain Loss: 0.0000
Train Epoch: 29 [6132/10752 (57%)]	 Regressor Loss: -0.646061
Regressor Loss: -0.6461
Domain Loss: 0.0000
Train Epoch: 29 [6252/10752 (58%)]	 Regressor Loss: -0.970602
Regressor Loss: -0.9706
Domain Loss: 0.0000
Train Epoch: 29 [6372/10752 (59%)]	 Regressor Loss: -0.417793
Regressor Loss: -0.4178
Domain Loss: 0.0002
Train Epoch: 29 [6492/10752 (60%)]	 Regressor Loss: -0.919426
Regressor Loss: -0.9194
Domain Loss: 0.0000
Train Epoch: 29 [6612/10752 (61%)]	 Regressor Loss: -0.369187
Regressor Loss: -0.3692
Domain Loss: 0.0000
Train Epoch: 29 [6732/10752 (63%)]	 Regressor Loss: -1.040772
Regressor Loss: -1.0408
Domain Loss: 0.0000
Train Epoch: 29 [6852/10752 (64%)]	 Regressor Loss: -0.376029
Regressor Loss: -0.3760
Domain Loss: 0.0000
Train Epoch: 29 [6972/10752 (65%)]	 Regressor Loss: -0.980694
Regressor Loss: -0.9807
Domain Loss: 0.0000
Train Epoch: 29 [7092/10752 (66%)]	 Regressor Loss: -0.374896
Regressor Loss: -0.3749
Domain Loss: 0.0000
Train Epoch: 29 [7212/10752 (67%)]	 Regressor Loss: -0.834943
Regressor Loss: -0.8349
Domain Loss: 0.0000
Train Epoch: 29 [7332/10752 (68%)]	 Regressor Loss: -0.324072
Regressor Loss: -0.3241
Domain Loss: 0.0000
Train Epoch: 29 [7452/10752 (69%)]	 Regressor Loss: -0.675732
Regressor Loss: -0.6757
Domain Loss: 0.0000
Train Epoch: 29 [7572/10752 (70%)]	 Regressor Loss: -0.534342
Regressor Loss: -0.5343
Domain Loss: 0.0000
Train Epoch: 29 [7692/10752 (72%)]	 Regressor Loss: -0.447619
Regressor Loss: -0.4476
Domain Loss: 0.0000
Train Epoch: 29 [7812/10752 (73%)]	 Regressor Loss: -0.537248
Regressor Loss: -0.5372
Domain Loss: 0.0000
Train Epoch: 29 [7932/10752 (74%)]	 Regressor Loss: -0.599071
Regressor Loss: -0.5991
Domain Loss: 0.0000
Train Epoch: 29 [8052/10752 (75%)]	 Regressor Loss: -0.436754
Regressor Loss: -0.4368
Domain Loss: 0.0000
Train Epoch: 29 [8172/10752 (76%)]	 Regressor Loss: -0.642249
Regressor Loss: -0.6422
Domain Loss: 0.0000
Train Epoch: 29 [8292/10752 (77%)]	 Regressor Loss: -0.734488
Regressor Loss: -0.7345
Domain Loss: 0.0000
Train Epoch: 29 [8412/10752 (78%)]	 Regressor Loss: -0.226255
Regressor Loss: -0.2263
Domain Loss: 0.0000
Train Epoch: 29 [8532/10752 (79%)]	 Regressor Loss: -0.692503
Regressor Loss: -0.6925
Domain Loss: 0.0000
Train Epoch: 29 [8652/10752 (80%)]	 Regressor Loss: -0.676443
Regressor Loss: -0.6764
Domain Loss: 0.0000
Train Epoch: 29 [8772/10752 (82%)]	 Regressor Loss: -0.962808
Regressor Loss: -0.9628
Domain Loss: 0.0000
Train Epoch: 29 [8892/10752 (83%)]	 Regressor Loss: -0.429665
Regressor Loss: -0.4297
Domain Loss: 0.0000
Train Epoch: 29 [9012/10752 (84%)]	 Regressor Loss: -0.895303
Regressor Loss: -0.8953
Domain Loss: 0.0000
Train Epoch: 29 [9132/10752 (85%)]	 Regressor Loss: -0.294729
Regressor Loss: -0.2947
Domain Loss: 0.0000
Train Epoch: 29 [9252/10752 (86%)]	 Regressor Loss: -0.787893
Regressor Loss: -0.7879
Domain Loss: 0.0000
Train Epoch: 29 [9372/10752 (87%)]	 Regressor Loss: -0.413125
Regressor Loss: -0.4131
Domain Loss: 0.0000
Training set: Average loss: -0.5727
Training set: Average Domain loss: 0.0000
Training set: Average Acc: 1.0000
Validation set: Average loss: -0.5366
Validation set: Average Domain loss: 0.0047
 Validation set: Average Acc: 0.9975
Training Main Encoder
Epoch  30 / 300
Train Epoch: 30 [12/10752 (0%)]	 Regressor Loss: -0.592394
Regressor Loss: -0.5924
Domain Loss: 0.0000
Train Epoch: 30 [132/10752 (1%)]	 Regressor Loss: -0.347639
Regressor Loss: -0.3476
Domain Loss: 0.0000
Train Epoch: 30 [252/10752 (2%)]	 Regressor Loss: -0.927934
Regressor Loss: -0.9279
Domain Loss: 0.0000
Train Epoch: 30 [372/10752 (3%)]	 Regressor Loss: -0.269314
Regressor Loss: -0.2693
Domain Loss: 0.0000
Train Epoch: 30 [492/10752 (5%)]	 Regressor Loss: -0.948002
Regressor Loss: -0.9480
Domain Loss: 0.0006
Train Epoch: 30 [612/10752 (6%)]	 Regressor Loss: -0.421876
Regressor Loss: -0.4219
Domain Loss: 0.0000
Train Epoch: 30 [732/10752 (7%)]	 Regressor Loss: -0.843493
Regressor Loss: -0.8435
Domain Loss: 0.0000
Train Epoch: 30 [852/10752 (8%)]	 Regressor Loss: -0.372394
Regressor Loss: -0.3724
Domain Loss: 0.0000
Train Epoch: 30 [972/10752 (9%)]	 Regressor Loss: -0.589731
Regressor Loss: -0.5897
Domain Loss: 0.0000
Train Epoch: 30 [1092/10752 (10%)]	 Regressor Loss: -0.115052
Regressor Loss: -0.1151
Domain Loss: 0.0000
Train Epoch: 30 [1212/10752 (11%)]	 Regressor Loss: -0.501840
Regressor Loss: -0.5018
Domain Loss: 0.0000
Train Epoch: 30 [1332/10752 (12%)]	 Regressor Loss: -0.453887
Regressor Loss: -0.4539
Domain Loss: 0.0000
Train Epoch: 30 [1452/10752 (14%)]	 Regressor Loss: -0.367265
Regressor Loss: -0.3673
Domain Loss: 0.0000
Train Epoch: 30 [1572/10752 (15%)]	 Regressor Loss: -0.553039
Regressor Loss: -0.5530
Domain Loss: 0.0000
Train Epoch: 30 [1692/10752 (16%)]	 Regressor Loss: -0.402313
Regressor Loss: -0.4023
Domain Loss: 0.0000
Train Epoch: 30 [1812/10752 (17%)]	 Regressor Loss: -0.542677
Regressor Loss: -0.5427
Domain Loss: 0.0000
Train Epoch: 30 [1932/10752 (18%)]	 Regressor Loss: -0.203950
Regressor Loss: -0.2039
Domain Loss: 0.0000
Train Epoch: 30 [2052/10752 (19%)]	 Regressor Loss: -0.770324
Regressor Loss: -0.7703
Domain Loss: 0.0000
Train Epoch: 30 [2172/10752 (20%)]	 Regressor Loss: -0.324953
Regressor Loss: -0.3250
Domain Loss: 0.0000
Train Epoch: 30 [2292/10752 (21%)]	 Regressor Loss: -0.856606
Regressor Loss: -0.8566
Domain Loss: 0.0000
Train Epoch: 30 [2412/10752 (22%)]	 Regressor Loss: -0.374027
Regressor Loss: -0.3740
Domain Loss: 0.0000
Train Epoch: 30 [2532/10752 (24%)]	 Regressor Loss: -0.908872
Regressor Loss: -0.9089
Domain Loss: 0.0000
Train Epoch: 30 [2652/10752 (25%)]	 Regressor Loss: -0.204154
Regressor Loss: -0.2042
Domain Loss: 0.0000
Train Epoch: 30 [2772/10752 (26%)]	 Regressor Loss: -0.886353
Regressor Loss: -0.8864
Domain Loss: 0.0000
Train Epoch: 30 [2892/10752 (27%)]	 Regressor Loss: -0.324598
Regressor Loss: -0.3246
Domain Loss: 0.0001
Train Epoch: 30 [3012/10752 (28%)]	 Regressor Loss: -0.870884
Regressor Loss: -0.8709
Domain Loss: 0.0000
Train Epoch: 30 [3132/10752 (29%)]	 Regressor Loss: -0.723730
Regressor Loss: -0.7237
Domain Loss: 0.0000
Train Epoch: 30 [3252/10752 (30%)]	 Regressor Loss: -0.758972
Regressor Loss: -0.7590
Domain Loss: 0.0135
Train Epoch: 30 [3372/10752 (31%)]	 Regressor Loss: -0.319328
Regressor Loss: -0.3193
Domain Loss: 0.0000
Train Epoch: 30 [3492/10752 (32%)]	 Regressor Loss: -0.977450
Regressor Loss: -0.9775
Domain Loss: 0.0000
Train Epoch: 30 [3612/10752 (34%)]	 Regressor Loss: -0.213559
Regressor Loss: -0.2136
Domain Loss: 0.0000
Train Epoch: 30 [3732/10752 (35%)]	 Regressor Loss: -0.923648
Regressor Loss: -0.9236
Domain Loss: 0.0000
Train Epoch: 30 [3852/10752 (36%)]	 Regressor Loss: -0.435353
Regressor Loss: -0.4354
Domain Loss: 0.0000
Train Epoch: 30 [3972/10752 (37%)]	 Regressor Loss: -0.957484
Regressor Loss: -0.9575
Domain Loss: 0.0000
Train Epoch: 30 [4092/10752 (38%)]	 Regressor Loss: -0.228195
Regressor Loss: -0.2282
Domain Loss: 0.0000
Train Epoch: 30 [4212/10752 (39%)]	 Regressor Loss: -0.727366
Regressor Loss: -0.7274
Domain Loss: 0.0000
Train Epoch: 30 [4332/10752 (40%)]	 Regressor Loss: -0.329303
Regressor Loss: -0.3293
Domain Loss: 0.0000
Train Epoch: 30 [4452/10752 (41%)]	 Regressor Loss: -0.390011
Regressor Loss: -0.3900
Domain Loss: 0.0000
Train Epoch: 30 [4572/10752 (43%)]	 Regressor Loss: -0.186186
Regressor Loss: -0.1862
Domain Loss: 0.0000
Train Epoch: 30 [4692/10752 (44%)]	 Regressor Loss: -0.407961
Regressor Loss: -0.4080
Domain Loss: 0.0000
Train Epoch: 30 [4812/10752 (45%)]	 Regressor Loss: -0.368087
Regressor Loss: -0.3681
Domain Loss: 0.0000
Train Epoch: 30 [4932/10752 (46%)]	 Regressor Loss: -0.201100
Regressor Loss: -0.2011
Domain Loss: 0.0000
Train Epoch: 30 [5052/10752 (47%)]	 Regressor Loss: -0.427973
Regressor Loss: -0.4280
Domain Loss: 0.0000
Train Epoch: 30 [5172/10752 (48%)]	 Regressor Loss: -0.355951
Regressor Loss: -0.3560
Domain Loss: 0.0000
Train Epoch: 30 [5292/10752 (49%)]	 Regressor Loss: -0.760320
Regressor Loss: -0.7603
Domain Loss: 0.0000
Train Epoch: 30 [5412/10752 (50%)]	 Regressor Loss: -0.386340
Regressor Loss: -0.3863
Domain Loss: 0.0000
Train Epoch: 30 [5532/10752 (51%)]	 Regressor Loss: -0.975843
Regressor Loss: -0.9758
Domain Loss: 0.0000
Train Epoch: 30 [5652/10752 (53%)]	 Regressor Loss: -0.568403
Regressor Loss: -0.5684
Domain Loss: 0.0000
Train Epoch: 30 [5772/10752 (54%)]	 Regressor Loss: -0.781125
Regressor Loss: -0.7811
Domain Loss: 0.0000
Train Epoch: 30 [5892/10752 (55%)]	 Regressor Loss: -0.648714
Regressor Loss: -0.6487
Domain Loss: 0.0000
Train Epoch: 30 [6012/10752 (56%)]	 Regressor Loss: -1.096676
Regressor Loss: -1.0967
Domain Loss: 0.0000
Train Epoch: 30 [6132/10752 (57%)]	 Regressor Loss: -0.588704
Regressor Loss: -0.5887
Domain Loss: 0.0001
Train Epoch: 30 [6252/10752 (58%)]	 Regressor Loss: -1.029674
Regressor Loss: -1.0297
Domain Loss: 0.0000
Train Epoch: 30 [6372/10752 (59%)]	 Regressor Loss: -0.474458
Regressor Loss: -0.4745
Domain Loss: 0.0000
Train Epoch: 30 [6492/10752 (60%)]	 Regressor Loss: -0.713679
Regressor Loss: -0.7137
Domain Loss: 0.0000
Train Epoch: 30 [6612/10752 (61%)]	 Regressor Loss: -0.049742
Regressor Loss: -0.0497
Domain Loss: 0.0003
Train Epoch: 30 [6732/10752 (63%)]	 Regressor Loss: -0.839391
Regressor Loss: -0.8394
Domain Loss: 0.0000
Train Epoch: 30 [6852/10752 (64%)]	 Regressor Loss: -0.312735
Regressor Loss: -0.3127
Domain Loss: 0.0000
Train Epoch: 30 [6972/10752 (65%)]	 Regressor Loss: -0.809641
Regressor Loss: -0.8096
Domain Loss: 0.0000
Train Epoch: 30 [7092/10752 (66%)]	 Regressor Loss: -0.513066
Regressor Loss: -0.5131
Domain Loss: 0.0000
Train Epoch: 30 [7212/10752 (67%)]	 Regressor Loss: -0.966680
Regressor Loss: -0.9667
Domain Loss: 0.0000
Train Epoch: 30 [7332/10752 (68%)]	 Regressor Loss: -0.451457
Regressor Loss: -0.4515
Domain Loss: 0.0000
Train Epoch: 30 [7452/10752 (69%)]	 Regressor Loss: -0.793970
Regressor Loss: -0.7940
Domain Loss: 0.0000
Train Epoch: 30 [7572/10752 (70%)]	 Regressor Loss: -0.512355
Regressor Loss: -0.5124
Domain Loss: 0.0000
Train Epoch: 30 [7692/10752 (72%)]	 Regressor Loss: -0.339459
Regressor Loss: -0.3395
Domain Loss: 0.0000
Train Epoch: 30 [7812/10752 (73%)]	 Regressor Loss: -0.541868
Regressor Loss: -0.5419
Domain Loss: 0.0000
Train Epoch: 30 [7932/10752 (74%)]	 Regressor Loss: -0.191961
Regressor Loss: -0.1920
Domain Loss: 0.0000
Train Epoch: 30 [8052/10752 (75%)]	 Regressor Loss: -0.661170
Regressor Loss: -0.6612
Domain Loss: 0.0000
Train Epoch: 30 [8172/10752 (76%)]	 Regressor Loss: -0.441448
Regressor Loss: -0.4414
Domain Loss: 0.0000
Train Epoch: 30 [8292/10752 (77%)]	 Regressor Loss: -0.732718
Regressor Loss: -0.7327
Domain Loss: 0.0000
Train Epoch: 30 [8412/10752 (78%)]	 Regressor Loss: -0.397258
Regressor Loss: -0.3973
Domain Loss: 0.0000
Train Epoch: 30 [8532/10752 (79%)]	 Regressor Loss: -0.743308
Regressor Loss: -0.7433
Domain Loss: 0.0000
Train Epoch: 30 [8652/10752 (80%)]	 Regressor Loss: -0.584638
Regressor Loss: -0.5846
Domain Loss: 0.0000
Train Epoch: 30 [8772/10752 (82%)]	 Regressor Loss: -0.932023
Regressor Loss: -0.9320
Domain Loss: 0.0000
Train Epoch: 30 [8892/10752 (83%)]	 Regressor Loss: -0.171275
Regressor Loss: -0.1713
Domain Loss: 0.0000
Train Epoch: 30 [9012/10752 (84%)]	 Regressor Loss: -0.716543
Regressor Loss: -0.7165
Domain Loss: 0.0001
Train Epoch: 30 [9132/10752 (85%)]	 Regressor Loss: -0.376538
Regressor Loss: -0.3765
Domain Loss: 0.0000
Train Epoch: 30 [9252/10752 (86%)]	 Regressor Loss: -0.914787
Regressor Loss: -0.9148
Domain Loss: 0.0000
Train Epoch: 30 [9372/10752 (87%)]	 Regressor Loss: -0.364822
Regressor Loss: -0.3648
Domain Loss: 0.0000
Training set: Average loss: -0.5781
Training set: Average Domain loss: 0.0003
Training set: Average Acc: 0.9999
Validation set: Average loss: -0.5652
Validation set: Average Domain loss: 0.0007
 Validation set: Average Acc: 1.0000
Training Main Encoder
Epoch  31 / 300
Train Epoch: 31 [12/10752 (0%)]	 Regressor Loss: -0.552444
Regressor Loss: -0.5524
Domain Loss: 0.0000
Train Epoch: 31 [132/10752 (1%)]	 Regressor Loss: -0.420584
Regressor Loss: -0.4206
Domain Loss: 0.0015
Train Epoch: 31 [252/10752 (2%)]	 Regressor Loss: -0.923768
Regressor Loss: -0.9238
Domain Loss: 0.0000
Train Epoch: 31 [372/10752 (3%)]	 Regressor Loss: -0.278938
Regressor Loss: -0.2789
Domain Loss: 0.0000
Train Epoch: 31 [492/10752 (5%)]	 Regressor Loss: -0.943791
Regressor Loss: -0.9438
Domain Loss: 0.0011
Train Epoch: 31 [612/10752 (6%)]	 Regressor Loss: -0.376613
Regressor Loss: -0.3766
Domain Loss: 0.0000
Train Epoch: 31 [732/10752 (7%)]	 Regressor Loss: -0.981826
Regressor Loss: -0.9818
Domain Loss: 0.0000
Train Epoch: 31 [852/10752 (8%)]	 Regressor Loss: -0.596929
Regressor Loss: -0.5969
Domain Loss: 0.0000
Train Epoch: 31 [972/10752 (9%)]	 Regressor Loss: -0.524487
Regressor Loss: -0.5245
Domain Loss: 0.0000
Train Epoch: 31 [1092/10752 (10%)]	 Regressor Loss: -0.249883
Regressor Loss: -0.2499
Domain Loss: 0.0000
Train Epoch: 31 [1212/10752 (11%)]	 Regressor Loss: -0.461229
Regressor Loss: -0.4612
Domain Loss: 0.0000
Train Epoch: 31 [1332/10752 (12%)]	 Regressor Loss: -0.434943
Regressor Loss: -0.4349
Domain Loss: 0.0000
Train Epoch: 31 [1452/10752 (14%)]	 Regressor Loss: -0.416789
Regressor Loss: -0.4168
Domain Loss: 0.0000
Train Epoch: 31 [1572/10752 (15%)]	 Regressor Loss: -0.690311
Regressor Loss: -0.6903
Domain Loss: 0.0000
Train Epoch: 31 [1692/10752 (16%)]	 Regressor Loss: -0.327673
Regressor Loss: -0.3277
Domain Loss: 0.0000
Train Epoch: 31 [1812/10752 (17%)]	 Regressor Loss: -0.741885
Regressor Loss: -0.7419
Domain Loss: 0.0000
Train Epoch: 31 [1932/10752 (18%)]	 Regressor Loss: -0.417190
Regressor Loss: -0.4172
Domain Loss: 0.0000
Train Epoch: 31 [2052/10752 (19%)]	 Regressor Loss: -0.844669
Regressor Loss: -0.8447
Domain Loss: 0.0000
Train Epoch: 31 [2172/10752 (20%)]	 Regressor Loss: -0.531726
Regressor Loss: -0.5317
Domain Loss: 0.0000
Train Epoch: 31 [2292/10752 (21%)]	 Regressor Loss: -0.779094
Regressor Loss: -0.7791
Domain Loss: 0.0000
Train Epoch: 31 [2412/10752 (22%)]	 Regressor Loss: -0.266718
Regressor Loss: -0.2667
Domain Loss: 0.0000
Train Epoch: 31 [2532/10752 (24%)]	 Regressor Loss: -0.710233
Regressor Loss: -0.7102
Domain Loss: 0.0000
Train Epoch: 31 [2652/10752 (25%)]	 Regressor Loss: -0.361272
Regressor Loss: -0.3613
Domain Loss: 0.0000
Train Epoch: 31 [2772/10752 (26%)]	 Regressor Loss: -1.052390
Regressor Loss: -1.0524
Domain Loss: 0.0000
Train Epoch: 31 [2892/10752 (27%)]	 Regressor Loss: -0.449381
Regressor Loss: -0.4494
Domain Loss: 0.0001
Train Epoch: 31 [3012/10752 (28%)]	 Regressor Loss: -0.863438
Regressor Loss: -0.8634
Domain Loss: 0.0000
Train Epoch: 31 [3132/10752 (29%)]	 Regressor Loss: -0.494663
Regressor Loss: -0.4947
Domain Loss: 0.0000
Train Epoch: 31 [3252/10752 (30%)]	 Regressor Loss: -0.869704
Regressor Loss: -0.8697
Domain Loss: 0.0000
Train Epoch: 31 [3372/10752 (31%)]	 Regressor Loss: -0.167463
Regressor Loss: -0.1675
Domain Loss: 0.0000
Train Epoch: 31 [3492/10752 (32%)]	 Regressor Loss: -1.072175
Regressor Loss: -1.0722
Domain Loss: 0.0000
Train Epoch: 31 [3612/10752 (34%)]	 Regressor Loss: -0.358808
Regressor Loss: -0.3588
Domain Loss: 0.0000
Train Epoch: 31 [3732/10752 (35%)]	 Regressor Loss: -0.787799
Regressor Loss: -0.7878
Domain Loss: 0.0000
Train Epoch: 31 [3852/10752 (36%)]	 Regressor Loss: -0.499680
Regressor Loss: -0.4997
Domain Loss: 0.0000
Train Epoch: 31 [3972/10752 (37%)]	 Regressor Loss: -0.852314
Regressor Loss: -0.8523
Domain Loss: 0.0000
Train Epoch: 31 [4092/10752 (38%)]	 Regressor Loss: -0.262234
Regressor Loss: -0.2622
Domain Loss: 0.0000
Train Epoch: 31 [4212/10752 (39%)]	 Regressor Loss: -0.567997
Regressor Loss: -0.5680
Domain Loss: 0.0000
Train Epoch: 31 [4332/10752 (40%)]	 Regressor Loss: -0.414237
Regressor Loss: -0.4142
Domain Loss: 0.0000
Train Epoch: 31 [4452/10752 (41%)]	 Regressor Loss: -0.519677
Regressor Loss: -0.5197
Domain Loss: 0.0000
Train Epoch: 31 [4572/10752 (43%)]	 Regressor Loss: -0.387347
Regressor Loss: -0.3873
Domain Loss: 0.0000
Train Epoch: 31 [4692/10752 (44%)]	 Regressor Loss: -0.456581
Regressor Loss: -0.4566
Domain Loss: 0.0000
Train Epoch: 31 [4812/10752 (45%)]	 Regressor Loss: -0.237390
Regressor Loss: -0.2374
Domain Loss: 0.0000
Train Epoch: 31 [4932/10752 (46%)]	 Regressor Loss: -0.275293
Regressor Loss: -0.2753
Domain Loss: 0.0000
Train Epoch: 31 [5052/10752 (47%)]	 Regressor Loss: -0.576341
Regressor Loss: -0.5763
Domain Loss: 0.0000
Train Epoch: 31 [5172/10752 (48%)]	 Regressor Loss: -0.537840
Regressor Loss: -0.5378
Domain Loss: 0.0000
Train Epoch: 31 [5292/10752 (49%)]	 Regressor Loss: -0.915740
Regressor Loss: -0.9157
Domain Loss: 0.0000
Train Epoch: 31 [5412/10752 (50%)]	 Regressor Loss: -0.396674
Regressor Loss: -0.3967
Domain Loss: 0.0000
Train Epoch: 31 [5532/10752 (51%)]	 Regressor Loss: -0.891150
Regressor Loss: -0.8912
Domain Loss: 0.0000
Train Epoch: 31 [5652/10752 (53%)]	 Regressor Loss: -0.430366
Regressor Loss: -0.4304
Domain Loss: 0.0000
Train Epoch: 31 [5772/10752 (54%)]	 Regressor Loss: -0.927940
Regressor Loss: -0.9279
Domain Loss: 0.0000
Train Epoch: 31 [5892/10752 (55%)]	 Regressor Loss: -0.570161
Regressor Loss: -0.5702
Domain Loss: 0.0000
Train Epoch: 31 [6012/10752 (56%)]	 Regressor Loss: -0.960782
Regressor Loss: -0.9608
Domain Loss: 0.0000
Train Epoch: 31 [6132/10752 (57%)]	 Regressor Loss: -0.717047
Regressor Loss: -0.7170
Domain Loss: 0.0000
Train Epoch: 31 [6252/10752 (58%)]	 Regressor Loss: -0.879401
Regressor Loss: -0.8794
Domain Loss: 0.0000
Train Epoch: 31 [6372/10752 (59%)]	 Regressor Loss: -0.476719
Regressor Loss: -0.4767
Domain Loss: 0.0000
Train Epoch: 31 [6492/10752 (60%)]	 Regressor Loss: -1.001266
Regressor Loss: -1.0013
Domain Loss: 0.0000
Train Epoch: 31 [6612/10752 (61%)]	 Regressor Loss: -0.494504
Regressor Loss: -0.4945
Domain Loss: 0.0002
Train Epoch: 31 [6732/10752 (63%)]	 Regressor Loss: -0.828557
Regressor Loss: -0.8286
Domain Loss: 0.0000
Train Epoch: 31 [6852/10752 (64%)]	 Regressor Loss: -0.378962
Regressor Loss: -0.3790
Domain Loss: 0.0000
Train Epoch: 31 [6972/10752 (65%)]	 Regressor Loss: -0.939503
Regressor Loss: -0.9395
Domain Loss: 0.0000
Train Epoch: 31 [7092/10752 (66%)]	 Regressor Loss: -0.537837
Regressor Loss: -0.5378
Domain Loss: 0.0000
Train Epoch: 31 [7212/10752 (67%)]	 Regressor Loss: -0.940627
Regressor Loss: -0.9406
Domain Loss: 0.0000
Train Epoch: 31 [7332/10752 (68%)]	 Regressor Loss: -0.419348
Regressor Loss: -0.4193
Domain Loss: 0.0000
Train Epoch: 31 [7452/10752 (69%)]	 Regressor Loss: -0.741811
Regressor Loss: -0.7418
Domain Loss: 0.0000
Train Epoch: 31 [7572/10752 (70%)]	 Regressor Loss: -0.378515
Regressor Loss: -0.3785
Domain Loss: 0.0000
Train Epoch: 31 [7692/10752 (72%)]	 Regressor Loss: -0.551771
Regressor Loss: -0.5518
Domain Loss: 0.0000
Train Epoch: 31 [7812/10752 (73%)]	 Regressor Loss: -0.513054
Regressor Loss: -0.5131
Domain Loss: 0.0000
Train Epoch: 31 [7932/10752 (74%)]	 Regressor Loss: -0.710196
Regressor Loss: -0.7102
Domain Loss: 0.0000
Train Epoch: 31 [8052/10752 (75%)]	 Regressor Loss: -0.683578
Regressor Loss: -0.6836
Domain Loss: 0.0000
Train Epoch: 31 [8172/10752 (76%)]	 Regressor Loss: -0.660349
Regressor Loss: -0.6603
Domain Loss: 0.0000
Train Epoch: 31 [8292/10752 (77%)]	 Regressor Loss: -0.752756
Regressor Loss: -0.7528
Domain Loss: 0.0000
Train Epoch: 31 [8412/10752 (78%)]	 Regressor Loss: -0.309033
Regressor Loss: -0.3090
Domain Loss: 0.0000
Train Epoch: 31 [8532/10752 (79%)]	 Regressor Loss: -0.829489
Regressor Loss: -0.8295
Domain Loss: 0.0000
Train Epoch: 31 [8652/10752 (80%)]	 Regressor Loss: -0.636248
Regressor Loss: -0.6362
Domain Loss: 0.0000
Train Epoch: 31 [8772/10752 (82%)]	 Regressor Loss: -0.865168
Regressor Loss: -0.8652
Domain Loss: 0.0000
Train Epoch: 31 [8892/10752 (83%)]	 Regressor Loss: -0.324976
Regressor Loss: -0.3250
Domain Loss: 0.0000
Train Epoch: 31 [9012/10752 (84%)]	 Regressor Loss: -0.950489
Regressor Loss: -0.9505
Domain Loss: 0.0000
Train Epoch: 31 [9132/10752 (85%)]	 Regressor Loss: -0.350620
Regressor Loss: -0.3506
Domain Loss: 0.0000
Train Epoch: 31 [9252/10752 (86%)]	 Regressor Loss: -1.039573
Regressor Loss: -1.0396
Domain Loss: 0.0000
Train Epoch: 31 [9372/10752 (87%)]	 Regressor Loss: -0.327139
Regressor Loss: -0.3271
Domain Loss: 0.0000
Training set: Average loss: -0.5943
Training set: Average Domain loss: 0.0005
Training set: Average Acc: 0.9998
Validation set: Average loss: -0.5620
Validation set: Average Domain loss: 0.0071
 Validation set: Average Acc: 0.9983
Training Main Encoder
Epoch  32 / 300
Train Epoch: 32 [12/10752 (0%)]	 Regressor Loss: -0.581692
Regressor Loss: -0.5817
Domain Loss: 0.0000
Train Epoch: 32 [132/10752 (1%)]	 Regressor Loss: -0.406598
Regressor Loss: -0.4066
Domain Loss: 0.0002
Train Epoch: 32 [252/10752 (2%)]	 Regressor Loss: -0.943565
Regressor Loss: -0.9436
Domain Loss: 0.0000
Train Epoch: 32 [372/10752 (3%)]	 Regressor Loss: -0.289567
Regressor Loss: -0.2896
Domain Loss: 0.0000
Train Epoch: 32 [492/10752 (5%)]	 Regressor Loss: -0.987824
Regressor Loss: -0.9878
Domain Loss: 0.0000
Train Epoch: 32 [612/10752 (6%)]	 Regressor Loss: -0.365989
Regressor Loss: -0.3660
Domain Loss: 0.0000
Train Epoch: 32 [732/10752 (7%)]	 Regressor Loss: -0.891851
Regressor Loss: -0.8919
Domain Loss: 0.0000
Train Epoch: 32 [852/10752 (8%)]	 Regressor Loss: -0.505788
Regressor Loss: -0.5058
Domain Loss: 0.0000
Train Epoch: 32 [972/10752 (9%)]	 Regressor Loss: -0.444322
Regressor Loss: -0.4443
Domain Loss: 0.0000
Train Epoch: 32 [1092/10752 (10%)]	 Regressor Loss: -0.359050
Regressor Loss: -0.3591
Domain Loss: 0.0000
Train Epoch: 32 [1212/10752 (11%)]	 Regressor Loss: -0.451910
Regressor Loss: -0.4519
Domain Loss: 0.0000
Train Epoch: 32 [1332/10752 (12%)]	 Regressor Loss: -0.586938
Regressor Loss: -0.5869
Domain Loss: 0.0000
Train Epoch: 32 [1452/10752 (14%)]	 Regressor Loss: -0.034316
Regressor Loss: -0.0343
Domain Loss: 0.0000
Train Epoch: 32 [1572/10752 (15%)]	 Regressor Loss: -0.590656
Regressor Loss: -0.5907
Domain Loss: 0.0000
Train Epoch: 32 [1692/10752 (16%)]	 Regressor Loss: -0.445284
Regressor Loss: -0.4453
Domain Loss: 0.0000
Train Epoch: 32 [1812/10752 (17%)]	 Regressor Loss: -0.521339
Regressor Loss: -0.5213
Domain Loss: 0.0002
Train Epoch: 32 [1932/10752 (18%)]	 Regressor Loss: -0.283640
Regressor Loss: -0.2836
Domain Loss: 0.0000
Train Epoch: 32 [2052/10752 (19%)]	 Regressor Loss: -0.985067
Regressor Loss: -0.9851
Domain Loss: 0.0000
Train Epoch: 32 [2172/10752 (20%)]	 Regressor Loss: -0.303172
Regressor Loss: -0.3032
Domain Loss: 0.0000
Train Epoch: 32 [2292/10752 (21%)]	 Regressor Loss: -0.952572
Regressor Loss: -0.9526
Domain Loss: 0.0000
Train Epoch: 32 [2412/10752 (22%)]	 Regressor Loss: -0.355757
Regressor Loss: -0.3558
Domain Loss: 0.0000
Train Epoch: 32 [2532/10752 (24%)]	 Regressor Loss: -0.677168
Regressor Loss: -0.6772
Domain Loss: 0.0000
Train Epoch: 32 [2652/10752 (25%)]	 Regressor Loss: -0.348544
Regressor Loss: -0.3485
Domain Loss: 0.0000
Train Epoch: 32 [2772/10752 (26%)]	 Regressor Loss: -0.948356
Regressor Loss: -0.9484
Domain Loss: 0.0000
Train Epoch: 32 [2892/10752 (27%)]	 Regressor Loss: -0.363972
Regressor Loss: -0.3640
Domain Loss: 0.0000
Train Epoch: 32 [3012/10752 (28%)]	 Regressor Loss: -0.981010
Regressor Loss: -0.9810
Domain Loss: 0.0000
Train Epoch: 32 [3132/10752 (29%)]	 Regressor Loss: -0.539536
Regressor Loss: -0.5395
Domain Loss: 0.0000
Train Epoch: 32 [3252/10752 (30%)]	 Regressor Loss: -1.068196
Regressor Loss: -1.0682
Domain Loss: 0.0000
Train Epoch: 32 [3372/10752 (31%)]	 Regressor Loss: -0.295734
Regressor Loss: -0.2957
Domain Loss: 0.0000
Train Epoch: 32 [3492/10752 (32%)]	 Regressor Loss: -0.917197
Regressor Loss: -0.9172
Domain Loss: 0.0000
Train Epoch: 32 [3612/10752 (34%)]	 Regressor Loss: -0.293605
Regressor Loss: -0.2936
Domain Loss: 0.0000
Train Epoch: 32 [3732/10752 (35%)]	 Regressor Loss: -0.982036
Regressor Loss: -0.9820
Domain Loss: 0.0000
Train Epoch: 32 [3852/10752 (36%)]	 Regressor Loss: -0.525772
Regressor Loss: -0.5258
Domain Loss: 0.0000
Train Epoch: 32 [3972/10752 (37%)]	 Regressor Loss: -0.721056
Regressor Loss: -0.7211
Domain Loss: 0.0000
Train Epoch: 32 [4092/10752 (38%)]	 Regressor Loss: -0.476220
Regressor Loss: -0.4762
Domain Loss: 0.0000
Train Epoch: 32 [4212/10752 (39%)]	 Regressor Loss: -0.713791
Regressor Loss: -0.7138
Domain Loss: 0.0027
Train Epoch: 32 [4332/10752 (40%)]	 Regressor Loss: -0.421908
Regressor Loss: -0.4219
Domain Loss: 0.0000
Train Epoch: 32 [4452/10752 (41%)]	 Regressor Loss: -0.439693
Regressor Loss: -0.4397
Domain Loss: 0.0000
Train Epoch: 32 [4572/10752 (43%)]	 Regressor Loss: -0.403837
Regressor Loss: -0.4038
Domain Loss: 0.0000
Train Epoch: 32 [4692/10752 (44%)]	 Regressor Loss: -0.393561
Regressor Loss: -0.3936
Domain Loss: 0.0000
Train Epoch: 32 [4812/10752 (45%)]	 Regressor Loss: -0.467784
Regressor Loss: -0.4678
Domain Loss: 0.0000
Train Epoch: 32 [4932/10752 (46%)]	 Regressor Loss: -0.434093
Regressor Loss: -0.4341
Domain Loss: 0.0000
Train Epoch: 32 [5052/10752 (47%)]	 Regressor Loss: -0.556485
Regressor Loss: -0.5565
Domain Loss: 0.0000
Train Epoch: 32 [5172/10752 (48%)]	 Regressor Loss: -0.392759
Regressor Loss: -0.3928
Domain Loss: 0.0000
Train Epoch: 32 [5292/10752 (49%)]	 Regressor Loss: -0.765435
Regressor Loss: -0.7654
Domain Loss: 0.0000
Train Epoch: 32 [5412/10752 (50%)]	 Regressor Loss: -0.275616
Regressor Loss: -0.2756
Domain Loss: 0.0000
Train Epoch: 32 [5532/10752 (51%)]	 Regressor Loss: -0.902273
Regressor Loss: -0.9023
Domain Loss: 0.0000
Train Epoch: 32 [5652/10752 (53%)]	 Regressor Loss: -0.524712
Regressor Loss: -0.5247
Domain Loss: 0.0000
Train Epoch: 32 [5772/10752 (54%)]	 Regressor Loss: -0.997419
Regressor Loss: -0.9974
Domain Loss: 0.0000
Train Epoch: 32 [5892/10752 (55%)]	 Regressor Loss: -0.377415
Regressor Loss: -0.3774
Domain Loss: 0.0000
Train Epoch: 32 [6012/10752 (56%)]	 Regressor Loss: -0.930007
Regressor Loss: -0.9300
Domain Loss: 0.0000
Train Epoch: 32 [6132/10752 (57%)]	 Regressor Loss: -0.553629
Regressor Loss: -0.5536
Domain Loss: 0.0000
Train Epoch: 32 [6252/10752 (58%)]	 Regressor Loss: -0.941201
Regressor Loss: -0.9412
Domain Loss: 0.0000
Train Epoch: 32 [6372/10752 (59%)]	 Regressor Loss: -0.498689
Regressor Loss: -0.4987
Domain Loss: 0.0000
Train Epoch: 32 [6492/10752 (60%)]	 Regressor Loss: -0.817288
Regressor Loss: -0.8173
Domain Loss: 0.0000
Train Epoch: 32 [6612/10752 (61%)]	 Regressor Loss: -0.385566
Regressor Loss: -0.3856
Domain Loss: 0.0000
Train Epoch: 32 [6732/10752 (63%)]	 Regressor Loss: -0.879362
Regressor Loss: -0.8794
Domain Loss: 0.0000
Train Epoch: 32 [6852/10752 (64%)]	 Regressor Loss: -0.465706
Regressor Loss: -0.4657
Domain Loss: 0.0000
Train Epoch: 32 [6972/10752 (65%)]	 Regressor Loss: -1.065034
Regressor Loss: -1.0650
Domain Loss: 0.0000
Train Epoch: 32 [7092/10752 (66%)]	 Regressor Loss: -0.552146
Regressor Loss: -0.5521
Domain Loss: 0.0000
Train Epoch: 32 [7212/10752 (67%)]	 Regressor Loss: -0.905575
Regressor Loss: -0.9056
Domain Loss: 0.0000
Train Epoch: 32 [7332/10752 (68%)]	 Regressor Loss: -0.350102
Regressor Loss: -0.3501
Domain Loss: 0.0000
Train Epoch: 32 [7452/10752 (69%)]	 Regressor Loss: -0.769489
Regressor Loss: -0.7695
Domain Loss: 0.0000
Train Epoch: 32 [7572/10752 (70%)]	 Regressor Loss: -0.031375
Regressor Loss: -0.0314
Domain Loss: 0.0000
Train Epoch: 32 [7692/10752 (72%)]	 Regressor Loss: -0.588855
Regressor Loss: -0.5889
Domain Loss: 0.0000
Train Epoch: 32 [7812/10752 (73%)]	 Regressor Loss: -0.513620
Regressor Loss: -0.5136
Domain Loss: 0.0000
Train Epoch: 32 [7932/10752 (74%)]	 Regressor Loss: -0.579302
Regressor Loss: -0.5793
Domain Loss: 0.0000
Train Epoch: 32 [8052/10752 (75%)]	 Regressor Loss: -0.565902
Regressor Loss: -0.5659
Domain Loss: 0.0000
Train Epoch: 32 [8172/10752 (76%)]	 Regressor Loss: -0.367381
Regressor Loss: -0.3674
Domain Loss: 0.0000
Train Epoch: 32 [8292/10752 (77%)]	 Regressor Loss: -0.732164
Regressor Loss: -0.7322
Domain Loss: 0.0000
Train Epoch: 32 [8412/10752 (78%)]	 Regressor Loss: -0.225427
Regressor Loss: -0.2254
Domain Loss: 0.0000
Train Epoch: 32 [8532/10752 (79%)]	 Regressor Loss: -0.802711
Regressor Loss: -0.8027
Domain Loss: 0.0000
Train Epoch: 32 [8652/10752 (80%)]	 Regressor Loss: -0.698932
Regressor Loss: -0.6989
Domain Loss: 0.0000
Train Epoch: 32 [8772/10752 (82%)]	 Regressor Loss: -0.858015
Regressor Loss: -0.8580
Domain Loss: 0.0000
Train Epoch: 32 [8892/10752 (83%)]	 Regressor Loss: -0.263380
Regressor Loss: -0.2634
Domain Loss: 0.0000
Train Epoch: 32 [9012/10752 (84%)]	 Regressor Loss: -0.982751
Regressor Loss: -0.9828
Domain Loss: 0.0000
Train Epoch: 32 [9132/10752 (85%)]	 Regressor Loss: -0.342001
Regressor Loss: -0.3420
Domain Loss: 0.0000
Train Epoch: 32 [9252/10752 (86%)]	 Regressor Loss: -0.895756
Regressor Loss: -0.8958
Domain Loss: 0.0000
Train Epoch: 32 [9372/10752 (87%)]	 Regressor Loss: -0.246207
Regressor Loss: -0.2462
Domain Loss: 0.0000
Training set: Average loss: -0.6007
Training set: Average Domain loss: 0.0002
Training set: Average Acc: 0.9999
Validation set: Average loss: -0.5705
Validation set: Average Domain loss: 0.0081
 Validation set: Average Acc: 0.9967
Training Main Encoder
Epoch  33 / 300
Train Epoch: 33 [12/10752 (0%)]	 Regressor Loss: -0.549016
Regressor Loss: -0.5490
Domain Loss: 0.0000
Train Epoch: 33 [132/10752 (1%)]	 Regressor Loss: -0.521399
Regressor Loss: -0.5214
Domain Loss: 0.0000
Train Epoch: 33 [252/10752 (2%)]	 Regressor Loss: -0.964946
Regressor Loss: -0.9649
Domain Loss: 0.0000
Train Epoch: 33 [372/10752 (3%)]	 Regressor Loss: -0.362404
Regressor Loss: -0.3624
Domain Loss: 0.0000
Train Epoch: 33 [492/10752 (5%)]	 Regressor Loss: -0.843049
Regressor Loss: -0.8430
Domain Loss: 0.0000
Train Epoch: 33 [612/10752 (6%)]	 Regressor Loss: -0.458432
Regressor Loss: -0.4584
Domain Loss: 0.0000
Train Epoch: 33 [732/10752 (7%)]	 Regressor Loss: -1.151779
Regressor Loss: -1.1518
Domain Loss: 0.0000
Train Epoch: 33 [852/10752 (8%)]	 Regressor Loss: -0.397884
Regressor Loss: -0.3979
Domain Loss: 0.0000
Train Epoch: 33 [972/10752 (9%)]	 Regressor Loss: -0.695706
Regressor Loss: -0.6957
Domain Loss: 0.0000
Train Epoch: 33 [1092/10752 (10%)]	 Regressor Loss: -0.411548
Regressor Loss: -0.4115
Domain Loss: 0.0000
Train Epoch: 33 [1212/10752 (11%)]	 Regressor Loss: -0.438643
Regressor Loss: -0.4386
Domain Loss: 0.0000
Train Epoch: 33 [1332/10752 (12%)]	 Regressor Loss: -0.385151
Regressor Loss: -0.3852
Domain Loss: 0.0000
Train Epoch: 33 [1452/10752 (14%)]	 Regressor Loss: -0.572902
Regressor Loss: -0.5729
Domain Loss: 0.0000
Train Epoch: 33 [1572/10752 (15%)]	 Regressor Loss: -0.526687
Regressor Loss: -0.5267
Domain Loss: 0.0000
Train Epoch: 33 [1692/10752 (16%)]	 Regressor Loss: -0.109355
Regressor Loss: -0.1094
Domain Loss: 0.0000
Train Epoch: 33 [1812/10752 (17%)]	 Regressor Loss: -0.258211
Regressor Loss: -0.2582
Domain Loss: 0.0000
Train Epoch: 33 [1932/10752 (18%)]	 Regressor Loss: -0.447001
Regressor Loss: -0.4470
Domain Loss: 0.0000
Train Epoch: 33 [2052/10752 (19%)]	 Regressor Loss: -0.736666
Regressor Loss: -0.7367
Domain Loss: 0.0000
Train Epoch: 33 [2172/10752 (20%)]	 Regressor Loss: -0.404191
Regressor Loss: -0.4042
Domain Loss: 0.0000
Train Epoch: 33 [2292/10752 (21%)]	 Regressor Loss: -0.976587
Regressor Loss: -0.9766
Domain Loss: 0.0000
Train Epoch: 33 [2412/10752 (22%)]	 Regressor Loss: -0.407904
Regressor Loss: -0.4079
Domain Loss: 0.0000
Train Epoch: 33 [2532/10752 (24%)]	 Regressor Loss: -0.975292
Regressor Loss: -0.9753
Domain Loss: 0.0000
Train Epoch: 33 [2652/10752 (25%)]	 Regressor Loss: -0.475739
Regressor Loss: -0.4757
Domain Loss: 0.0000
Train Epoch: 33 [2772/10752 (26%)]	 Regressor Loss: -0.884340
Regressor Loss: -0.8843
Domain Loss: 0.0000
Train Epoch: 33 [2892/10752 (27%)]	 Regressor Loss: -0.481822
Regressor Loss: -0.4818
Domain Loss: 0.0000
Train Epoch: 33 [3012/10752 (28%)]	 Regressor Loss: -0.971386
Regressor Loss: -0.9714
Domain Loss: 0.0001
Train Epoch: 33 [3132/10752 (29%)]	 Regressor Loss: -0.747472
Regressor Loss: -0.7475
Domain Loss: 0.0000
Train Epoch: 33 [3252/10752 (30%)]	 Regressor Loss: -0.866067
Regressor Loss: -0.8661
Domain Loss: 0.0000
Train Epoch: 33 [3372/10752 (31%)]	 Regressor Loss: -0.368852
Regressor Loss: -0.3689
Domain Loss: 0.0000
Train Epoch: 33 [3492/10752 (32%)]	 Regressor Loss: -1.071453
Regressor Loss: -1.0715
Domain Loss: 0.0001
Train Epoch: 33 [3612/10752 (34%)]	 Regressor Loss: -0.258621
Regressor Loss: -0.2586
Domain Loss: 0.0000
Train Epoch: 33 [3732/10752 (35%)]	 Regressor Loss: -1.012074
Regressor Loss: -1.0121
Domain Loss: 0.0000
Train Epoch: 33 [3852/10752 (36%)]	 Regressor Loss: -0.583607
Regressor Loss: -0.5836
Domain Loss: 0.0000
Train Epoch: 33 [3972/10752 (37%)]	 Regressor Loss: -1.072825
Regressor Loss: -1.0728
Domain Loss: 0.0001
Train Epoch: 33 [4092/10752 (38%)]	 Regressor Loss: -0.433985
Regressor Loss: -0.4340
Domain Loss: 0.0000
Train Epoch: 33 [4212/10752 (39%)]	 Regressor Loss: -0.732135
Regressor Loss: -0.7321
Domain Loss: 0.0000
Train Epoch: 33 [4332/10752 (40%)]	 Regressor Loss: -0.334674
Regressor Loss: -0.3347
Domain Loss: 0.0000
Train Epoch: 33 [4452/10752 (41%)]	 Regressor Loss: -0.485972
Regressor Loss: -0.4860
Domain Loss: 0.0000
Train Epoch: 33 [4572/10752 (43%)]	 Regressor Loss: -0.504806
Regressor Loss: -0.5048
Domain Loss: 0.0000
Train Epoch: 33 [4692/10752 (44%)]	 Regressor Loss: -0.196319
Regressor Loss: -0.1963
Domain Loss: 0.0000
Train Epoch: 33 [4812/10752 (45%)]	 Regressor Loss: -0.137954
Regressor Loss: -0.1380
Domain Loss: 0.0000
Train Epoch: 33 [4932/10752 (46%)]	 Regressor Loss: -0.471615
Regressor Loss: -0.4716
Domain Loss: 0.0000
Train Epoch: 33 [5052/10752 (47%)]	 Regressor Loss: -0.619173
Regressor Loss: -0.6192
Domain Loss: 0.0000
Train Epoch: 33 [5172/10752 (48%)]	 Regressor Loss: -0.459725
Regressor Loss: -0.4597
Domain Loss: 0.0000
Train Epoch: 33 [5292/10752 (49%)]	 Regressor Loss: -0.968612
Regressor Loss: -0.9686
Domain Loss: 0.0000
Train Epoch: 33 [5412/10752 (50%)]	 Regressor Loss: -0.384749
Regressor Loss: -0.3847
Domain Loss: 0.0000
Train Epoch: 33 [5532/10752 (51%)]	 Regressor Loss: -1.027912
Regressor Loss: -1.0279
Domain Loss: 0.0005
Train Epoch: 33 [5652/10752 (53%)]	 Regressor Loss: -0.496048
Regressor Loss: -0.4960
Domain Loss: 0.0000
Train Epoch: 33 [5772/10752 (54%)]	 Regressor Loss: -0.942036
Regressor Loss: -0.9420
Domain Loss: 0.0001
Train Epoch: 33 [5892/10752 (55%)]	 Regressor Loss: -0.295356
Regressor Loss: -0.2954
Domain Loss: 0.0000
Train Epoch: 33 [6012/10752 (56%)]	 Regressor Loss: -0.800543
Regressor Loss: -0.8005
Domain Loss: 0.0000
Train Epoch: 33 [6132/10752 (57%)]	 Regressor Loss: -0.798757
Regressor Loss: -0.7988
Domain Loss: 0.0000
Train Epoch: 33 [6252/10752 (58%)]	 Regressor Loss: -0.965691
Regressor Loss: -0.9657
Domain Loss: 0.0000
Train Epoch: 33 [6372/10752 (59%)]	 Regressor Loss: -0.466950
Regressor Loss: -0.4669
Domain Loss: 0.0001
Train Epoch: 33 [6492/10752 (60%)]	 Regressor Loss: -0.948801
Regressor Loss: -0.9488
Domain Loss: 0.0000
Train Epoch: 33 [6612/10752 (61%)]	 Regressor Loss: -0.535193
Regressor Loss: -0.5352
Domain Loss: 0.0000
Train Epoch: 33 [6732/10752 (63%)]	 Regressor Loss: -1.070569
Regressor Loss: -1.0706
Domain Loss: 0.0000
Train Epoch: 33 [6852/10752 (64%)]	 Regressor Loss: -0.609894
Regressor Loss: -0.6099
Domain Loss: 0.0000
Train Epoch: 33 [6972/10752 (65%)]	 Regressor Loss: -0.911713
Regressor Loss: -0.9117
Domain Loss: 0.0000
Train Epoch: 33 [7092/10752 (66%)]	 Regressor Loss: -0.188522
Regressor Loss: -0.1885
Domain Loss: 0.0000
Train Epoch: 33 [7212/10752 (67%)]	 Regressor Loss: -0.962880
Regressor Loss: -0.9629
Domain Loss: 0.0000
Train Epoch: 33 [7332/10752 (68%)]	 Regressor Loss: -0.482515
Regressor Loss: -0.4825
Domain Loss: 0.0000
Train Epoch: 33 [7452/10752 (69%)]	 Regressor Loss: -0.880371
Regressor Loss: -0.8804
Domain Loss: 0.0000
Train Epoch: 33 [7572/10752 (70%)]	 Regressor Loss: -0.314904
Regressor Loss: -0.3149
Domain Loss: 0.0000
Train Epoch: 33 [7692/10752 (72%)]	 Regressor Loss: -0.267454
Regressor Loss: -0.2675
Domain Loss: 0.0000
Train Epoch: 33 [7812/10752 (73%)]	 Regressor Loss: -0.504800
Regressor Loss: -0.5048
Domain Loss: 0.0000
Train Epoch: 33 [7932/10752 (74%)]	 Regressor Loss: -0.762736
Regressor Loss: -0.7627
Domain Loss: 0.0000
Train Epoch: 33 [8052/10752 (75%)]	 Regressor Loss: -0.751008
Regressor Loss: -0.7510
Domain Loss: 0.0000
Train Epoch: 33 [8172/10752 (76%)]	 Regressor Loss: -0.722801
Regressor Loss: -0.7228
Domain Loss: 0.0000
Train Epoch: 33 [8292/10752 (77%)]	 Regressor Loss: -0.722336
Regressor Loss: -0.7223
Domain Loss: 0.0000
Train Epoch: 33 [8412/10752 (78%)]	 Regressor Loss: -0.330224
Regressor Loss: -0.3302
Domain Loss: 0.0000
Train Epoch: 33 [8532/10752 (79%)]	 Regressor Loss: -0.856891
Regressor Loss: -0.8569
Domain Loss: 0.0000
Train Epoch: 33 [8652/10752 (80%)]	 Regressor Loss: -0.708331
Regressor Loss: -0.7083
Domain Loss: 0.0000
Train Epoch: 33 [8772/10752 (82%)]	 Regressor Loss: -0.896359
Regressor Loss: -0.8964
Domain Loss: 0.0000
Train Epoch: 33 [8892/10752 (83%)]	 Regressor Loss: -0.418124
Regressor Loss: -0.4181
Domain Loss: 0.0000
Train Epoch: 33 [9012/10752 (84%)]	 Regressor Loss: -1.104071
Regressor Loss: -1.1041
Domain Loss: 0.0002
Train Epoch: 33 [9132/10752 (85%)]	 Regressor Loss: -0.375186
Regressor Loss: -0.3752
Domain Loss: 0.0000
Train Epoch: 33 [9252/10752 (86%)]	 Regressor Loss: -1.056774
Regressor Loss: -1.0568
Domain Loss: 0.0634
Train Epoch: 33 [9372/10752 (87%)]	 Regressor Loss: -0.116421
Regressor Loss: -0.1164
Domain Loss: 0.0000
Training set: Average loss: -0.6306
Training set: Average Domain loss: 0.0047
Training set: Average Acc: 0.9988
Validation set: Average loss: -0.5830
Validation set: Average Domain loss: 0.1729
 Validation set: Average Acc: 0.9750
Training Main Encoder
Epoch  34 / 300
Train Epoch: 34 [12/10752 (0%)]	 Regressor Loss: -0.789902
Regressor Loss: -0.7899
Domain Loss: 0.0000
Train Epoch: 34 [132/10752 (1%)]	 Regressor Loss: -0.625307
Regressor Loss: -0.6253
Domain Loss: 0.0007
Train Epoch: 34 [252/10752 (2%)]	 Regressor Loss: -1.098393
Regressor Loss: -1.0984
Domain Loss: 0.0037
Train Epoch: 34 [372/10752 (3%)]	 Regressor Loss: -0.390289
Regressor Loss: -0.3903
Domain Loss: 0.0000
Train Epoch: 34 [492/10752 (5%)]	 Regressor Loss: -1.011411
Regressor Loss: -1.0114
Domain Loss: 0.0000
Train Epoch: 34 [612/10752 (6%)]	 Regressor Loss: -0.347405
Regressor Loss: -0.3474
Domain Loss: 0.0000
Train Epoch: 34 [732/10752 (7%)]	 Regressor Loss: -1.173806
Regressor Loss: -1.1738
Domain Loss: 0.0000
Train Epoch: 34 [852/10752 (8%)]	 Regressor Loss: -0.751670
Regressor Loss: -0.7517
Domain Loss: 0.0728
Train Epoch: 34 [972/10752 (9%)]	 Regressor Loss: -0.720670
Regressor Loss: -0.7207
Domain Loss: 0.0000
Train Epoch: 34 [1092/10752 (10%)]	 Regressor Loss: -0.206560
Regressor Loss: -0.2066
Domain Loss: 0.0000
Train Epoch: 34 [1212/10752 (11%)]	 Regressor Loss: -0.500737
Regressor Loss: -0.5007
Domain Loss: 0.0000
Train Epoch: 34 [1332/10752 (12%)]	 Regressor Loss: -0.586095
Regressor Loss: -0.5861
Domain Loss: 0.0000
Train Epoch: 34 [1452/10752 (14%)]	 Regressor Loss: -0.508202
Regressor Loss: -0.5082
Domain Loss: 0.0000
Train Epoch: 34 [1572/10752 (15%)]	 Regressor Loss: -0.617442
Regressor Loss: -0.6174
Domain Loss: 0.0000
Train Epoch: 34 [1692/10752 (16%)]	 Regressor Loss: -0.276929
Regressor Loss: -0.2769
Domain Loss: 0.0000
Train Epoch: 34 [1812/10752 (17%)]	 Regressor Loss: -0.178443
Regressor Loss: -0.1784
Domain Loss: 0.0000
Train Epoch: 34 [1932/10752 (18%)]	 Regressor Loss: -0.396716
Regressor Loss: -0.3967
Domain Loss: 0.0000
Train Epoch: 34 [2052/10752 (19%)]	 Regressor Loss: -0.878336
Regressor Loss: -0.8783
Domain Loss: 0.0000
Train Epoch: 34 [2172/10752 (20%)]	 Regressor Loss: -0.359377
Regressor Loss: -0.3594
Domain Loss: 0.0000
Train Epoch: 34 [2292/10752 (21%)]	 Regressor Loss: -0.907186
Regressor Loss: -0.9072
Domain Loss: 0.0000
Train Epoch: 34 [2412/10752 (22%)]	 Regressor Loss: -0.317548
Regressor Loss: -0.3175
Domain Loss: 0.0000
Train Epoch: 34 [2532/10752 (24%)]	 Regressor Loss: -0.816320
Regressor Loss: -0.8163
Domain Loss: 0.0000
Train Epoch: 34 [2652/10752 (25%)]	 Regressor Loss: -0.367817
Regressor Loss: -0.3678
Domain Loss: 0.0002
Train Epoch: 34 [2772/10752 (26%)]	 Regressor Loss: -0.944942
Regressor Loss: -0.9449
Domain Loss: 0.0006
Train Epoch: 34 [2892/10752 (27%)]	 Regressor Loss: -0.490920
Regressor Loss: -0.4909
Domain Loss: 0.0000
Train Epoch: 34 [3012/10752 (28%)]	 Regressor Loss: -0.945632
Regressor Loss: -0.9456
Domain Loss: 0.0000
Train Epoch: 34 [3132/10752 (29%)]	 Regressor Loss: -0.863824
Regressor Loss: -0.8638
Domain Loss: 0.0000
Train Epoch: 34 [3252/10752 (30%)]	 Regressor Loss: -0.865409
Regressor Loss: -0.8654
Domain Loss: 0.0000
Train Epoch: 34 [3372/10752 (31%)]	 Regressor Loss: -0.373424
Regressor Loss: -0.3734
Domain Loss: 0.0000
Train Epoch: 34 [3492/10752 (32%)]	 Regressor Loss: -1.047719
Regressor Loss: -1.0477
Domain Loss: 0.0000
Train Epoch: 34 [3612/10752 (34%)]	 Regressor Loss: -0.377955
Regressor Loss: -0.3780
Domain Loss: 0.0000
Train Epoch: 34 [3732/10752 (35%)]	 Regressor Loss: -0.946081
Regressor Loss: -0.9461
Domain Loss: 0.0000
Train Epoch: 34 [3852/10752 (36%)]	 Regressor Loss: -0.458380
Regressor Loss: -0.4584
Domain Loss: 0.0000
Train Epoch: 34 [3972/10752 (37%)]	 Regressor Loss: -0.968585
Regressor Loss: -0.9686
Domain Loss: 0.0002
Train Epoch: 34 [4092/10752 (38%)]	 Regressor Loss: -0.302731
Regressor Loss: -0.3027
Domain Loss: 0.0000
Train Epoch: 34 [4212/10752 (39%)]	 Regressor Loss: -0.731493
Regressor Loss: -0.7315
Domain Loss: 0.0000
Train Epoch: 34 [4332/10752 (40%)]	 Regressor Loss: -0.453821
Regressor Loss: -0.4538
Domain Loss: 0.0000
Train Epoch: 34 [4452/10752 (41%)]	 Regressor Loss: -0.407269
Regressor Loss: -0.4073
Domain Loss: 0.0000
Train Epoch: 34 [4572/10752 (43%)]	 Regressor Loss: -0.448760
Regressor Loss: -0.4488
Domain Loss: 0.0000
Train Epoch: 34 [4692/10752 (44%)]	 Regressor Loss: -0.533444
Regressor Loss: -0.5334
Domain Loss: 0.0001
Train Epoch: 34 [4812/10752 (45%)]	 Regressor Loss: -0.553476
Regressor Loss: -0.5535
Domain Loss: 0.0000
Train Epoch: 34 [4932/10752 (46%)]	 Regressor Loss: -0.255580
Regressor Loss: -0.2556
Domain Loss: 0.0000
Train Epoch: 34 [5052/10752 (47%)]	 Regressor Loss: -0.564140
Regressor Loss: -0.5641
Domain Loss: 0.0000
Train Epoch: 34 [5172/10752 (48%)]	 Regressor Loss: -0.451796
Regressor Loss: -0.4518
Domain Loss: 0.0000
Train Epoch: 34 [5292/10752 (49%)]	 Regressor Loss: -0.942254
Regressor Loss: -0.9423
Domain Loss: 0.0000
Train Epoch: 34 [5412/10752 (50%)]	 Regressor Loss: -0.479849
Regressor Loss: -0.4798
Domain Loss: 0.0000
Train Epoch: 34 [5532/10752 (51%)]	 Regressor Loss: -1.072439
Regressor Loss: -1.0724
Domain Loss: 0.0000
Train Epoch: 34 [5652/10752 (53%)]	 Regressor Loss: -0.820130
Regressor Loss: -0.8201
Domain Loss: 0.0004
Train Epoch: 34 [5772/10752 (54%)]	 Regressor Loss: -1.066258
Regressor Loss: -1.0663
Domain Loss: 0.0000
Train Epoch: 34 [5892/10752 (55%)]	 Regressor Loss: -0.607032
Regressor Loss: -0.6070
Domain Loss: 0.0000
Train Epoch: 34 [6012/10752 (56%)]	 Regressor Loss: -1.100199
Regressor Loss: -1.1002
Domain Loss: 0.0000
Train Epoch: 34 [6132/10752 (57%)]	 Regressor Loss: -0.648205
Regressor Loss: -0.6482
Domain Loss: 0.0000
Train Epoch: 34 [6252/10752 (58%)]	 Regressor Loss: -1.090199
Regressor Loss: -1.0902
Domain Loss: 0.0275
Train Epoch: 34 [6372/10752 (59%)]	 Regressor Loss: -0.135656
Regressor Loss: -0.1357
Domain Loss: 0.0000
Train Epoch: 34 [6492/10752 (60%)]	 Regressor Loss: -0.954679
Regressor Loss: -0.9547
Domain Loss: 0.0000
Train Epoch: 34 [6612/10752 (61%)]	 Regressor Loss: -0.566730
Regressor Loss: -0.5667
Domain Loss: 0.0000
Train Epoch: 34 [6732/10752 (63%)]	 Regressor Loss: -1.043421
Regressor Loss: -1.0434
Domain Loss: 0.0000
Train Epoch: 34 [6852/10752 (64%)]	 Regressor Loss: -0.472571
Regressor Loss: -0.4726
Domain Loss: 0.0000
Train Epoch: 34 [6972/10752 (65%)]	 Regressor Loss: -0.800667
Regressor Loss: -0.8007
Domain Loss: 0.0000
Train Epoch: 34 [7092/10752 (66%)]	 Regressor Loss: -0.012096
Regressor Loss: -0.0121
Domain Loss: 0.0004
Train Epoch: 34 [7212/10752 (67%)]	 Regressor Loss: -0.865872
Regressor Loss: -0.8659
Domain Loss: 0.0000
Train Epoch: 34 [7332/10752 (68%)]	 Regressor Loss: -0.426357
Regressor Loss: -0.4264
Domain Loss: 0.0000
Train Epoch: 34 [7452/10752 (69%)]	 Regressor Loss: -0.898998
Regressor Loss: -0.8990
Domain Loss: 0.0000
Train Epoch: 34 [7572/10752 (70%)]	 Regressor Loss: -0.449342
Regressor Loss: -0.4493
Domain Loss: 0.0000
Train Epoch: 34 [7692/10752 (72%)]	 Regressor Loss: -0.725044
Regressor Loss: -0.7250
Domain Loss: 0.0000
Train Epoch: 34 [7812/10752 (73%)]	 Regressor Loss: -0.427001
Regressor Loss: -0.4270
Domain Loss: 0.0000
Train Epoch: 34 [7932/10752 (74%)]	 Regressor Loss: -0.573534
Regressor Loss: -0.5735
Domain Loss: 0.0000
Train Epoch: 34 [8052/10752 (75%)]	 Regressor Loss: -0.708166
Regressor Loss: -0.7082
Domain Loss: 0.0000
Train Epoch: 34 [8172/10752 (76%)]	 Regressor Loss: -0.505334
Regressor Loss: -0.5053
Domain Loss: 0.0000
Train Epoch: 34 [8292/10752 (77%)]	 Regressor Loss: -0.758916
Regressor Loss: -0.7589
Domain Loss: 0.0000
Train Epoch: 34 [8412/10752 (78%)]	 Regressor Loss: -0.322449
Regressor Loss: -0.3224
Domain Loss: 0.0000
Train Epoch: 34 [8532/10752 (79%)]	 Regressor Loss: -0.791759
Regressor Loss: -0.7918
Domain Loss: 0.0000
Train Epoch: 34 [8652/10752 (80%)]	 Regressor Loss: -0.766925
Regressor Loss: -0.7669
Domain Loss: 0.0000
Train Epoch: 34 [8772/10752 (82%)]	 Regressor Loss: -0.900597
Regressor Loss: -0.9006
Domain Loss: 0.0001
Train Epoch: 34 [8892/10752 (83%)]	 Regressor Loss: -0.470672
Regressor Loss: -0.4707
Domain Loss: 0.0000
Train Epoch: 34 [9012/10752 (84%)]	 Regressor Loss: -1.027103
Regressor Loss: -1.0271
Domain Loss: 0.0002
Train Epoch: 34 [9132/10752 (85%)]	 Regressor Loss: -0.480700
Regressor Loss: -0.4807
Domain Loss: 0.0000
Train Epoch: 34 [9252/10752 (86%)]	 Regressor Loss: -1.172627
Regressor Loss: -1.1726
Domain Loss: 0.0001
Train Epoch: 34 [9372/10752 (87%)]	 Regressor Loss: -0.000000
Regressor Loss: -0.0000
Domain Loss: 0.0000
Training set: Average loss: -0.6242
Training set: Average Domain loss: 0.0117
Training set: Average Acc: 0.9989
Validation set: Average loss: -0.5668
Validation set: Average Domain loss: 0.0003
 Validation set: Average Acc: 1.0000
Training Main Encoder
Epoch  35 / 300
Train Epoch: 35 [12/10752 (0%)]	 Regressor Loss: -0.713070
Regressor Loss: -0.7131
Domain Loss: 0.0000
Train Epoch: 35 [132/10752 (1%)]	 Regressor Loss: -0.466754
Regressor Loss: -0.4668
Domain Loss: 0.0001
Train Epoch: 35 [252/10752 (2%)]	 Regressor Loss: -1.111083
Regressor Loss: -1.1111
Domain Loss: 0.0000
Train Epoch: 35 [372/10752 (3%)]	 Regressor Loss: -0.363521
Regressor Loss: -0.3635
Domain Loss: 0.0000
Train Epoch: 35 [492/10752 (5%)]	 Regressor Loss: -0.910810
Regressor Loss: -0.9108
Domain Loss: 0.0000
Train Epoch: 35 [612/10752 (6%)]	 Regressor Loss: -0.650943
Regressor Loss: -0.6509
Domain Loss: 0.0000
Train Epoch: 35 [732/10752 (7%)]	 Regressor Loss: -0.968917
Regressor Loss: -0.9689
Domain Loss: 0.0000
Train Epoch: 35 [852/10752 (8%)]	 Regressor Loss: -0.661550
Regressor Loss: -0.6616
Domain Loss: 0.0000
Train Epoch: 35 [972/10752 (9%)]	 Regressor Loss: -0.654831
Regressor Loss: -0.6548
Domain Loss: 0.0000
Train Epoch: 35 [1092/10752 (10%)]	 Regressor Loss: -0.464185
Regressor Loss: -0.4642
Domain Loss: 0.0000
Train Epoch: 35 [1212/10752 (11%)]	 Regressor Loss: -0.612803
Regressor Loss: -0.6128
Domain Loss: 0.0000
Train Epoch: 35 [1332/10752 (12%)]	 Regressor Loss: -0.406739
Regressor Loss: -0.4067
Domain Loss: 0.0000
Train Epoch: 35 [1452/10752 (14%)]	 Regressor Loss: -0.500774
Regressor Loss: -0.5008
Domain Loss: 0.0000
Train Epoch: 35 [1572/10752 (15%)]	 Regressor Loss: -0.438949
Regressor Loss: -0.4389
Domain Loss: 0.0000
Train Epoch: 35 [1692/10752 (16%)]	 Regressor Loss: -0.314751
Regressor Loss: -0.3148
Domain Loss: 0.0000
Train Epoch: 35 [1812/10752 (17%)]	 Regressor Loss: -0.617822
Regressor Loss: -0.6178
Domain Loss: 0.0000
Train Epoch: 35 [1932/10752 (18%)]	 Regressor Loss: -0.425345
Regressor Loss: -0.4253
Domain Loss: 0.0002
Train Epoch: 35 [2052/10752 (19%)]	 Regressor Loss: -0.921839
Regressor Loss: -0.9218
Domain Loss: 0.0000
Train Epoch: 35 [2172/10752 (20%)]	 Regressor Loss: -0.445196
Regressor Loss: -0.4452
Domain Loss: 0.0000
Train Epoch: 35 [2292/10752 (21%)]	 Regressor Loss: -0.900937
Regressor Loss: -0.9009
Domain Loss: 0.0000
Train Epoch: 35 [2412/10752 (22%)]	 Regressor Loss: -0.319322
Regressor Loss: -0.3193
Domain Loss: 0.0000
Train Epoch: 35 [2532/10752 (24%)]	 Regressor Loss: -1.130493
Regressor Loss: -1.1305
Domain Loss: 0.0000
Train Epoch: 35 [2652/10752 (25%)]	 Regressor Loss: -0.492344
Regressor Loss: -0.4923
Domain Loss: 0.0000
Train Epoch: 35 [2772/10752 (26%)]	 Regressor Loss: -1.043664
Regressor Loss: -1.0437
Domain Loss: 0.0000
Train Epoch: 35 [2892/10752 (27%)]	 Regressor Loss: -0.286060
Regressor Loss: -0.2861
Domain Loss: 0.0000
Train Epoch: 35 [3012/10752 (28%)]	 Regressor Loss: -0.950133
Regressor Loss: -0.9501
Domain Loss: 0.0000
Train Epoch: 35 [3132/10752 (29%)]	 Regressor Loss: -0.670831
Regressor Loss: -0.6708
Domain Loss: 0.0000
Train Epoch: 35 [3252/10752 (30%)]	 Regressor Loss: -0.998772
Regressor Loss: -0.9988
Domain Loss: 0.0000
Train Epoch: 35 [3372/10752 (31%)]	 Regressor Loss: -0.394516
Regressor Loss: -0.3945
Domain Loss: 0.0000
Train Epoch: 35 [3492/10752 (32%)]	 Regressor Loss: -0.631635
Regressor Loss: -0.6316
Domain Loss: 0.0000
Train Epoch: 35 [3612/10752 (34%)]	 Regressor Loss: -0.436686
Regressor Loss: -0.4367
Domain Loss: 0.0000
Train Epoch: 35 [3732/10752 (35%)]	 Regressor Loss: -1.087796
Regressor Loss: -1.0878
Domain Loss: 0.0000
Train Epoch: 35 [3852/10752 (36%)]	 Regressor Loss: -0.291823
Regressor Loss: -0.2918
Domain Loss: 0.0000
Train Epoch: 35 [3972/10752 (37%)]	 Regressor Loss: -1.029218
Regressor Loss: -1.0292
Domain Loss: 0.0000
Train Epoch: 35 [4092/10752 (38%)]	 Regressor Loss: -0.391510
Regressor Loss: -0.3915
Domain Loss: 0.0000
Train Epoch: 35 [4212/10752 (39%)]	 Regressor Loss: -0.722379
Regressor Loss: -0.7224
Domain Loss: 0.0000
Train Epoch: 35 [4332/10752 (40%)]	 Regressor Loss: -0.382106
Regressor Loss: -0.3821
Domain Loss: 0.0000
Train Epoch: 35 [4452/10752 (41%)]	 Regressor Loss: -0.360536
Regressor Loss: -0.3605
Domain Loss: 0.0000
Train Epoch: 35 [4572/10752 (43%)]	 Regressor Loss: -0.422899
Regressor Loss: -0.4229
Domain Loss: 0.0000
Train Epoch: 35 [4692/10752 (44%)]	 Regressor Loss: -0.220875
Regressor Loss: -0.2209
Domain Loss: 0.0000
Train Epoch: 35 [4812/10752 (45%)]	 Regressor Loss: -0.501373
Regressor Loss: -0.5014
Domain Loss: 0.0050
Train Epoch: 35 [4932/10752 (46%)]	 Regressor Loss: -0.374702
Regressor Loss: -0.3747
Domain Loss: 0.0000
Train Epoch: 35 [5052/10752 (47%)]	 Regressor Loss: -0.513309
Regressor Loss: -0.5133
Domain Loss: 0.0000
Train Epoch: 35 [5172/10752 (48%)]	 Regressor Loss: -0.369836
Regressor Loss: -0.3698
Domain Loss: 0.0000
Train Epoch: 35 [5292/10752 (49%)]	 Regressor Loss: -0.411977
Regressor Loss: -0.4120
Domain Loss: 0.0000
Train Epoch: 35 [5412/10752 (50%)]	 Regressor Loss: -0.382154
Regressor Loss: -0.3822
Domain Loss: 0.0000
Train Epoch: 35 [5532/10752 (51%)]	 Regressor Loss: -0.567726
Regressor Loss: -0.5677
Domain Loss: 0.0000
Train Epoch: 35 [5652/10752 (53%)]	 Regressor Loss: -0.540423
Regressor Loss: -0.5404
Domain Loss: 0.0000
Train Epoch: 35 [5772/10752 (54%)]	 Regressor Loss: -0.781193
Regressor Loss: -0.7812
Domain Loss: 0.0000
Train Epoch: 35 [5892/10752 (55%)]	 Regressor Loss: -0.433342
Regressor Loss: -0.4333
Domain Loss: 0.0000
Train Epoch: 35 [6012/10752 (56%)]	 Regressor Loss: -0.635183
Regressor Loss: -0.6352
Domain Loss: 0.0000
Train Epoch: 35 [6132/10752 (57%)]	 Regressor Loss: -1.041274
Regressor Loss: -1.0413
Domain Loss: 0.0000
Train Epoch: 35 [6252/10752 (58%)]	 Regressor Loss: -1.100285
Regressor Loss: -1.1003
Domain Loss: 0.0000
Train Epoch: 35 [6372/10752 (59%)]	 Regressor Loss: -0.667496
Regressor Loss: -0.6675
Domain Loss: 0.0000
Train Epoch: 35 [6492/10752 (60%)]	 Regressor Loss: -0.990883
Regressor Loss: -0.9909
Domain Loss: 0.0000
Train Epoch: 35 [6612/10752 (61%)]	 Regressor Loss: -0.365882
Regressor Loss: -0.3659
Domain Loss: 0.0000
Train Epoch: 35 [6732/10752 (63%)]	 Regressor Loss: -0.866239
Regressor Loss: -0.8662
Domain Loss: 0.0000
Train Epoch: 35 [6852/10752 (64%)]	 Regressor Loss: -0.552468
Regressor Loss: -0.5525
Domain Loss: 0.2302
Train Epoch: 35 [6972/10752 (65%)]	 Regressor Loss: -1.047896
Regressor Loss: -1.0479
Domain Loss: 0.0000
Train Epoch: 35 [7092/10752 (66%)]	 Regressor Loss: -0.365950
Regressor Loss: -0.3659
Domain Loss: 0.0000
Train Epoch: 35 [7212/10752 (67%)]	 Regressor Loss: -0.808615
Regressor Loss: -0.8086
Domain Loss: 0.0000
Train Epoch: 35 [7332/10752 (68%)]	 Regressor Loss: -0.000000
Regressor Loss: -0.0000
Domain Loss: 0.0000
Train Epoch: 35 [7452/10752 (69%)]	 Regressor Loss: -0.907797
Regressor Loss: -0.9078
Domain Loss: 0.0000
Train Epoch: 35 [7572/10752 (70%)]	 Regressor Loss: -0.000000
Regressor Loss: -0.0000
Domain Loss: 0.0908
Train Epoch: 35 [7692/10752 (72%)]	 Regressor Loss: -0.510077
Regressor Loss: -0.5101
Domain Loss: 0.0001
Train Epoch: 35 [7812/10752 (73%)]	 Regressor Loss: -0.260147
Regressor Loss: -0.2601
Domain Loss: 0.0000
Train Epoch: 35 [7932/10752 (74%)]	 Regressor Loss: -0.482734
Regressor Loss: -0.4827
Domain Loss: 0.0000
Train Epoch: 35 [8052/10752 (75%)]	 Regressor Loss: -0.456832
Regressor Loss: -0.4568
Domain Loss: 0.0000
Train Epoch: 35 [8172/10752 (76%)]	 Regressor Loss: -0.455816
Regressor Loss: -0.4558
Domain Loss: 0.0000
Train Epoch: 35 [8292/10752 (77%)]	 Regressor Loss: -0.746968
Regressor Loss: -0.7470
Domain Loss: 0.0000
Train Epoch: 35 [8412/10752 (78%)]	 Regressor Loss: -0.445439
Regressor Loss: -0.4454
Domain Loss: 0.0000
Train Epoch: 35 [8532/10752 (79%)]	 Regressor Loss: -0.728459
Regressor Loss: -0.7285
Domain Loss: 0.0000
Train Epoch: 35 [8652/10752 (80%)]	 Regressor Loss: -0.891732
Regressor Loss: -0.8917
Domain Loss: 0.0000
Train Epoch: 35 [8772/10752 (82%)]	 Regressor Loss: -1.044748
Regressor Loss: -1.0447
Domain Loss: 0.0000
Train Epoch: 35 [8892/10752 (83%)]	 Regressor Loss: -0.492309
Regressor Loss: -0.4923
Domain Loss: 0.0000
Train Epoch: 35 [9012/10752 (84%)]	 Regressor Loss: -0.573114
Regressor Loss: -0.5731
Domain Loss: 0.0000
Train Epoch: 35 [9132/10752 (85%)]	 Regressor Loss: -0.288148
Regressor Loss: -0.2881
Domain Loss: 0.0000
Train Epoch: 35 [9252/10752 (86%)]	 Regressor Loss: -0.961214
Regressor Loss: -0.9612
Domain Loss: 0.0000
Train Epoch: 35 [9372/10752 (87%)]	 Regressor Loss: -0.391134
Regressor Loss: -0.3911
Domain Loss: 0.0000
Training set: Average loss: -0.6328
Training set: Average Domain loss: 0.0021
Training set: Average Acc: 0.9991
Validation set: Average loss: -0.5979
Validation set: Average Domain loss: 0.0010
 Validation set: Average Acc: 0.9992
Training Main Encoder
Epoch  36 / 300
Train Epoch: 36 [12/10752 (0%)]	 Regressor Loss: -0.879639
Regressor Loss: -0.8796
Domain Loss: 0.0000
Train Epoch: 36 [132/10752 (1%)]	 Regressor Loss: -0.305896
Regressor Loss: -0.3059
Domain Loss: 0.0000
Train Epoch: 36 [252/10752 (2%)]	 Regressor Loss: -0.937866
Regressor Loss: -0.9379
Domain Loss: 0.0000
Train Epoch: 36 [372/10752 (3%)]	 Regressor Loss: -0.480195
Regressor Loss: -0.4802
Domain Loss: 0.0000
Train Epoch: 36 [492/10752 (5%)]	 Regressor Loss: -1.043525
Regressor Loss: -1.0435
Domain Loss: 0.0000
Train Epoch: 36 [612/10752 (6%)]	 Regressor Loss: -0.347694
Regressor Loss: -0.3477
Domain Loss: 0.0000
Train Epoch: 36 [732/10752 (7%)]	 Regressor Loss: -1.018404
Regressor Loss: -1.0184
Domain Loss: 0.0000
Train Epoch: 36 [852/10752 (8%)]	 Regressor Loss: -0.457734
Regressor Loss: -0.4577
Domain Loss: 0.0000
Train Epoch: 36 [972/10752 (9%)]	 Regressor Loss: -0.646061
Regressor Loss: -0.6461
Domain Loss: 0.0000
Train Epoch: 36 [1092/10752 (10%)]	 Regressor Loss: -0.543934
Regressor Loss: -0.5439
Domain Loss: 0.0000
Train Epoch: 36 [1212/10752 (11%)]	 Regressor Loss: -0.364713
Regressor Loss: -0.3647
Domain Loss: 0.0000
Train Epoch: 36 [1332/10752 (12%)]	 Regressor Loss: -0.513262
Regressor Loss: -0.5133
Domain Loss: 0.0000
Train Epoch: 36 [1452/10752 (14%)]	 Regressor Loss: -0.458309
Regressor Loss: -0.4583
Domain Loss: 0.0000
Train Epoch: 36 [1572/10752 (15%)]	 Regressor Loss: -0.518653
Regressor Loss: -0.5187
Domain Loss: 0.0000
Train Epoch: 36 [1692/10752 (16%)]	 Regressor Loss: -0.503512
Regressor Loss: -0.5035
Domain Loss: 0.0000
Train Epoch: 36 [1812/10752 (17%)]	 Regressor Loss: -0.802785
Regressor Loss: -0.8028
Domain Loss: 0.0000
Train Epoch: 36 [1932/10752 (18%)]	 Regressor Loss: -0.352330
Regressor Loss: -0.3523
Domain Loss: 0.0000
Train Epoch: 36 [2052/10752 (19%)]	 Regressor Loss: -0.943347
Regressor Loss: -0.9433
Domain Loss: 0.0000
Train Epoch: 36 [2172/10752 (20%)]	 Regressor Loss: -0.310965
Regressor Loss: -0.3110
Domain Loss: 0.0000
Train Epoch: 36 [2292/10752 (21%)]	 Regressor Loss: -1.015933
Regressor Loss: -1.0159
Domain Loss: 0.0000
Train Epoch: 36 [2412/10752 (22%)]	 Regressor Loss: -0.499220
Regressor Loss: -0.4992
Domain Loss: 0.0000
Train Epoch: 36 [2532/10752 (24%)]	 Regressor Loss: -0.445885
Regressor Loss: -0.4459
Domain Loss: 0.0000
Train Epoch: 36 [2652/10752 (25%)]	 Regressor Loss: -0.149382
Regressor Loss: -0.1494
Domain Loss: 0.0000
Train Epoch: 36 [2772/10752 (26%)]	 Regressor Loss: -0.991031
Regressor Loss: -0.9910
Domain Loss: 0.0000
Train Epoch: 36 [2892/10752 (27%)]	 Regressor Loss: -0.492938
Regressor Loss: -0.4929
Domain Loss: 0.0000
Train Epoch: 36 [3012/10752 (28%)]	 Regressor Loss: -0.886099
Regressor Loss: -0.8861
Domain Loss: 0.0000
Train Epoch: 36 [3132/10752 (29%)]	 Regressor Loss: -0.801186
Regressor Loss: -0.8012
Domain Loss: 0.0000
Train Epoch: 36 [3252/10752 (30%)]	 Regressor Loss: -0.935326
Regressor Loss: -0.9353
Domain Loss: 0.0136
Train Epoch: 36 [3372/10752 (31%)]	 Regressor Loss: -0.419977
Regressor Loss: -0.4200
Domain Loss: 0.0000
Train Epoch: 36 [3492/10752 (32%)]	 Regressor Loss: -1.101156
Regressor Loss: -1.1012
Domain Loss: 0.0002
Train Epoch: 36 [3612/10752 (34%)]	 Regressor Loss: -0.490052
Regressor Loss: -0.4901
Domain Loss: 0.0000
Train Epoch: 36 [3732/10752 (35%)]	 Regressor Loss: -1.048545
Regressor Loss: -1.0485
Domain Loss: 0.0000
Train Epoch: 36 [3852/10752 (36%)]	 Regressor Loss: -0.548977
Regressor Loss: -0.5490
Domain Loss: 0.0000
Train Epoch: 36 [3972/10752 (37%)]	 Regressor Loss: -0.555705
Regressor Loss: -0.5557
Domain Loss: 0.0000
Train Epoch: 36 [4092/10752 (38%)]	 Regressor Loss: -0.533534
Regressor Loss: -0.5335
Domain Loss: 0.0000
Train Epoch: 36 [4212/10752 (39%)]	 Regressor Loss: -0.721631
Regressor Loss: -0.7216
Domain Loss: 0.0000
Train Epoch: 36 [4332/10752 (40%)]	 Regressor Loss: -0.459928
Regressor Loss: -0.4599
Domain Loss: 0.0000
Train Epoch: 36 [4452/10752 (41%)]	 Regressor Loss: -0.414868
Regressor Loss: -0.4149
Domain Loss: 0.0000
Train Epoch: 36 [4572/10752 (43%)]	 Regressor Loss: -0.413825
Regressor Loss: -0.4138
Domain Loss: 0.0000
Train Epoch: 36 [4692/10752 (44%)]	 Regressor Loss: -0.379402
Regressor Loss: -0.3794
Domain Loss: 0.0000
Train Epoch: 36 [4812/10752 (45%)]	 Regressor Loss: -0.540018
Regressor Loss: -0.5400
Domain Loss: 0.0000
Train Epoch: 36 [4932/10752 (46%)]	 Regressor Loss: -0.534170
Regressor Loss: -0.5342
Domain Loss: 0.0000
Train Epoch: 36 [5052/10752 (47%)]	 Regressor Loss: -0.665246
Regressor Loss: -0.6652
Domain Loss: 0.0000
Train Epoch: 36 [5172/10752 (48%)]	 Regressor Loss: -0.467668
Regressor Loss: -0.4677
Domain Loss: 0.0000
Train Epoch: 36 [5292/10752 (49%)]	 Regressor Loss: -0.986836
Regressor Loss: -0.9868
Domain Loss: 0.0010
Train Epoch: 36 [5412/10752 (50%)]	 Regressor Loss: -0.506444
Regressor Loss: -0.5064
Domain Loss: 0.0000
Train Epoch: 36 [5532/10752 (51%)]	 Regressor Loss: -0.987926
Regressor Loss: -0.9879
Domain Loss: 0.0000
Train Epoch: 36 [5652/10752 (53%)]	 Regressor Loss: -0.785898
Regressor Loss: -0.7859
Domain Loss: 0.0000
Train Epoch: 36 [5772/10752 (54%)]	 Regressor Loss: -1.056987
Regressor Loss: -1.0570
Domain Loss: 0.0000
Train Epoch: 36 [5892/10752 (55%)]	 Regressor Loss: -0.464193
Regressor Loss: -0.4642
Domain Loss: 0.0000
Train Epoch: 36 [6012/10752 (56%)]	 Regressor Loss: -1.130746
Regressor Loss: -1.1307
Domain Loss: 0.0001
